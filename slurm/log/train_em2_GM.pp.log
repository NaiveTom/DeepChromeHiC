************************************
************************************

    Welcome to use DeepChromeHiC

************************************
************************************

begin time >>> Sun Oct  3 04:17:30 2021

begin time >>> Sun Oct  3 04:17:30 2021

begin time >>> Sun Oct  3 04:17:30 2021

begin time >>> Sun Oct  3 04:17:30 2021

begin time >>> Sun Oct  3 04:17:30 2021



If it is the first time to use, please preprocess the data first.
Use the command: python3 DeepChromeHiC.py -p true -n [gene name]
For example: python3 DeepChromeHiC.py -p true -n AD2.po


=== Below is your input ===

args.model = onehot_embedding_dense
args.type = train
args.name = GM.pp
args.length = 10001
===========================


-> h5_weights/GM.pp folder already exist. pass.
-> result/GM.pp/onehot_cnn_one_branch folder already exist. pass.
-> result/GM.pp/onehot_cnn_two_branch folder already exist. pass.
-> result/GM.pp/onehot_embedding_dense folder already exist. pass.
-> result/GM.pp/onehot_dense folder already exist. pass.
-> result/GM.pp/onehot_resnet18 folder already exist. pass.
-> result/GM.pp/onehot_resnet34 folder already exist. pass.
-> result/GM.pp/embedding_cnn_one_branch folder already exist. pass.
-> result/GM.pp/embedding_cnn_two_branch folder already exist. pass.
-> result/GM.pp/embedding_dense folder already exist. pass.
-> result/GM.pp/onehot_embedding_cnn_one_branch folder already exist. pass.
-> result/GM.pp/onehot_embedding_cnn_two_branch folder already exist. pass.
########################################
gen_name
GM.pp
########################################

########################################
model_name
onehot_embedding_dense
########################################

Found 4468 images belonging to 2 classes.
Found 550 images belonging to 2 classes.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 20002, 5, 1, 8)    32776     
_________________________________________________________________
flatten (Flatten)            (None, 800080)            0         
_________________________________________________________________
batch_normalization (BatchNo (None, 800080)            3200320   
_________________________________________________________________
dense (Dense)                (None, 512)               409641472 
_________________________________________________________________
batch_normalization_1 (Batch (None, 512)               2048      
_________________________________________________________________
activation (Activation)      (None, 512)               0         
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               262656    
_________________________________________________________________
batch_normalization_2 (Batch (None, 512)               2048      
_________________________________________________________________
activation_1 (Activation)    (None, 512)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 512)               262656    
_________________________________________________________________
batch_normalization_3 (Batch (None, 512)               2048      
_________________________________________________________________
activation_2 (Activation)    (None, 512)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               262656    
_________________________________________________________________
batch_normalization_4 (Batch (None, 512)               2048      
_________________________________________________________________
activation_3 (Activation)    (None, 512)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 2)                 1026      
=================================================================
Total params: 413,671,754
Trainable params: 412,067,498
Non-trainable params: 1,604,256
_________________________________________________________________
Epoch 1/500
139/139 - 70s - loss: 0.7686 - accuracy: 0.5546 - val_loss: 0.6972 - val_accuracy: 0.4982
Epoch 2/500
139/139 - 27s - loss: 0.6491 - accuracy: 0.6531 - val_loss: 0.7997 - val_accuracy: 0.4982
Epoch 3/500
139/139 - 27s - loss: 0.5754 - accuracy: 0.7101 - val_loss: 0.9936 - val_accuracy: 0.5018
Epoch 4/500
139/139 - 28s - loss: 0.4792 - accuracy: 0.7689 - val_loss: 1.1601 - val_accuracy: 0.5037
Epoch 5/500
139/139 - 27s - loss: 0.3980 - accuracy: 0.8282 - val_loss: 1.2694 - val_accuracy: 0.5239
Epoch 6/500
139/139 - 28s - loss: 0.3313 - accuracy: 0.8620 - val_loss: 1.3090 - val_accuracy: 0.5643
Epoch 7/500
139/139 - 27s - loss: 0.2562 - accuracy: 0.8909 - val_loss: 1.4239 - val_accuracy: 0.5625
Epoch 8/500
139/139 - 26s - loss: 0.2298 - accuracy: 0.9083 - val_loss: 1.5203 - val_accuracy: 0.5625
Epoch 9/500
139/139 - 27s - loss: 0.1944 - accuracy: 0.9261 - val_loss: 1.6434 - val_accuracy: 0.5662
Epoch 10/500
139/139 - 26s - loss: 0.1617 - accuracy: 0.9364 - val_loss: 1.7801 - val_accuracy: 0.5625
Epoch 11/500
139/139 - 27s - loss: 0.1432 - accuracy: 0.9441 - val_loss: 1.8167 - val_accuracy: 0.5680
Epoch 12/500
139/139 - 28s - loss: 0.1389 - accuracy: 0.9457 - val_loss: 1.8671 - val_accuracy: 0.5772
Epoch 13/500
139/139 - 27s - loss: 0.1019 - accuracy: 0.9596 - val_loss: 1.8629 - val_accuracy: 0.5864
Epoch 14/500
139/139 - 26s - loss: 0.1051 - accuracy: 0.9603 - val_loss: 1.9105 - val_accuracy: 0.5846
Epoch 15/500
139/139 - 27s - loss: 0.0945 - accuracy: 0.9624 - val_loss: 1.9606 - val_accuracy: 0.5956
Epoch 16/500
139/139 - 27s - loss: 0.0925 - accuracy: 0.9669 - val_loss: 1.9711 - val_accuracy: 0.6011
Epoch 17/500
139/139 - 27s - loss: 0.0743 - accuracy: 0.9718 - val_loss: 2.0054 - val_accuracy: 0.6085
Epoch 18/500
139/139 - 25s - loss: 0.0671 - accuracy: 0.9762 - val_loss: 2.1093 - val_accuracy: 0.5974
Epoch 19/500
139/139 - 25s - loss: 0.0655 - accuracy: 0.9770 - val_loss: 2.1196 - val_accuracy: 0.5919
Epoch 20/500
139/139 - 25s - loss: 0.0731 - accuracy: 0.9709 - val_loss: 2.1433 - val_accuracy: 0.5974
Epoch 21/500
139/139 - 26s - loss: 0.0602 - accuracy: 0.9777 - val_loss: 2.1734 - val_accuracy: 0.5993
Epoch 22/500
139/139 - 26s - loss: 0.0574 - accuracy: 0.9793 - val_loss: 2.2693 - val_accuracy: 0.5938
Epoch 23/500
139/139 - 25s - loss: 0.0450 - accuracy: 0.9835 - val_loss: 2.2986 - val_accuracy: 0.5993
Epoch 24/500
139/139 - 25s - loss: 0.0478 - accuracy: 0.9822 - val_loss: 2.2725 - val_accuracy: 0.6048
Epoch 25/500
139/139 - 25s - loss: 0.0599 - accuracy: 0.9784 - val_loss: 2.2445 - val_accuracy: 0.6011
Epoch 26/500
139/139 - 25s - loss: 0.0564 - accuracy: 0.9811 - val_loss: 2.2374 - val_accuracy: 0.6066
Epoch 27/500
139/139 - 27s - loss: 0.0487 - accuracy: 0.9815 - val_loss: 2.2625 - val_accuracy: 0.6085
========================================
save_weights
h5_weights/GM.pp/onehot_embedding_dense.h5
========================================

end time >>> Sun Oct  3 04:30:25 2021

end time >>> Sun Oct  3 04:30:25 2021

end time >>> Sun Oct  3 04:30:25 2021

end time >>> Sun Oct  3 04:30:25 2021

end time >>> Sun Oct  3 04:30:25 2021












args.model = onehot_embedding_dense
time used = 775.142341375351


************************************
************************************

    Welcome to use DeepChromeHiC

************************************
************************************

begin time >>> Sun Oct  3 04:30:26 2021

begin time >>> Sun Oct  3 04:30:26 2021

begin time >>> Sun Oct  3 04:30:26 2021

begin time >>> Sun Oct  3 04:30:26 2021

begin time >>> Sun Oct  3 04:30:26 2021



If it is the first time to use, please preprocess the data first.
Use the command: python3 DeepChromeHiC.py -p true -n [gene name]
For example: python3 DeepChromeHiC.py -p true -n AD2.po


=== Below is your input ===

args.model = onehot_embedding_cnn_one_branch
args.type = train
args.name = GM.pp
args.length = 10001
===========================


-> h5_weights/GM.pp folder already exist. pass.
-> result/GM.pp/onehot_cnn_one_branch folder already exist. pass.
-> result/GM.pp/onehot_cnn_two_branch folder already exist. pass.
-> result/GM.pp/onehot_embedding_dense folder already exist. pass.
-> result/GM.pp/onehot_dense folder already exist. pass.
-> result/GM.pp/onehot_resnet18 folder already exist. pass.
-> result/GM.pp/onehot_resnet34 folder already exist. pass.
-> result/GM.pp/embedding_cnn_one_branch folder already exist. pass.
-> result/GM.pp/embedding_cnn_two_branch folder already exist. pass.
-> result/GM.pp/embedding_dense folder already exist. pass.
-> result/GM.pp/onehot_embedding_cnn_one_branch folder already exist. pass.
-> result/GM.pp/onehot_embedding_cnn_two_branch folder already exist. pass.
########################################
gen_name
GM.pp
########################################

########################################
model_name
onehot_embedding_cnn_one_branch
########################################

Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 10001, 100)   409700      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 10001, 100)   409700      input_2[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 20002, 100)   0           embedding[0][0]                  
                                                                 embedding_1[0][0]                
__________________________________________________________________________________________________
sequential (Sequential)         (None, 155, 64)      205888      concatenate[0][0]                
__________________________________________________________________________________________________
flatten (Flatten)               (None, 9920)         0           sequential[0][0]                 
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 9920)         39680       flatten[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 9920)         0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dense (Dense)                   (None, 512)          5079552     dropout[0][0]                    
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 512)          2048        dense[0][0]                      
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 512)          0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           activation_4[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 512)          2048        dense_1[0][0]                    
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 512)          0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           activation_5[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_2[0][0]                  
==================================================================================================
Total params: 6,411,785
Trainable params: 6,389,385
Non-trainable params: 22,400
__________________________________________________________________________________________________
Epoch 1/500
140/140 - 20s - loss: 0.9334 - accuracy: 0.5011 - val_loss: 0.6991 - val_accuracy: 0.4674
Epoch 2/500
140/140 - 19s - loss: 0.9211 - accuracy: 0.4991 - val_loss: 0.6992 - val_accuracy: 0.4674
Epoch 3/500
140/140 - 19s - loss: 0.8645 - accuracy: 0.5172 - val_loss: 0.6987 - val_accuracy: 0.4674
Epoch 4/500
140/140 - 19s - loss: 0.8520 - accuracy: 0.5226 - val_loss: 0.6987 - val_accuracy: 0.4728
Epoch 5/500
140/140 - 19s - loss: 0.8641 - accuracy: 0.5130 - val_loss: 0.7001 - val_accuracy: 0.4837
Epoch 6/500
140/140 - 19s - loss: 0.8521 - accuracy: 0.5155 - val_loss: 0.6997 - val_accuracy: 0.5091
Epoch 7/500
140/140 - 19s - loss: 0.8137 - accuracy: 0.5416 - val_loss: 0.6974 - val_accuracy: 0.5145
Epoch 8/500
140/140 - 19s - loss: 0.8062 - accuracy: 0.5428 - val_loss: 0.6938 - val_accuracy: 0.5308
Epoch 9/500
140/140 - 20s - loss: 0.8101 - accuracy: 0.5282 - val_loss: 0.6908 - val_accuracy: 0.5326
Epoch 10/500
140/140 - 19s - loss: 0.7695 - accuracy: 0.5600 - val_loss: 0.6877 - val_accuracy: 0.5435
Epoch 11/500
140/140 - 19s - loss: 0.7899 - accuracy: 0.5448 - val_loss: 0.6854 - val_accuracy: 0.5435
Epoch 12/500
140/140 - 19s - loss: 0.7742 - accuracy: 0.5636 - val_loss: 0.6818 - val_accuracy: 0.5670
Epoch 13/500
140/140 - 19s - loss: 0.7775 - accuracy: 0.5553 - val_loss: 0.6785 - val_accuracy: 0.5688
Epoch 14/500
140/140 - 19s - loss: 0.7573 - accuracy: 0.5717 - val_loss: 0.6762 - val_accuracy: 0.5797
Epoch 15/500
140/140 - 19s - loss: 0.7520 - accuracy: 0.5793 - val_loss: 0.6751 - val_accuracy: 0.5761
Epoch 16/500
140/140 - 19s - loss: 0.7478 - accuracy: 0.5755 - val_loss: 0.6726 - val_accuracy: 0.5851
Epoch 17/500
140/140 - 19s - loss: 0.7466 - accuracy: 0.5788 - val_loss: 0.6707 - val_accuracy: 0.5851
Epoch 18/500
140/140 - 19s - loss: 0.7458 - accuracy: 0.5781 - val_loss: 0.6687 - val_accuracy: 0.5906
Epoch 19/500
140/140 - 19s - loss: 0.7290 - accuracy: 0.5840 - val_loss: 0.6672 - val_accuracy: 0.5870
Epoch 20/500
140/140 - 19s - loss: 0.7449 - accuracy: 0.5793 - val_loss: 0.6662 - val_accuracy: 0.5960
Epoch 21/500
140/140 - 20s - loss: 0.7222 - accuracy: 0.5923 - val_loss: 0.6638 - val_accuracy: 0.5978
Epoch 22/500
140/140 - 19s - loss: 0.7230 - accuracy: 0.5902 - val_loss: 0.6627 - val_accuracy: 0.5996
Epoch 23/500
140/140 - 19s - loss: 0.7033 - accuracy: 0.6028 - val_loss: 0.6609 - val_accuracy: 0.6051
Epoch 24/500
140/140 - 19s - loss: 0.6936 - accuracy: 0.6066 - val_loss: 0.6595 - val_accuracy: 0.6033
Epoch 25/500
140/140 - 19s - loss: 0.7024 - accuracy: 0.6055 - val_loss: 0.6578 - val_accuracy: 0.5996
Epoch 26/500
140/140 - 19s - loss: 0.6868 - accuracy: 0.6173 - val_loss: 0.6559 - val_accuracy: 0.6051
Epoch 27/500
140/140 - 19s - loss: 0.6734 - accuracy: 0.6281 - val_loss: 0.6547 - val_accuracy: 0.6123
Epoch 28/500
140/140 - 19s - loss: 0.6800 - accuracy: 0.6200 - val_loss: 0.6523 - val_accuracy: 0.6159
Epoch 29/500
140/140 - 19s - loss: 0.6765 - accuracy: 0.6303 - val_loss: 0.6509 - val_accuracy: 0.6178
Epoch 30/500
140/140 - 19s - loss: 0.6752 - accuracy: 0.6321 - val_loss: 0.6494 - val_accuracy: 0.6250
Epoch 31/500
140/140 - 19s - loss: 0.6501 - accuracy: 0.6444 - val_loss: 0.6476 - val_accuracy: 0.6322
Epoch 32/500
140/140 - 19s - loss: 0.6494 - accuracy: 0.6525 - val_loss: 0.6461 - val_accuracy: 0.6286
Epoch 33/500
140/140 - 19s - loss: 0.6488 - accuracy: 0.6534 - val_loss: 0.6450 - val_accuracy: 0.6304
Epoch 34/500
140/140 - 19s - loss: 0.6194 - accuracy: 0.6637 - val_loss: 0.6439 - val_accuracy: 0.6341
Epoch 35/500
140/140 - 19s - loss: 0.6432 - accuracy: 0.6603 - val_loss: 0.6423 - val_accuracy: 0.6395
Epoch 36/500
140/140 - 19s - loss: 0.6165 - accuracy: 0.6706 - val_loss: 0.6411 - val_accuracy: 0.6413
Epoch 37/500
140/140 - 19s - loss: 0.6290 - accuracy: 0.6639 - val_loss: 0.6395 - val_accuracy: 0.6413
Epoch 38/500
140/140 - 19s - loss: 0.6254 - accuracy: 0.6691 - val_loss: 0.6382 - val_accuracy: 0.6413
Epoch 39/500
140/140 - 19s - loss: 0.5929 - accuracy: 0.6901 - val_loss: 0.6363 - val_accuracy: 0.6431
Epoch 40/500
140/140 - 19s - loss: 0.6009 - accuracy: 0.6872 - val_loss: 0.6351 - val_accuracy: 0.6413
Epoch 41/500
140/140 - 19s - loss: 0.6062 - accuracy: 0.6762 - val_loss: 0.6338 - val_accuracy: 0.6449
Epoch 42/500
140/140 - 19s - loss: 0.5861 - accuracy: 0.6984 - val_loss: 0.6323 - val_accuracy: 0.6486
Epoch 43/500
140/140 - 19s - loss: 0.5784 - accuracy: 0.7040 - val_loss: 0.6320 - val_accuracy: 0.6449
Epoch 44/500
140/140 - 20s - loss: 0.5661 - accuracy: 0.7103 - val_loss: 0.6310 - val_accuracy: 0.6522
Epoch 45/500
140/140 - 19s - loss: 0.5705 - accuracy: 0.7114 - val_loss: 0.6297 - val_accuracy: 0.6504
Epoch 46/500
140/140 - 19s - loss: 0.5588 - accuracy: 0.7118 - val_loss: 0.6283 - val_accuracy: 0.6522
Epoch 47/500
140/140 - 19s - loss: 0.5621 - accuracy: 0.7091 - val_loss: 0.6274 - val_accuracy: 0.6576
Epoch 48/500
140/140 - 19s - loss: 0.5586 - accuracy: 0.7123 - val_loss: 0.6262 - val_accuracy: 0.6594
Epoch 49/500
140/140 - 19s - loss: 0.5295 - accuracy: 0.7293 - val_loss: 0.6253 - val_accuracy: 0.6522
Epoch 50/500
140/140 - 19s - loss: 0.5130 - accuracy: 0.7429 - val_loss: 0.6241 - val_accuracy: 0.6594
Epoch 51/500
140/140 - 19s - loss: 0.5264 - accuracy: 0.7429 - val_loss: 0.6237 - val_accuracy: 0.6612
Epoch 52/500
140/140 - 19s - loss: 0.5204 - accuracy: 0.7400 - val_loss: 0.6234 - val_accuracy: 0.6630
Epoch 53/500
140/140 - 19s - loss: 0.4988 - accuracy: 0.7530 - val_loss: 0.6227 - val_accuracy: 0.6630
Epoch 54/500
140/140 - 19s - loss: 0.4933 - accuracy: 0.7611 - val_loss: 0.6218 - val_accuracy: 0.6630
Epoch 55/500
140/140 - 19s - loss: 0.4781 - accuracy: 0.7705 - val_loss: 0.6216 - val_accuracy: 0.6630
Epoch 56/500
140/140 - 19s - loss: 0.4738 - accuracy: 0.7723 - val_loss: 0.6213 - val_accuracy: 0.6667
Epoch 57/500
140/140 - 19s - loss: 0.4811 - accuracy: 0.7658 - val_loss: 0.6205 - val_accuracy: 0.6649
Epoch 58/500
140/140 - 19s - loss: 0.4678 - accuracy: 0.7803 - val_loss: 0.6205 - val_accuracy: 0.6612
Epoch 59/500
140/140 - 19s - loss: 0.4700 - accuracy: 0.7730 - val_loss: 0.6201 - val_accuracy: 0.6630
Epoch 60/500
140/140 - 19s - loss: 0.4590 - accuracy: 0.7772 - val_loss: 0.6201 - val_accuracy: 0.6703
Epoch 61/500
140/140 - 19s - loss: 0.4434 - accuracy: 0.7974 - val_loss: 0.6205 - val_accuracy: 0.6721
Epoch 62/500
140/140 - 19s - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.6211 - val_accuracy: 0.6667
Epoch 63/500
140/140 - 19s - loss: 0.4312 - accuracy: 0.7998 - val_loss: 0.6208 - val_accuracy: 0.6667
Epoch 64/500
140/140 - 19s - loss: 0.4312 - accuracy: 0.7938 - val_loss: 0.6210 - val_accuracy: 0.6667
Epoch 65/500
140/140 - 19s - loss: 0.4219 - accuracy: 0.8018 - val_loss: 0.6206 - val_accuracy: 0.6685
Epoch 66/500
140/140 - 19s - loss: 0.4144 - accuracy: 0.8094 - val_loss: 0.6212 - val_accuracy: 0.6667
Epoch 67/500
140/140 - 19s - loss: 0.4155 - accuracy: 0.8054 - val_loss: 0.6218 - val_accuracy: 0.6721
Epoch 68/500
140/140 - 19s - loss: 0.4088 - accuracy: 0.8180 - val_loss: 0.6228 - val_accuracy: 0.6685
Epoch 69/500
140/140 - 19s - loss: 0.3982 - accuracy: 0.8224 - val_loss: 0.6241 - val_accuracy: 0.6685
Epoch 70/500
140/140 - 19s - loss: 0.3844 - accuracy: 0.8318 - val_loss: 0.6251 - val_accuracy: 0.6667
Epoch 71/500
140/140 - 19s - loss: 0.3907 - accuracy: 0.8218 - val_loss: 0.6254 - val_accuracy: 0.6649
Epoch 72/500
140/140 - 19s - loss: 0.3820 - accuracy: 0.8330 - val_loss: 0.6272 - val_accuracy: 0.6649
Epoch 73/500
140/140 - 19s - loss: 0.3607 - accuracy: 0.8381 - val_loss: 0.6274 - val_accuracy: 0.6685
Epoch 74/500
140/140 - 19s - loss: 0.3570 - accuracy: 0.8406 - val_loss: 0.6279 - val_accuracy: 0.6667
Epoch 75/500
140/140 - 19s - loss: 0.3548 - accuracy: 0.8379 - val_loss: 0.6284 - val_accuracy: 0.6703
Epoch 76/500
140/140 - 19s - loss: 0.3520 - accuracy: 0.8471 - val_loss: 0.6298 - val_accuracy: 0.6703
Epoch 77/500
140/140 - 19s - loss: 0.3419 - accuracy: 0.8468 - val_loss: 0.6301 - val_accuracy: 0.6703
Epoch 78/500
140/140 - 19s - loss: 0.3377 - accuracy: 0.8558 - val_loss: 0.6315 - val_accuracy: 0.6685
Epoch 79/500
140/140 - 19s - loss: 0.3223 - accuracy: 0.8592 - val_loss: 0.6336 - val_accuracy: 0.6703
Epoch 80/500
140/140 - 19s - loss: 0.3188 - accuracy: 0.8683 - val_loss: 0.6352 - val_accuracy: 0.6685
Epoch 81/500
140/140 - 19s - loss: 0.3350 - accuracy: 0.8515 - val_loss: 0.6369 - val_accuracy: 0.6739
Epoch 82/500
140/140 - 19s - loss: 0.3135 - accuracy: 0.8598 - val_loss: 0.6383 - val_accuracy: 0.6721
Epoch 83/500
140/140 - 19s - loss: 0.3166 - accuracy: 0.8625 - val_loss: 0.6401 - val_accuracy: 0.6775
Epoch 84/500
140/140 - 19s - loss: 0.3162 - accuracy: 0.8695 - val_loss: 0.6419 - val_accuracy: 0.6775
Epoch 85/500
140/140 - 19s - loss: 0.2963 - accuracy: 0.8764 - val_loss: 0.6438 - val_accuracy: 0.6757
Epoch 86/500
140/140 - 19s - loss: 0.2993 - accuracy: 0.8760 - val_loss: 0.6442 - val_accuracy: 0.6757
Epoch 87/500
140/140 - 19s - loss: 0.2689 - accuracy: 0.8901 - val_loss: 0.6461 - val_accuracy: 0.6739
Epoch 88/500
140/140 - 19s - loss: 0.2911 - accuracy: 0.8878 - val_loss: 0.6476 - val_accuracy: 0.6775
Epoch 89/500
140/140 - 19s - loss: 0.2742 - accuracy: 0.8874 - val_loss: 0.6492 - val_accuracy: 0.6757
Epoch 90/500
140/140 - 19s - loss: 0.2827 - accuracy: 0.8858 - val_loss: 0.6525 - val_accuracy: 0.6812
Epoch 91/500
140/140 - 19s - loss: 0.2637 - accuracy: 0.8887 - val_loss: 0.6547 - val_accuracy: 0.6793
Epoch 92/500
140/140 - 19s - loss: 0.2554 - accuracy: 0.8963 - val_loss: 0.6571 - val_accuracy: 0.6775
Epoch 93/500
140/140 - 19s - loss: 0.2536 - accuracy: 0.8999 - val_loss: 0.6590 - val_accuracy: 0.6775
Epoch 94/500
140/140 - 19s - loss: 0.2427 - accuracy: 0.9046 - val_loss: 0.6617 - val_accuracy: 0.6793
Epoch 95/500
140/140 - 19s - loss: 0.2570 - accuracy: 0.8966 - val_loss: 0.6653 - val_accuracy: 0.6812
Epoch 96/500
140/140 - 19s - loss: 0.2370 - accuracy: 0.9035 - val_loss: 0.6660 - val_accuracy: 0.6848
Epoch 97/500
140/140 - 19s - loss: 0.2429 - accuracy: 0.8988 - val_loss: 0.6696 - val_accuracy: 0.6830
Epoch 98/500
140/140 - 19s - loss: 0.2365 - accuracy: 0.9044 - val_loss: 0.6716 - val_accuracy: 0.6812
Epoch 99/500
140/140 - 19s - loss: 0.2370 - accuracy: 0.9093 - val_loss: 0.6740 - val_accuracy: 0.6830
Epoch 100/500
140/140 - 19s - loss: 0.2343 - accuracy: 0.9064 - val_loss: 0.6762 - val_accuracy: 0.6848
Epoch 101/500
140/140 - 19s - loss: 0.2211 - accuracy: 0.9158 - val_loss: 0.6803 - val_accuracy: 0.6848
Epoch 102/500
140/140 - 19s - loss: 0.2313 - accuracy: 0.9133 - val_loss: 0.6815 - val_accuracy: 0.6848
Epoch 103/500
140/140 - 19s - loss: 0.2112 - accuracy: 0.9145 - val_loss: 0.6837 - val_accuracy: 0.6830
Epoch 104/500
140/140 - 19s - loss: 0.2242 - accuracy: 0.9102 - val_loss: 0.6890 - val_accuracy: 0.6812
Epoch 105/500
140/140 - 19s - loss: 0.2085 - accuracy: 0.9198 - val_loss: 0.6914 - val_accuracy: 0.6830
Epoch 106/500
140/140 - 19s - loss: 0.2100 - accuracy: 0.9145 - val_loss: 0.6945 - val_accuracy: 0.6830
Epoch 107/500
140/140 - 19s - loss: 0.2134 - accuracy: 0.9174 - val_loss: 0.6983 - val_accuracy: 0.6830
Epoch 108/500
140/140 - 19s - loss: 0.2049 - accuracy: 0.9176 - val_loss: 0.7009 - val_accuracy: 0.6812
Epoch 109/500
140/140 - 19s - loss: 0.1933 - accuracy: 0.9250 - val_loss: 0.7043 - val_accuracy: 0.6812
Epoch 110/500
140/140 - 19s - loss: 0.1995 - accuracy: 0.9230 - val_loss: 0.7073 - val_accuracy: 0.6812
Epoch 111/500
140/140 - 19s - loss: 0.1997 - accuracy: 0.9203 - val_loss: 0.7105 - val_accuracy: 0.6830
Epoch 112/500
140/140 - 19s - loss: 0.1843 - accuracy: 0.9288 - val_loss: 0.7123 - val_accuracy: 0.6848
Epoch 113/500
140/140 - 19s - loss: 0.1804 - accuracy: 0.9295 - val_loss: 0.7168 - val_accuracy: 0.6775
Epoch 114/500
140/140 - 19s - loss: 0.1746 - accuracy: 0.9351 - val_loss: 0.7196 - val_accuracy: 0.6775
Epoch 115/500
140/140 - 19s - loss: 0.1776 - accuracy: 0.9308 - val_loss: 0.7233 - val_accuracy: 0.6866
Epoch 116/500
140/140 - 19s - loss: 0.1794 - accuracy: 0.9351 - val_loss: 0.7236 - val_accuracy: 0.6830
Epoch 117/500
140/140 - 19s - loss: 0.1704 - accuracy: 0.9344 - val_loss: 0.7275 - val_accuracy: 0.6848
Epoch 118/500
140/140 - 19s - loss: 0.1607 - accuracy: 0.9431 - val_loss: 0.7305 - val_accuracy: 0.6866
Epoch 119/500
140/140 - 19s - loss: 0.1925 - accuracy: 0.9225 - val_loss: 0.7371 - val_accuracy: 0.6793
Epoch 120/500
140/140 - 19s - loss: 0.1533 - accuracy: 0.9420 - val_loss: 0.7411 - val_accuracy: 0.6866
Epoch 121/500
140/140 - 19s - loss: 0.1668 - accuracy: 0.9339 - val_loss: 0.7441 - val_accuracy: 0.6902
Epoch 122/500
140/140 - 19s - loss: 0.1553 - accuracy: 0.9420 - val_loss: 0.7480 - val_accuracy: 0.6902
Epoch 123/500
140/140 - 19s - loss: 0.1490 - accuracy: 0.9476 - val_loss: 0.7501 - val_accuracy: 0.6902
Epoch 124/500
140/140 - 19s - loss: 0.1507 - accuracy: 0.9413 - val_loss: 0.7534 - val_accuracy: 0.6866
Epoch 125/500
140/140 - 19s - loss: 0.1647 - accuracy: 0.9371 - val_loss: 0.7586 - val_accuracy: 0.6938
Epoch 126/500
140/140 - 19s - loss: 0.1502 - accuracy: 0.9445 - val_loss: 0.7602 - val_accuracy: 0.6902
Epoch 127/500
140/140 - 19s - loss: 0.1495 - accuracy: 0.9456 - val_loss: 0.7630 - val_accuracy: 0.6975
Epoch 128/500
140/140 - 19s - loss: 0.1566 - accuracy: 0.9400 - val_loss: 0.7684 - val_accuracy: 0.6975
Epoch 129/500
140/140 - 19s - loss: 0.1514 - accuracy: 0.9413 - val_loss: 0.7700 - val_accuracy: 0.6993
Epoch 130/500
140/140 - 19s - loss: 0.1436 - accuracy: 0.9487 - val_loss: 0.7725 - val_accuracy: 0.6993
Epoch 131/500
140/140 - 19s - loss: 0.1309 - accuracy: 0.9525 - val_loss: 0.7750 - val_accuracy: 0.6993
Epoch 132/500
140/140 - 19s - loss: 0.1354 - accuracy: 0.9494 - val_loss: 0.7791 - val_accuracy: 0.7029
Epoch 133/500
140/140 - 19s - loss: 0.1389 - accuracy: 0.9458 - val_loss: 0.7811 - val_accuracy: 0.7047
Epoch 134/500
140/140 - 19s - loss: 0.1359 - accuracy: 0.9489 - val_loss: 0.7863 - val_accuracy: 0.7047
Epoch 135/500
140/140 - 19s - loss: 0.1270 - accuracy: 0.9559 - val_loss: 0.7890 - val_accuracy: 0.7011
Epoch 136/500
140/140 - 19s - loss: 0.1380 - accuracy: 0.9494 - val_loss: 0.7942 - val_accuracy: 0.7029
Epoch 137/500
140/140 - 19s - loss: 0.1269 - accuracy: 0.9554 - val_loss: 0.7973 - val_accuracy: 0.6975
Epoch 138/500
140/140 - 19s - loss: 0.1275 - accuracy: 0.9514 - val_loss: 0.7993 - val_accuracy: 0.7083
Epoch 139/500
140/140 - 19s - loss: 0.1257 - accuracy: 0.9552 - val_loss: 0.8025 - val_accuracy: 0.7065
Epoch 140/500
140/140 - 19s - loss: 0.1283 - accuracy: 0.9528 - val_loss: 0.8062 - val_accuracy: 0.7011
Epoch 141/500
140/140 - 19s - loss: 0.1231 - accuracy: 0.9516 - val_loss: 0.8095 - val_accuracy: 0.6902
Epoch 142/500
140/140 - 19s - loss: 0.1174 - accuracy: 0.9532 - val_loss: 0.8133 - val_accuracy: 0.6957
Epoch 143/500
140/140 - 19s - loss: 0.1174 - accuracy: 0.9563 - val_loss: 0.8183 - val_accuracy: 0.6975
Epoch 144/500
140/140 - 19s - loss: 0.1234 - accuracy: 0.9568 - val_loss: 0.8196 - val_accuracy: 0.6975
Epoch 145/500
140/140 - 19s - loss: 0.1177 - accuracy: 0.9579 - val_loss: 0.8233 - val_accuracy: 0.6993
Epoch 146/500
140/140 - 19s - loss: 0.1113 - accuracy: 0.9597 - val_loss: 0.8255 - val_accuracy: 0.6938
Epoch 147/500
140/140 - 19s - loss: 0.1055 - accuracy: 0.9624 - val_loss: 0.8308 - val_accuracy: 0.6938
Epoch 148/500
140/140 - 19s - loss: 0.1183 - accuracy: 0.9530 - val_loss: 0.8336 - val_accuracy: 0.7047
Epoch 149/500
140/140 - 19s - loss: 0.1059 - accuracy: 0.9615 - val_loss: 0.8375 - val_accuracy: 0.7011
Epoch 150/500
140/140 - 19s - loss: 0.1077 - accuracy: 0.9628 - val_loss: 0.8431 - val_accuracy: 0.6938
Epoch 151/500
140/140 - 19s - loss: 0.1053 - accuracy: 0.9595 - val_loss: 0.8448 - val_accuracy: 0.6975
Epoch 152/500
140/140 - 19s - loss: 0.1074 - accuracy: 0.9619 - val_loss: 0.8498 - val_accuracy: 0.6993
Epoch 153/500
140/140 - 19s - loss: 0.1073 - accuracy: 0.9592 - val_loss: 0.8542 - val_accuracy: 0.6975
Epoch 154/500
140/140 - 19s - loss: 0.1142 - accuracy: 0.9575 - val_loss: 0.8542 - val_accuracy: 0.6957
Epoch 155/500
140/140 - 19s - loss: 0.0958 - accuracy: 0.9682 - val_loss: 0.8567 - val_accuracy: 0.7029
Epoch 156/500
140/140 - 19s - loss: 0.0958 - accuracy: 0.9655 - val_loss: 0.8622 - val_accuracy: 0.6993
Epoch 157/500
140/140 - 19s - loss: 0.0952 - accuracy: 0.9657 - val_loss: 0.8633 - val_accuracy: 0.6920
Epoch 158/500
140/140 - 19s - loss: 0.0949 - accuracy: 0.9707 - val_loss: 0.8681 - val_accuracy: 0.7029
========================================
save_weights
h5_weights/GM.pp/onehot_embedding_cnn_one_branch.h5
========================================

end time >>> Sun Oct  3 05:21:48 2021

end time >>> Sun Oct  3 05:21:48 2021

end time >>> Sun Oct  3 05:21:48 2021

end time >>> Sun Oct  3 05:21:48 2021

end time >>> Sun Oct  3 05:21:48 2021












args.model = onehot_embedding_cnn_one_branch
time used = 3082.6248528957367


************************************
************************************

    Welcome to use DeepChromeHiC

************************************
************************************

begin time >>> Sun Oct  3 05:21:50 2021

begin time >>> Sun Oct  3 05:21:50 2021

begin time >>> Sun Oct  3 05:21:50 2021

begin time >>> Sun Oct  3 05:21:50 2021

begin time >>> Sun Oct  3 05:21:50 2021



If it is the first time to use, please preprocess the data first.
Use the command: python3 DeepChromeHiC.py -p true -n [gene name]
For example: python3 DeepChromeHiC.py -p true -n AD2.po


=== Below is your input ===

args.model = onehot_embedding_cnn_two_branch
args.type = train
args.name = GM.pp
args.length = 10001
===========================


-> h5_weights/GM.pp folder already exist. pass.
-> result/GM.pp/onehot_cnn_one_branch folder already exist. pass.
-> result/GM.pp/onehot_cnn_two_branch folder already exist. pass.
-> result/GM.pp/onehot_embedding_dense folder already exist. pass.
-> result/GM.pp/onehot_dense folder already exist. pass.
-> result/GM.pp/onehot_resnet18 folder already exist. pass.
-> result/GM.pp/onehot_resnet34 folder already exist. pass.
-> result/GM.pp/embedding_cnn_one_branch folder already exist. pass.
-> result/GM.pp/embedding_cnn_two_branch folder already exist. pass.
-> result/GM.pp/embedding_dense folder already exist. pass.
-> result/GM.pp/onehot_embedding_cnn_one_branch folder already exist. pass.
-> result/GM.pp/onehot_embedding_cnn_two_branch folder already exist. pass.
########################################
gen_name
GM.pp
########################################

########################################
model_name
onehot_embedding_cnn_two_branch
########################################

Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 10001, 100)   409700      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 10001, 100)   409700      input_2[0][0]                    
__________________________________________________________________________________________________
sequential (Sequential)         (None, 77, 64)       205888      embedding[0][0]                  
__________________________________________________________________________________________________
sequential_1 (Sequential)       (None, 77, 64)       205888      embedding_1[0][0]                
__________________________________________________________________________________________________
flatten (Flatten)               (None, 4928)         0           sequential[0][0]                 
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 4928)         0           sequential_1[0][0]               
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 9856)         0           flatten[0][0]                    
                                                                 flatten_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 9856)         39424       concatenate[0][0]                
__________________________________________________________________________________________________
dropout (Dropout)               (None, 9856)         0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dense (Dense)                   (None, 512)          5046784     dropout[0][0]                    
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 512)          2048        dense[0][0]                      
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 512)          2048        dense_1[0][0]                    
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           activation_9[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_2[0][0]                  
==================================================================================================
Total params: 6,584,649
Trainable params: 6,561,865
Non-trainable params: 22,784
__________________________________________________________________________________________________
Epoch 1/500
140/140 - 20s - loss: 1.0489 - accuracy: 0.5034 - val_loss: 0.6913 - val_accuracy: 0.5326
Epoch 2/500
140/140 - 19s - loss: 1.0185 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5326
Epoch 3/500
140/140 - 19s - loss: 0.9666 - accuracy: 0.5121 - val_loss: 0.6964 - val_accuracy: 0.5326
Epoch 4/500
140/140 - 19s - loss: 0.9444 - accuracy: 0.5085 - val_loss: 0.6921 - val_accuracy: 0.5290
Epoch 5/500
140/140 - 19s - loss: 0.9152 - accuracy: 0.5219 - val_loss: 0.6981 - val_accuracy: 0.4982
Epoch 6/500
140/140 - 19s - loss: 0.8944 - accuracy: 0.5210 - val_loss: 0.7056 - val_accuracy: 0.4964
Epoch 7/500
140/140 - 19s - loss: 0.8837 - accuracy: 0.5262 - val_loss: 0.7045 - val_accuracy: 0.4909
Epoch 8/500
140/140 - 19s - loss: 0.8712 - accuracy: 0.5298 - val_loss: 0.7028 - val_accuracy: 0.5036
Epoch 9/500
140/140 - 19s - loss: 0.8343 - accuracy: 0.5316 - val_loss: 0.6975 - val_accuracy: 0.5091
Epoch 10/500
140/140 - 19s - loss: 0.8178 - accuracy: 0.5412 - val_loss: 0.6924 - val_accuracy: 0.5163
Epoch 11/500
140/140 - 19s - loss: 0.8099 - accuracy: 0.5432 - val_loss: 0.6888 - val_accuracy: 0.5308
Epoch 12/500
140/140 - 19s - loss: 0.8154 - accuracy: 0.5450 - val_loss: 0.6869 - val_accuracy: 0.5344
Epoch 13/500
140/140 - 19s - loss: 0.7855 - accuracy: 0.5600 - val_loss: 0.6847 - val_accuracy: 0.5380
Epoch 14/500
140/140 - 19s - loss: 0.7677 - accuracy: 0.5755 - val_loss: 0.6812 - val_accuracy: 0.5525
Epoch 15/500
140/140 - 19s - loss: 0.7887 - accuracy: 0.5589 - val_loss: 0.6786 - val_accuracy: 0.5525
Epoch 16/500
140/140 - 19s - loss: 0.7689 - accuracy: 0.5656 - val_loss: 0.6757 - val_accuracy: 0.5634
Epoch 17/500
140/140 - 19s - loss: 0.7453 - accuracy: 0.5846 - val_loss: 0.6733 - val_accuracy: 0.5670
Epoch 18/500
140/140 - 19s - loss: 0.7448 - accuracy: 0.5806 - val_loss: 0.6721 - val_accuracy: 0.5725
Epoch 19/500
140/140 - 19s - loss: 0.7478 - accuracy: 0.5773 - val_loss: 0.6696 - val_accuracy: 0.5833
Epoch 20/500
140/140 - 19s - loss: 0.7265 - accuracy: 0.5927 - val_loss: 0.6679 - val_accuracy: 0.5942
Epoch 21/500
140/140 - 19s - loss: 0.7220 - accuracy: 0.5963 - val_loss: 0.6658 - val_accuracy: 0.5978
Epoch 22/500
140/140 - 19s - loss: 0.7062 - accuracy: 0.6059 - val_loss: 0.6645 - val_accuracy: 0.6014
Epoch 23/500
140/140 - 19s - loss: 0.7000 - accuracy: 0.6073 - val_loss: 0.6629 - val_accuracy: 0.6033
Epoch 24/500
140/140 - 19s - loss: 0.7120 - accuracy: 0.6068 - val_loss: 0.6613 - val_accuracy: 0.6051
Epoch 25/500
140/140 - 19s - loss: 0.6975 - accuracy: 0.6144 - val_loss: 0.6601 - val_accuracy: 0.6069
Epoch 26/500
140/140 - 19s - loss: 0.6878 - accuracy: 0.6232 - val_loss: 0.6588 - val_accuracy: 0.6214
Epoch 27/500
140/140 - 19s - loss: 0.6841 - accuracy: 0.6249 - val_loss: 0.6576 - val_accuracy: 0.6178
Epoch 28/500
140/140 - 19s - loss: 0.6723 - accuracy: 0.6209 - val_loss: 0.6560 - val_accuracy: 0.6196
Epoch 29/500
140/140 - 19s - loss: 0.6739 - accuracy: 0.6279 - val_loss: 0.6547 - val_accuracy: 0.6214
Epoch 30/500
140/140 - 19s - loss: 0.6625 - accuracy: 0.6261 - val_loss: 0.6537 - val_accuracy: 0.6286
Epoch 31/500
140/140 - 19s - loss: 0.6530 - accuracy: 0.6469 - val_loss: 0.6527 - val_accuracy: 0.6232
Epoch 32/500
140/140 - 19s - loss: 0.6489 - accuracy: 0.6507 - val_loss: 0.6514 - val_accuracy: 0.6304
Epoch 33/500
140/140 - 19s - loss: 0.6502 - accuracy: 0.6494 - val_loss: 0.6506 - val_accuracy: 0.6286
Epoch 34/500
140/140 - 19s - loss: 0.6407 - accuracy: 0.6599 - val_loss: 0.6499 - val_accuracy: 0.6268
Epoch 35/500
140/140 - 19s - loss: 0.6407 - accuracy: 0.6652 - val_loss: 0.6485 - val_accuracy: 0.6377
Epoch 36/500
140/140 - 19s - loss: 0.6113 - accuracy: 0.6733 - val_loss: 0.6471 - val_accuracy: 0.6359
Epoch 37/500
140/140 - 19s - loss: 0.5962 - accuracy: 0.6861 - val_loss: 0.6466 - val_accuracy: 0.6359
Epoch 38/500
140/140 - 19s - loss: 0.5991 - accuracy: 0.6838 - val_loss: 0.6454 - val_accuracy: 0.6377
Epoch 39/500
140/140 - 19s - loss: 0.5912 - accuracy: 0.6919 - val_loss: 0.6449 - val_accuracy: 0.6359
Epoch 40/500
140/140 - 19s - loss: 0.6017 - accuracy: 0.6773 - val_loss: 0.6436 - val_accuracy: 0.6359
Epoch 41/500
140/140 - 19s - loss: 0.5916 - accuracy: 0.6908 - val_loss: 0.6435 - val_accuracy: 0.6431
Epoch 42/500
140/140 - 19s - loss: 0.5722 - accuracy: 0.7000 - val_loss: 0.6423 - val_accuracy: 0.6359
Epoch 43/500
140/140 - 19s - loss: 0.5662 - accuracy: 0.7109 - val_loss: 0.6418 - val_accuracy: 0.6395
Epoch 44/500
140/140 - 19s - loss: 0.5521 - accuracy: 0.7199 - val_loss: 0.6425 - val_accuracy: 0.6359
Epoch 45/500
140/140 - 19s - loss: 0.5548 - accuracy: 0.7152 - val_loss: 0.6419 - val_accuracy: 0.6377
Epoch 46/500
140/140 - 19s - loss: 0.5424 - accuracy: 0.7313 - val_loss: 0.6416 - val_accuracy: 0.6395
Epoch 47/500
140/140 - 19s - loss: 0.5484 - accuracy: 0.7206 - val_loss: 0.6406 - val_accuracy: 0.6449
Epoch 48/500
140/140 - 19s - loss: 0.5306 - accuracy: 0.7270 - val_loss: 0.6402 - val_accuracy: 0.6449
Epoch 49/500
140/140 - 19s - loss: 0.5153 - accuracy: 0.7494 - val_loss: 0.6408 - val_accuracy: 0.6467
Epoch 50/500
140/140 - 19s - loss: 0.5256 - accuracy: 0.7409 - val_loss: 0.6408 - val_accuracy: 0.6486
Epoch 51/500
140/140 - 19s - loss: 0.5162 - accuracy: 0.7436 - val_loss: 0.6420 - val_accuracy: 0.6558
Epoch 52/500
140/140 - 19s - loss: 0.4962 - accuracy: 0.7571 - val_loss: 0.6419 - val_accuracy: 0.6540
Epoch 53/500
140/140 - 19s - loss: 0.4835 - accuracy: 0.7631 - val_loss: 0.6418 - val_accuracy: 0.6504
Epoch 54/500
140/140 - 19s - loss: 0.4858 - accuracy: 0.7633 - val_loss: 0.6422 - val_accuracy: 0.6558
Epoch 55/500
140/140 - 19s - loss: 0.4748 - accuracy: 0.7750 - val_loss: 0.6435 - val_accuracy: 0.6576
Epoch 56/500
140/140 - 19s - loss: 0.4516 - accuracy: 0.7803 - val_loss: 0.6440 - val_accuracy: 0.6612
Epoch 57/500
140/140 - 19s - loss: 0.4698 - accuracy: 0.7721 - val_loss: 0.6440 - val_accuracy: 0.6594
Epoch 58/500
140/140 - 19s - loss: 0.4586 - accuracy: 0.7884 - val_loss: 0.6453 - val_accuracy: 0.6649
Epoch 59/500
140/140 - 19s - loss: 0.4464 - accuracy: 0.7913 - val_loss: 0.6468 - val_accuracy: 0.6630
Epoch 60/500
140/140 - 19s - loss: 0.4372 - accuracy: 0.7974 - val_loss: 0.6487 - val_accuracy: 0.6630
Epoch 61/500
140/140 - 19s - loss: 0.4270 - accuracy: 0.8018 - val_loss: 0.6493 - val_accuracy: 0.6630
Epoch 62/500
140/140 - 19s - loss: 0.4170 - accuracy: 0.8121 - val_loss: 0.6502 - val_accuracy: 0.6630
Epoch 63/500
140/140 - 19s - loss: 0.4124 - accuracy: 0.8103 - val_loss: 0.6512 - val_accuracy: 0.6612
Epoch 64/500
140/140 - 19s - loss: 0.4109 - accuracy: 0.8086 - val_loss: 0.6531 - val_accuracy: 0.6630
Epoch 65/500
140/140 - 19s - loss: 0.3921 - accuracy: 0.8202 - val_loss: 0.6537 - val_accuracy: 0.6630
Epoch 66/500
140/140 - 19s - loss: 0.3852 - accuracy: 0.8274 - val_loss: 0.6555 - val_accuracy: 0.6667
Epoch 67/500
140/140 - 19s - loss: 0.3915 - accuracy: 0.8307 - val_loss: 0.6565 - val_accuracy: 0.6649
Epoch 68/500
140/140 - 19s - loss: 0.3734 - accuracy: 0.8314 - val_loss: 0.6592 - val_accuracy: 0.6667
Epoch 69/500
140/140 - 19s - loss: 0.3720 - accuracy: 0.8300 - val_loss: 0.6588 - val_accuracy: 0.6630
Epoch 70/500
140/140 - 19s - loss: 0.3513 - accuracy: 0.8529 - val_loss: 0.6610 - val_accuracy: 0.6612
Epoch 71/500
140/140 - 19s - loss: 0.3496 - accuracy: 0.8448 - val_loss: 0.6632 - val_accuracy: 0.6630
Epoch 72/500
140/140 - 19s - loss: 0.3505 - accuracy: 0.8455 - val_loss: 0.6654 - val_accuracy: 0.6576
Epoch 73/500
140/140 - 19s - loss: 0.3401 - accuracy: 0.8518 - val_loss: 0.6664 - val_accuracy: 0.6594
Epoch 74/500
140/140 - 19s - loss: 0.3436 - accuracy: 0.8502 - val_loss: 0.6701 - val_accuracy: 0.6612
Epoch 75/500
140/140 - 19s - loss: 0.3296 - accuracy: 0.8560 - val_loss: 0.6712 - val_accuracy: 0.6594
Epoch 76/500
140/140 - 19s - loss: 0.3344 - accuracy: 0.8542 - val_loss: 0.6754 - val_accuracy: 0.6594
Epoch 77/500
140/140 - 19s - loss: 0.3257 - accuracy: 0.8574 - val_loss: 0.6762 - val_accuracy: 0.6576
Epoch 78/500
140/140 - 19s - loss: 0.3101 - accuracy: 0.8683 - val_loss: 0.6785 - val_accuracy: 0.6558
Epoch 79/500
140/140 - 19s - loss: 0.3060 - accuracy: 0.8746 - val_loss: 0.6809 - val_accuracy: 0.6522
Epoch 80/500
140/140 - 19s - loss: 0.3018 - accuracy: 0.8674 - val_loss: 0.6837 - val_accuracy: 0.6576
Epoch 81/500
140/140 - 19s - loss: 0.2951 - accuracy: 0.8730 - val_loss: 0.6880 - val_accuracy: 0.6594
Epoch 82/500
140/140 - 19s - loss: 0.2927 - accuracy: 0.8811 - val_loss: 0.6889 - val_accuracy: 0.6486
Epoch 83/500
140/140 - 19s - loss: 0.2874 - accuracy: 0.8795 - val_loss: 0.6924 - val_accuracy: 0.6540
Epoch 84/500
140/140 - 19s - loss: 0.2767 - accuracy: 0.8865 - val_loss: 0.6955 - val_accuracy: 0.6576
Epoch 85/500
140/140 - 19s - loss: 0.2725 - accuracy: 0.8883 - val_loss: 0.6986 - val_accuracy: 0.6558
Epoch 86/500
140/140 - 19s - loss: 0.2663 - accuracy: 0.8914 - val_loss: 0.7020 - val_accuracy: 0.6594
========================================
save_weights
h5_weights/GM.pp/onehot_embedding_cnn_two_branch.h5
========================================

end time >>> Sun Oct  3 05:49:34 2021

end time >>> Sun Oct  3 05:49:34 2021

end time >>> Sun Oct  3 05:49:34 2021

end time >>> Sun Oct  3 05:49:34 2021

end time >>> Sun Oct  3 05:49:34 2021












args.model = onehot_embedding_cnn_two_branch
time used = 1664.1174807548523


