************************************
************************************

    Welcome to use DeepChromeHiC

************************************
************************************

begin time >>> Mon Oct  4 14:10:59 2021

begin time >>> Mon Oct  4 14:10:59 2021

begin time >>> Mon Oct  4 14:10:59 2021

begin time >>> Mon Oct  4 14:10:59 2021

begin time >>> Mon Oct  4 14:10:59 2021



If it is the first time to use, please preprocess the data first.
Use the command: python3 DeepChromeHiC.py -p true -n [gene name]
For example: python3 DeepChromeHiC.py -p true -n AD2.po


=== Below is your input ===

args.model = embedding_dense
args.type = train
args.name = X5628FC.po
args.length = 10001
===========================


-> h5_weights/X5628FC.po folder already exist. pass.
-> result/X5628FC.po/onehot_cnn_one_branch folder already exist. pass.
-> result/X5628FC.po/onehot_cnn_two_branch folder already exist. pass.
-> result/X5628FC.po/onehot_embedding_dense folder already exist. pass.
-> result/X5628FC.po/onehot_dense folder already exist. pass.
-> result/X5628FC.po/onehot_resnet18 folder already exist. pass.
-> result/X5628FC.po/onehot_resnet34 folder already exist. pass.
-> result/X5628FC.po/embedding_cnn_one_branch folder already exist. pass.
-> result/X5628FC.po/embedding_cnn_two_branch folder already exist. pass.
-> result/X5628FC.po/embedding_dense folder already exist. pass.
-> result/X5628FC.po/onehot_embedding_cnn_one_branch folder already exist. pass.
-> result/X5628FC.po/onehot_embedding_cnn_two_branch folder already exist. pass.
########################################
gen_name
X5628FC.po
########################################

########################################
model_name
embedding_dense
########################################

Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 10001, 100)   409700      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 10001, 100)   409700      input_2[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 20002, 100)   0           embedding[0][0]                  
                                                                 embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 626, 64)      409664      concatenate[0][0]                
__________________________________________________________________________________________________
max_pooling1d (MaxPooling1D)    (None, 38, 64)       0           conv1d[0][0]                     
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 38, 64)       256         max_pooling1d[0][0]              
__________________________________________________________________________________________________
flatten (Flatten)               (None, 2432)         0           batch_normalization[0][0]        
__________________________________________________________________________________________________
dropout (Dropout)               (None, 2432)         0           flatten[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 512)          1245696     dropout[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        dense[0][0]                      
__________________________________________________________________________________________________
activation (Activation)         (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           activation[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 512)          2048        dense_1[0][0]                    
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 512)          0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 512)          262656      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 512)          2048        dense_2[0][0]                    
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 512)          0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           activation_2[0][0]               
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 3,006,985
Trainable params: 3,003,785
Non-trainable params: 3,200
__________________________________________________________________________________________________
Epoch 1/500
896/896 - 115s - loss: 0.9264 - accuracy: 0.5016 - val_loss: 0.7045 - val_accuracy: 0.4884
Epoch 2/500
896/896 - 115s - loss: 0.8726 - accuracy: 0.5078 - val_loss: 0.6999 - val_accuracy: 0.5034
Epoch 3/500
896/896 - 115s - loss: 0.8471 - accuracy: 0.5053 - val_loss: 0.6983 - val_accuracy: 0.5130
Epoch 4/500
896/896 - 115s - loss: 0.8514 - accuracy: 0.5000 - val_loss: 0.6971 - val_accuracy: 0.5155
Epoch 5/500
896/896 - 115s - loss: 0.8360 - accuracy: 0.5065 - val_loss: 0.6960 - val_accuracy: 0.5164
Epoch 6/500
896/896 - 115s - loss: 0.8418 - accuracy: 0.4977 - val_loss: 0.6954 - val_accuracy: 0.5167
Epoch 7/500
896/896 - 115s - loss: 0.8267 - accuracy: 0.5075 - val_loss: 0.6949 - val_accuracy: 0.5155
Epoch 8/500
896/896 - 115s - loss: 0.8269 - accuracy: 0.5023 - val_loss: 0.6941 - val_accuracy: 0.5155
Epoch 9/500
896/896 - 115s - loss: 0.8179 - accuracy: 0.5044 - val_loss: 0.6935 - val_accuracy: 0.5133
Epoch 10/500
896/896 - 114s - loss: 0.8192 - accuracy: 0.5074 - val_loss: 0.6928 - val_accuracy: 0.5186
Epoch 11/500
896/896 - 114s - loss: 0.8067 - accuracy: 0.5131 - val_loss: 0.6922 - val_accuracy: 0.5203
Epoch 12/500
896/896 - 114s - loss: 0.8051 - accuracy: 0.5133 - val_loss: 0.6918 - val_accuracy: 0.5251
Epoch 13/500
896/896 - 114s - loss: 0.8010 - accuracy: 0.5168 - val_loss: 0.6919 - val_accuracy: 0.5243
Epoch 14/500
896/896 - 114s - loss: 0.8094 - accuracy: 0.5046 - val_loss: 0.6912 - val_accuracy: 0.5305
Epoch 15/500
896/896 - 114s - loss: 0.8063 - accuracy: 0.5061 - val_loss: 0.6910 - val_accuracy: 0.5299
Epoch 16/500
896/896 - 114s - loss: 0.8026 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5285
Epoch 17/500
896/896 - 114s - loss: 0.7930 - accuracy: 0.5095 - val_loss: 0.6898 - val_accuracy: 0.5359
Epoch 18/500
896/896 - 115s - loss: 0.8017 - accuracy: 0.5057 - val_loss: 0.6897 - val_accuracy: 0.5339
Epoch 19/500
896/896 - 115s - loss: 0.7947 - accuracy: 0.5108 - val_loss: 0.6894 - val_accuracy: 0.5359
Epoch 20/500
896/896 - 115s - loss: 0.7943 - accuracy: 0.5092 - val_loss: 0.6890 - val_accuracy: 0.5327
Epoch 21/500
896/896 - 115s - loss: 0.7852 - accuracy: 0.5159 - val_loss: 0.6884 - val_accuracy: 0.5392
Epoch 22/500
896/896 - 115s - loss: 0.7879 - accuracy: 0.5143 - val_loss: 0.6880 - val_accuracy: 0.5418
Epoch 23/500
896/896 - 115s - loss: 0.7888 - accuracy: 0.5074 - val_loss: 0.6877 - val_accuracy: 0.5415
Epoch 24/500
896/896 - 115s - loss: 0.7877 - accuracy: 0.5118 - val_loss: 0.6874 - val_accuracy: 0.5418
Epoch 25/500
896/896 - 115s - loss: 0.7872 - accuracy: 0.5115 - val_loss: 0.6869 - val_accuracy: 0.5460
Epoch 26/500
896/896 - 115s - loss: 0.7832 - accuracy: 0.5125 - val_loss: 0.6863 - val_accuracy: 0.5443
Epoch 27/500
896/896 - 115s - loss: 0.7792 - accuracy: 0.5165 - val_loss: 0.6860 - val_accuracy: 0.5455
Epoch 28/500
896/896 - 115s - loss: 0.7785 - accuracy: 0.5146 - val_loss: 0.6853 - val_accuracy: 0.5556
Epoch 29/500
896/896 - 115s - loss: 0.7745 - accuracy: 0.5183 - val_loss: 0.6849 - val_accuracy: 0.5483
Epoch 30/500
896/896 - 115s - loss: 0.7766 - accuracy: 0.5183 - val_loss: 0.6847 - val_accuracy: 0.5500
Epoch 31/500
896/896 - 115s - loss: 0.7758 - accuracy: 0.5158 - val_loss: 0.6843 - val_accuracy: 0.5491
Epoch 32/500
896/896 - 115s - loss: 0.7694 - accuracy: 0.5242 - val_loss: 0.6838 - val_accuracy: 0.5483
Epoch 33/500
896/896 - 115s - loss: 0.7700 - accuracy: 0.5210 - val_loss: 0.6834 - val_accuracy: 0.5494
Epoch 34/500
896/896 - 115s - loss: 0.7698 - accuracy: 0.5187 - val_loss: 0.6825 - val_accuracy: 0.5528
Epoch 35/500
896/896 - 115s - loss: 0.7682 - accuracy: 0.5196 - val_loss: 0.6820 - val_accuracy: 0.5522
Epoch 36/500
896/896 - 115s - loss: 0.7695 - accuracy: 0.5207 - val_loss: 0.6808 - val_accuracy: 0.5584
Epoch 37/500
896/896 - 115s - loss: 0.7623 - accuracy: 0.5265 - val_loss: 0.6800 - val_accuracy: 0.5621
Epoch 38/500
896/896 - 115s - loss: 0.7645 - accuracy: 0.5229 - val_loss: 0.6800 - val_accuracy: 0.5556
Epoch 39/500
896/896 - 115s - loss: 0.7628 - accuracy: 0.5253 - val_loss: 0.6794 - val_accuracy: 0.5584
Epoch 40/500
896/896 - 115s - loss: 0.7610 - accuracy: 0.5244 - val_loss: 0.6789 - val_accuracy: 0.5593
Epoch 41/500
896/896 - 115s - loss: 0.7568 - accuracy: 0.5301 - val_loss: 0.6783 - val_accuracy: 0.5621
Epoch 42/500
896/896 - 115s - loss: 0.7507 - accuracy: 0.5325 - val_loss: 0.6768 - val_accuracy: 0.5706
Epoch 43/500
896/896 - 115s - loss: 0.7538 - accuracy: 0.5315 - val_loss: 0.6761 - val_accuracy: 0.5709
Epoch 44/500
896/896 - 114s - loss: 0.7533 - accuracy: 0.5342 - val_loss: 0.6754 - val_accuracy: 0.5683
Epoch 45/500
896/896 - 115s - loss: 0.7543 - accuracy: 0.5305 - val_loss: 0.6749 - val_accuracy: 0.5711
Epoch 46/500
896/896 - 115s - loss: 0.7512 - accuracy: 0.5350 - val_loss: 0.6735 - val_accuracy: 0.5759
Epoch 47/500
896/896 - 114s - loss: 0.7400 - accuracy: 0.5473 - val_loss: 0.6733 - val_accuracy: 0.5734
Epoch 48/500
896/896 - 115s - loss: 0.7489 - accuracy: 0.5417 - val_loss: 0.6716 - val_accuracy: 0.5774
Epoch 49/500
896/896 - 115s - loss: 0.7475 - accuracy: 0.5394 - val_loss: 0.6709 - val_accuracy: 0.5782
Epoch 50/500
896/896 - 115s - loss: 0.7365 - accuracy: 0.5489 - val_loss: 0.6694 - val_accuracy: 0.5805
Epoch 51/500
896/896 - 115s - loss: 0.7365 - accuracy: 0.5488 - val_loss: 0.6683 - val_accuracy: 0.5805
Epoch 52/500
896/896 - 114s - loss: 0.7341 - accuracy: 0.5519 - val_loss: 0.6679 - val_accuracy: 0.5805
Epoch 53/500
896/896 - 115s - loss: 0.7278 - accuracy: 0.5561 - val_loss: 0.6650 - val_accuracy: 0.5884
Epoch 54/500
896/896 - 114s - loss: 0.7261 - accuracy: 0.5575 - val_loss: 0.6641 - val_accuracy: 0.5920
Epoch 55/500
896/896 - 114s - loss: 0.7221 - accuracy: 0.5628 - val_loss: 0.6620 - val_accuracy: 0.5935
Epoch 56/500
896/896 - 115s - loss: 0.7234 - accuracy: 0.5604 - val_loss: 0.6605 - val_accuracy: 0.5951
Epoch 57/500
896/896 - 115s - loss: 0.7170 - accuracy: 0.5698 - val_loss: 0.6603 - val_accuracy: 0.5957
Epoch 58/500
896/896 - 115s - loss: 0.7112 - accuracy: 0.5734 - val_loss: 0.6579 - val_accuracy: 0.5985
Epoch 59/500
896/896 - 115s - loss: 0.7099 - accuracy: 0.5792 - val_loss: 0.6563 - val_accuracy: 0.6019
Epoch 60/500
896/896 - 115s - loss: 0.7122 - accuracy: 0.5743 - val_loss: 0.6557 - val_accuracy: 0.6019
Epoch 61/500
896/896 - 114s - loss: 0.7084 - accuracy: 0.5796 - val_loss: 0.6537 - val_accuracy: 0.6053
Epoch 62/500
896/896 - 114s - loss: 0.7065 - accuracy: 0.5820 - val_loss: 0.6519 - val_accuracy: 0.6081
Epoch 63/500
896/896 - 115s - loss: 0.7060 - accuracy: 0.5836 - val_loss: 0.6506 - val_accuracy: 0.6124
Epoch 64/500
896/896 - 115s - loss: 0.6972 - accuracy: 0.5897 - val_loss: 0.6479 - val_accuracy: 0.6194
Epoch 65/500
896/896 - 114s - loss: 0.6937 - accuracy: 0.5928 - val_loss: 0.6470 - val_accuracy: 0.6189
Epoch 66/500
896/896 - 114s - loss: 0.6878 - accuracy: 0.5979 - val_loss: 0.6448 - val_accuracy: 0.6222
Epoch 67/500
896/896 - 114s - loss: 0.6875 - accuracy: 0.6013 - val_loss: 0.6450 - val_accuracy: 0.6214
Epoch 68/500
896/896 - 114s - loss: 0.6858 - accuracy: 0.6028 - val_loss: 0.6437 - val_accuracy: 0.6206
Epoch 69/500
896/896 - 114s - loss: 0.6795 - accuracy: 0.6088 - val_loss: 0.6427 - val_accuracy: 0.6222
Epoch 70/500
896/896 - 114s - loss: 0.6760 - accuracy: 0.6127 - val_loss: 0.6402 - val_accuracy: 0.6270
Epoch 71/500
896/896 - 115s - loss: 0.6739 - accuracy: 0.6146 - val_loss: 0.6375 - val_accuracy: 0.6290
Epoch 72/500
896/896 - 115s - loss: 0.6662 - accuracy: 0.6259 - val_loss: 0.6376 - val_accuracy: 0.6282
Epoch 73/500
896/896 - 114s - loss: 0.6617 - accuracy: 0.6284 - val_loss: 0.6347 - val_accuracy: 0.6321
Epoch 74/500
896/896 - 114s - loss: 0.6589 - accuracy: 0.6287 - val_loss: 0.6349 - val_accuracy: 0.6316
Epoch 75/500
896/896 - 114s - loss: 0.6520 - accuracy: 0.6393 - val_loss: 0.6336 - val_accuracy: 0.6321
Epoch 76/500
896/896 - 114s - loss: 0.6531 - accuracy: 0.6401 - val_loss: 0.6300 - val_accuracy: 0.6381
Epoch 77/500
896/896 - 114s - loss: 0.6445 - accuracy: 0.6442 - val_loss: 0.6284 - val_accuracy: 0.6414
Epoch 78/500
896/896 - 115s - loss: 0.6458 - accuracy: 0.6460 - val_loss: 0.6288 - val_accuracy: 0.6443
Epoch 79/500
896/896 - 114s - loss: 0.6415 - accuracy: 0.6464 - val_loss: 0.6272 - val_accuracy: 0.6462
Epoch 80/500
896/896 - 114s - loss: 0.6371 - accuracy: 0.6555 - val_loss: 0.6272 - val_accuracy: 0.6454
Epoch 81/500
896/896 - 114s - loss: 0.6323 - accuracy: 0.6595 - val_loss: 0.6248 - val_accuracy: 0.6477
Epoch 82/500
896/896 - 114s - loss: 0.6334 - accuracy: 0.6586 - val_loss: 0.6223 - val_accuracy: 0.6505
Epoch 83/500
896/896 - 114s - loss: 0.6216 - accuracy: 0.6635 - val_loss: 0.6218 - val_accuracy: 0.6539
Epoch 84/500
896/896 - 114s - loss: 0.6201 - accuracy: 0.6674 - val_loss: 0.6228 - val_accuracy: 0.6530
Epoch 85/500
896/896 - 114s - loss: 0.6180 - accuracy: 0.6693 - val_loss: 0.6193 - val_accuracy: 0.6587
Epoch 86/500
896/896 - 114s - loss: 0.6113 - accuracy: 0.6739 - val_loss: 0.6193 - val_accuracy: 0.6578
Epoch 87/500
896/896 - 114s - loss: 0.6148 - accuracy: 0.6707 - val_loss: 0.6170 - val_accuracy: 0.6646
Epoch 88/500
896/896 - 114s - loss: 0.6016 - accuracy: 0.6823 - val_loss: 0.6163 - val_accuracy: 0.6637
Epoch 89/500
896/896 - 114s - loss: 0.6001 - accuracy: 0.6841 - val_loss: 0.6142 - val_accuracy: 0.6677
Epoch 90/500
896/896 - 114s - loss: 0.5942 - accuracy: 0.6894 - val_loss: 0.6127 - val_accuracy: 0.6714
Epoch 91/500
896/896 - 114s - loss: 0.5956 - accuracy: 0.6898 - val_loss: 0.6102 - val_accuracy: 0.6711
Epoch 92/500
896/896 - 115s - loss: 0.5902 - accuracy: 0.6951 - val_loss: 0.6143 - val_accuracy: 0.6685
Epoch 93/500
896/896 - 114s - loss: 0.5808 - accuracy: 0.6981 - val_loss: 0.6089 - val_accuracy: 0.6742
Epoch 94/500
896/896 - 115s - loss: 0.5834 - accuracy: 0.7004 - val_loss: 0.6100 - val_accuracy: 0.6745
Epoch 95/500
896/896 - 114s - loss: 0.5747 - accuracy: 0.7072 - val_loss: 0.6095 - val_accuracy: 0.6765
Epoch 96/500
896/896 - 114s - loss: 0.5737 - accuracy: 0.7079 - val_loss: 0.6073 - val_accuracy: 0.6767
Epoch 97/500
896/896 - 114s - loss: 0.5690 - accuracy: 0.7118 - val_loss: 0.6074 - val_accuracy: 0.6781
Epoch 98/500
896/896 - 114s - loss: 0.5660 - accuracy: 0.7125 - val_loss: 0.6076 - val_accuracy: 0.6801
Epoch 99/500
896/896 - 114s - loss: 0.5590 - accuracy: 0.7193 - val_loss: 0.6052 - val_accuracy: 0.6821
Epoch 100/500
896/896 - 114s - loss: 0.5538 - accuracy: 0.7197 - val_loss: 0.6070 - val_accuracy: 0.6827
Epoch 101/500
896/896 - 114s - loss: 0.5554 - accuracy: 0.7219 - val_loss: 0.6043 - val_accuracy: 0.6852
Epoch 102/500
896/896 - 114s - loss: 0.5486 - accuracy: 0.7274 - val_loss: 0.6033 - val_accuracy: 0.6869
Epoch 103/500
896/896 - 114s - loss: 0.5418 - accuracy: 0.7311 - val_loss: 0.6058 - val_accuracy: 0.6863
Epoch 104/500
896/896 - 114s - loss: 0.5397 - accuracy: 0.7292 - val_loss: 0.6039 - val_accuracy: 0.6877
Epoch 105/500
896/896 - 114s - loss: 0.5332 - accuracy: 0.7355 - val_loss: 0.6018 - val_accuracy: 0.6897
Epoch 106/500
896/896 - 114s - loss: 0.5321 - accuracy: 0.7359 - val_loss: 0.5988 - val_accuracy: 0.6925
Epoch 107/500
896/896 - 114s - loss: 0.5326 - accuracy: 0.7389 - val_loss: 0.6047 - val_accuracy: 0.6883
Epoch 108/500
896/896 - 114s - loss: 0.5275 - accuracy: 0.7398 - val_loss: 0.6005 - val_accuracy: 0.6917
Epoch 109/500
896/896 - 114s - loss: 0.5192 - accuracy: 0.7485 - val_loss: 0.6017 - val_accuracy: 0.6914
Epoch 110/500
896/896 - 114s - loss: 0.5204 - accuracy: 0.7479 - val_loss: 0.5992 - val_accuracy: 0.6934
Epoch 111/500
896/896 - 114s - loss: 0.5091 - accuracy: 0.7539 - val_loss: 0.6025 - val_accuracy: 0.6917
Epoch 112/500
896/896 - 114s - loss: 0.5138 - accuracy: 0.7521 - val_loss: 0.6007 - val_accuracy: 0.6945
Epoch 113/500
896/896 - 115s - loss: 0.4994 - accuracy: 0.7597 - val_loss: 0.6002 - val_accuracy: 0.6954
Epoch 114/500
896/896 - 114s - loss: 0.4986 - accuracy: 0.7606 - val_loss: 0.6029 - val_accuracy: 0.6954
Epoch 115/500
896/896 - 114s - loss: 0.4959 - accuracy: 0.7628 - val_loss: 0.6025 - val_accuracy: 0.6968
Epoch 116/500
896/896 - 114s - loss: 0.4954 - accuracy: 0.7615 - val_loss: 0.5984 - val_accuracy: 0.6996
Epoch 117/500
896/896 - 114s - loss: 0.4925 - accuracy: 0.7663 - val_loss: 0.6004 - val_accuracy: 0.7007
Epoch 118/500
896/896 - 114s - loss: 0.4897 - accuracy: 0.7654 - val_loss: 0.5983 - val_accuracy: 0.7027
Epoch 119/500
896/896 - 114s - loss: 0.4831 - accuracy: 0.7721 - val_loss: 0.6023 - val_accuracy: 0.6990
Epoch 120/500
896/896 - 114s - loss: 0.4855 - accuracy: 0.7689 - val_loss: 0.6032 - val_accuracy: 0.7005
Epoch 121/500
896/896 - 114s - loss: 0.4786 - accuracy: 0.7706 - val_loss: 0.6051 - val_accuracy: 0.7005
Epoch 122/500
896/896 - 114s - loss: 0.4751 - accuracy: 0.7758 - val_loss: 0.5980 - val_accuracy: 0.7047
Epoch 123/500
896/896 - 114s - loss: 0.4763 - accuracy: 0.7742 - val_loss: 0.6007 - val_accuracy: 0.7033
Epoch 124/500
896/896 - 115s - loss: 0.4677 - accuracy: 0.7778 - val_loss: 0.5999 - val_accuracy: 0.7055
Epoch 125/500
896/896 - 114s - loss: 0.4648 - accuracy: 0.7834 - val_loss: 0.6036 - val_accuracy: 0.7053
Epoch 126/500
896/896 - 114s - loss: 0.4591 - accuracy: 0.7854 - val_loss: 0.6050 - val_accuracy: 0.7038
Epoch 127/500
896/896 - 114s - loss: 0.4600 - accuracy: 0.7857 - val_loss: 0.5988 - val_accuracy: 0.7044
Epoch 128/500
896/896 - 113s - loss: 0.4548 - accuracy: 0.7895 - val_loss: 0.6034 - val_accuracy: 0.7055
Epoch 129/500
896/896 - 114s - loss: 0.4556 - accuracy: 0.7879 - val_loss: 0.6046 - val_accuracy: 0.7075
Epoch 130/500
896/896 - 114s - loss: 0.4506 - accuracy: 0.7902 - val_loss: 0.6048 - val_accuracy: 0.7075
Epoch 131/500
896/896 - 114s - loss: 0.4452 - accuracy: 0.7919 - val_loss: 0.6056 - val_accuracy: 0.7075
Epoch 132/500
896/896 - 114s - loss: 0.4420 - accuracy: 0.7970 - val_loss: 0.5999 - val_accuracy: 0.7081
Epoch 133/500
896/896 - 114s - loss: 0.4408 - accuracy: 0.8002 - val_loss: 0.6070 - val_accuracy: 0.7064
Epoch 134/500
896/896 - 113s - loss: 0.4321 - accuracy: 0.8015 - val_loss: 0.6033 - val_accuracy: 0.7089
Epoch 135/500
896/896 - 114s - loss: 0.4290 - accuracy: 0.8037 - val_loss: 0.6058 - val_accuracy: 0.7095
Epoch 136/500
896/896 - 114s - loss: 0.4278 - accuracy: 0.8058 - val_loss: 0.6123 - val_accuracy: 0.7058
Epoch 137/500
896/896 - 114s - loss: 0.4244 - accuracy: 0.8065 - val_loss: 0.6061 - val_accuracy: 0.7081
Epoch 138/500
896/896 - 114s - loss: 0.4233 - accuracy: 0.8112 - val_loss: 0.6070 - val_accuracy: 0.7081
Epoch 139/500
896/896 - 114s - loss: 0.4194 - accuracy: 0.8098 - val_loss: 0.6078 - val_accuracy: 0.7081
Epoch 140/500
896/896 - 114s - loss: 0.4210 - accuracy: 0.8112 - val_loss: 0.6096 - val_accuracy: 0.7089
Epoch 141/500
896/896 - 114s - loss: 0.4156 - accuracy: 0.8139 - val_loss: 0.6070 - val_accuracy: 0.7098
Epoch 142/500
896/896 - 114s - loss: 0.4161 - accuracy: 0.8104 - val_loss: 0.6103 - val_accuracy: 0.7086
Epoch 143/500
896/896 - 114s - loss: 0.4141 - accuracy: 0.8111 - val_loss: 0.6084 - val_accuracy: 0.7064
Epoch 144/500
896/896 - 114s - loss: 0.4047 - accuracy: 0.8193 - val_loss: 0.6107 - val_accuracy: 0.7069
Epoch 145/500
896/896 - 114s - loss: 0.4022 - accuracy: 0.8202 - val_loss: 0.6092 - val_accuracy: 0.7078
Epoch 146/500
896/896 - 114s - loss: 0.4019 - accuracy: 0.8190 - val_loss: 0.6123 - val_accuracy: 0.7075
Epoch 147/500
896/896 - 114s - loss: 0.3932 - accuracy: 0.8237 - val_loss: 0.6120 - val_accuracy: 0.7075
Epoch 148/500
896/896 - 114s - loss: 0.3921 - accuracy: 0.8259 - val_loss: 0.6142 - val_accuracy: 0.7095
Epoch 149/500
896/896 - 114s - loss: 0.3924 - accuracy: 0.8249 - val_loss: 0.6119 - val_accuracy: 0.7095
Epoch 150/500
896/896 - 114s - loss: 0.3857 - accuracy: 0.8308 - val_loss: 0.6198 - val_accuracy: 0.7084
Epoch 151/500
896/896 - 114s - loss: 0.3883 - accuracy: 0.8278 - val_loss: 0.6177 - val_accuracy: 0.7098
Epoch 152/500
896/896 - 114s - loss: 0.3832 - accuracy: 0.8291 - val_loss: 0.6191 - val_accuracy: 0.7103
Epoch 153/500
896/896 - 114s - loss: 0.3767 - accuracy: 0.8333 - val_loss: 0.6159 - val_accuracy: 0.7137
Epoch 154/500
896/896 - 114s - loss: 0.3787 - accuracy: 0.8299 - val_loss: 0.6181 - val_accuracy: 0.7123
Epoch 155/500
896/896 - 114s - loss: 0.3718 - accuracy: 0.8371 - val_loss: 0.6184 - val_accuracy: 0.7134
Epoch 156/500
896/896 - 114s - loss: 0.3720 - accuracy: 0.8380 - val_loss: 0.6216 - val_accuracy: 0.7134
Epoch 157/500
896/896 - 114s - loss: 0.3678 - accuracy: 0.8374 - val_loss: 0.6216 - val_accuracy: 0.7140
Epoch 158/500
896/896 - 114s - loss: 0.3617 - accuracy: 0.8424 - val_loss: 0.6219 - val_accuracy: 0.7134
Epoch 159/500
896/896 - 114s - loss: 0.3645 - accuracy: 0.8390 - val_loss: 0.6215 - val_accuracy: 0.7137
Epoch 160/500
896/896 - 114s - loss: 0.3557 - accuracy: 0.8439 - val_loss: 0.6287 - val_accuracy: 0.7149
Epoch 161/500
896/896 - 114s - loss: 0.3598 - accuracy: 0.8418 - val_loss: 0.6250 - val_accuracy: 0.7143
Epoch 162/500
896/896 - 114s - loss: 0.3547 - accuracy: 0.8464 - val_loss: 0.6291 - val_accuracy: 0.7154
Epoch 163/500
896/896 - 114s - loss: 0.3528 - accuracy: 0.8475 - val_loss: 0.6274 - val_accuracy: 0.7168
Epoch 164/500
896/896 - 113s - loss: 0.3533 - accuracy: 0.8448 - val_loss: 0.6300 - val_accuracy: 0.7157
Epoch 165/500
896/896 - 114s - loss: 0.3435 - accuracy: 0.8496 - val_loss: 0.6317 - val_accuracy: 0.7160
Epoch 166/500
896/896 - 114s - loss: 0.3533 - accuracy: 0.8453 - val_loss: 0.6362 - val_accuracy: 0.7134
Epoch 167/500
896/896 - 114s - loss: 0.3441 - accuracy: 0.8520 - val_loss: 0.6314 - val_accuracy: 0.7168
Epoch 168/500
896/896 - 114s - loss: 0.3447 - accuracy: 0.8493 - val_loss: 0.6364 - val_accuracy: 0.7157
Epoch 169/500
896/896 - 114s - loss: 0.3310 - accuracy: 0.8586 - val_loss: 0.6366 - val_accuracy: 0.7165
Epoch 170/500
896/896 - 114s - loss: 0.3385 - accuracy: 0.8525 - val_loss: 0.6364 - val_accuracy: 0.7160
Epoch 171/500
896/896 - 114s - loss: 0.3344 - accuracy: 0.8555 - val_loss: 0.6389 - val_accuracy: 0.7140
Epoch 172/500
896/896 - 114s - loss: 0.3254 - accuracy: 0.8594 - val_loss: 0.6360 - val_accuracy: 0.7177
Epoch 173/500
896/896 - 114s - loss: 0.3260 - accuracy: 0.8605 - val_loss: 0.6409 - val_accuracy: 0.7165
Epoch 174/500
896/896 - 114s - loss: 0.3228 - accuracy: 0.8603 - val_loss: 0.6414 - val_accuracy: 0.7157
Epoch 175/500
896/896 - 114s - loss: 0.3203 - accuracy: 0.8636 - val_loss: 0.6473 - val_accuracy: 0.7157
Epoch 176/500
896/896 - 114s - loss: 0.3244 - accuracy: 0.8584 - val_loss: 0.6390 - val_accuracy: 0.7174
Epoch 177/500
896/896 - 114s - loss: 0.3151 - accuracy: 0.8663 - val_loss: 0.6475 - val_accuracy: 0.7157
Epoch 178/500
896/896 - 114s - loss: 0.3163 - accuracy: 0.8644 - val_loss: 0.6494 - val_accuracy: 0.7151
Epoch 179/500
896/896 - 114s - loss: 0.3069 - accuracy: 0.8683 - val_loss: 0.6481 - val_accuracy: 0.7180
Epoch 180/500
896/896 - 114s - loss: 0.3107 - accuracy: 0.8659 - val_loss: 0.6514 - val_accuracy: 0.7160
Epoch 181/500
896/896 - 114s - loss: 0.3048 - accuracy: 0.8707 - val_loss: 0.6507 - val_accuracy: 0.7160
Epoch 182/500
896/896 - 114s - loss: 0.3075 - accuracy: 0.8685 - val_loss: 0.6539 - val_accuracy: 0.7160
Epoch 183/500
896/896 - 114s - loss: 0.3030 - accuracy: 0.8708 - val_loss: 0.6588 - val_accuracy: 0.7165
Epoch 184/500
896/896 - 114s - loss: 0.3022 - accuracy: 0.8685 - val_loss: 0.6574 - val_accuracy: 0.7165
Epoch 185/500
896/896 - 114s - loss: 0.2946 - accuracy: 0.8734 - val_loss: 0.6587 - val_accuracy: 0.7174
Epoch 186/500
896/896 - 114s - loss: 0.2969 - accuracy: 0.8737 - val_loss: 0.6640 - val_accuracy: 0.7163
Epoch 187/500
896/896 - 114s - loss: 0.2932 - accuracy: 0.8751 - val_loss: 0.6604 - val_accuracy: 0.7194
Epoch 188/500
896/896 - 113s - loss: 0.2945 - accuracy: 0.8759 - val_loss: 0.6645 - val_accuracy: 0.7168
Epoch 189/500
896/896 - 114s - loss: 0.2991 - accuracy: 0.8738 - val_loss: 0.6696 - val_accuracy: 0.7163
Epoch 190/500
896/896 - 114s - loss: 0.2891 - accuracy: 0.8776 - val_loss: 0.6626 - val_accuracy: 0.7216
Epoch 191/500
896/896 - 114s - loss: 0.2874 - accuracy: 0.8763 - val_loss: 0.6685 - val_accuracy: 0.7202
Epoch 192/500
896/896 - 114s - loss: 0.2805 - accuracy: 0.8820 - val_loss: 0.6644 - val_accuracy: 0.7194
Epoch 193/500
896/896 - 114s - loss: 0.2842 - accuracy: 0.8799 - val_loss: 0.6672 - val_accuracy: 0.7205
Epoch 194/500
896/896 - 114s - loss: 0.2821 - accuracy: 0.8802 - val_loss: 0.6684 - val_accuracy: 0.7205
Epoch 195/500
896/896 - 114s - loss: 0.2738 - accuracy: 0.8853 - val_loss: 0.6761 - val_accuracy: 0.7182
Epoch 196/500
896/896 - 114s - loss: 0.2792 - accuracy: 0.8828 - val_loss: 0.6708 - val_accuracy: 0.7211
Epoch 197/500
896/896 - 114s - loss: 0.2711 - accuracy: 0.8844 - val_loss: 0.6767 - val_accuracy: 0.7185
Epoch 198/500
896/896 - 114s - loss: 0.2763 - accuracy: 0.8827 - val_loss: 0.6733 - val_accuracy: 0.7211
Epoch 199/500
896/896 - 114s - loss: 0.2720 - accuracy: 0.8880 - val_loss: 0.6781 - val_accuracy: 0.7182
Epoch 200/500
896/896 - 114s - loss: 0.2654 - accuracy: 0.8895 - val_loss: 0.6804 - val_accuracy: 0.7191
Epoch 201/500
896/896 - 114s - loss: 0.2606 - accuracy: 0.8919 - val_loss: 0.6852 - val_accuracy: 0.7171
Epoch 202/500
896/896 - 114s - loss: 0.2617 - accuracy: 0.8917 - val_loss: 0.6827 - val_accuracy: 0.7194
Epoch 203/500
896/896 - 114s - loss: 0.2626 - accuracy: 0.8907 - val_loss: 0.6833 - val_accuracy: 0.7202
Epoch 204/500
896/896 - 114s - loss: 0.2592 - accuracy: 0.8910 - val_loss: 0.6865 - val_accuracy: 0.7188
Epoch 205/500
896/896 - 114s - loss: 0.2575 - accuracy: 0.8932 - val_loss: 0.6874 - val_accuracy: 0.7188
Epoch 206/500
896/896 - 113s - loss: 0.2536 - accuracy: 0.8930 - val_loss: 0.6858 - val_accuracy: 0.7194
Epoch 207/500
896/896 - 114s - loss: 0.2540 - accuracy: 0.8948 - val_loss: 0.6941 - val_accuracy: 0.7188
Epoch 208/500
896/896 - 114s - loss: 0.2499 - accuracy: 0.8953 - val_loss: 0.6961 - val_accuracy: 0.7188
Epoch 209/500
896/896 - 114s - loss: 0.2546 - accuracy: 0.8949 - val_loss: 0.6930 - val_accuracy: 0.7194
Epoch 210/500
896/896 - 114s - loss: 0.2493 - accuracy: 0.8962 - val_loss: 0.6918 - val_accuracy: 0.7202
========================================
save_weights
h5_weights/X5628FC.po/embedding_dense.h5
========================================

end time >>> Mon Oct  4 20:51:52 2021

end time >>> Mon Oct  4 20:51:52 2021

end time >>> Mon Oct  4 20:51:52 2021

end time >>> Mon Oct  4 20:51:52 2021

end time >>> Mon Oct  4 20:51:52 2021












args.model = embedding_dense
time used = 24053.45000767708


************************************
************************************

    Welcome to use DeepChromeHiC

************************************
************************************

begin time >>> Mon Oct  4 20:51:53 2021

begin time >>> Mon Oct  4 20:51:53 2021

begin time >>> Mon Oct  4 20:51:53 2021

begin time >>> Mon Oct  4 20:51:53 2021

begin time >>> Mon Oct  4 20:51:53 2021



If it is the first time to use, please preprocess the data first.
Use the command: python3 DeepChromeHiC.py -p true -n [gene name]
For example: python3 DeepChromeHiC.py -p true -n AD2.po


=== Below is your input ===

args.model = embedding_cnn_one_branch
args.type = train
args.name = X5628FC.po
args.length = 10001
===========================


-> h5_weights/X5628FC.po folder already exist. pass.
-> result/X5628FC.po/onehot_cnn_one_branch folder already exist. pass.
-> result/X5628FC.po/onehot_cnn_two_branch folder already exist. pass.
-> result/X5628FC.po/onehot_embedding_dense folder already exist. pass.
-> result/X5628FC.po/onehot_dense folder already exist. pass.
-> result/X5628FC.po/onehot_resnet18 folder already exist. pass.
-> result/X5628FC.po/onehot_resnet34 folder already exist. pass.
-> result/X5628FC.po/embedding_cnn_one_branch folder already exist. pass.
-> result/X5628FC.po/embedding_cnn_two_branch folder already exist. pass.
-> result/X5628FC.po/embedding_dense folder already exist. pass.
-> result/X5628FC.po/onehot_embedding_cnn_one_branch folder already exist. pass.
-> result/X5628FC.po/onehot_embedding_cnn_two_branch folder already exist. pass.
########################################
gen_name
X5628FC.po
########################################

########################################
model_name
embedding_cnn_one_branch
########################################

Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 10001, 100)   409700      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 10001, 100)   409700      input_2[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 20002, 100)   0           embedding[0][0]                  
                                                                 embedding_1[0][0]                
__________________________________________________________________________________________________
sequential (Sequential)         (None, 155, 64)      205888      concatenate[0][0]                
__________________________________________________________________________________________________
flatten (Flatten)               (None, 9920)         0           sequential[0][0]                 
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 9920)         39680       flatten[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 9920)         0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dense (Dense)                   (None, 512)          5079552     dropout[0][0]                    
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 512)          2048        dense[0][0]                      
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 512)          0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           activation_4[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 512)          2048        dense_1[0][0]                    
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 512)          0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           activation_5[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_2[0][0]                  
==================================================================================================
Total params: 6,411,785
Trainable params: 6,389,385
Non-trainable params: 22,400
__________________________________________________________________________________________________
Epoch 1/500
896/896 - 119s - loss: 0.8986 - accuracy: 0.5000 - val_loss: 0.7217 - val_accuracy: 0.5093
Epoch 2/500
896/896 - 119s - loss: 0.8614 - accuracy: 0.5068 - val_loss: 0.7075 - val_accuracy: 0.5198
Epoch 3/500
896/896 - 119s - loss: 0.8374 - accuracy: 0.5164 - val_loss: 0.6993 - val_accuracy: 0.5282
Epoch 4/500
896/896 - 119s - loss: 0.8374 - accuracy: 0.5138 - val_loss: 0.6945 - val_accuracy: 0.5367
Epoch 5/500
896/896 - 119s - loss: 0.8214 - accuracy: 0.5223 - val_loss: 0.6902 - val_accuracy: 0.5452
Epoch 6/500
896/896 - 119s - loss: 0.8178 - accuracy: 0.5236 - val_loss: 0.6855 - val_accuracy: 0.5562
Epoch 7/500
896/896 - 119s - loss: 0.8046 - accuracy: 0.5302 - val_loss: 0.6824 - val_accuracy: 0.5601
Epoch 8/500
896/896 - 118s - loss: 0.7982 - accuracy: 0.5279 - val_loss: 0.6785 - val_accuracy: 0.5658
Epoch 9/500
896/896 - 119s - loss: 0.7932 - accuracy: 0.5355 - val_loss: 0.6757 - val_accuracy: 0.5678
Epoch 10/500
896/896 - 118s - loss: 0.7865 - accuracy: 0.5393 - val_loss: 0.6730 - val_accuracy: 0.5728
Epoch 11/500
896/896 - 118s - loss: 0.7874 - accuracy: 0.5404 - val_loss: 0.6708 - val_accuracy: 0.5765
Epoch 12/500
896/896 - 118s - loss: 0.7795 - accuracy: 0.5429 - val_loss: 0.6672 - val_accuracy: 0.5830
Epoch 13/500
896/896 - 118s - loss: 0.7662 - accuracy: 0.5504 - val_loss: 0.6645 - val_accuracy: 0.5844
Epoch 14/500
896/896 - 119s - loss: 0.7720 - accuracy: 0.5512 - val_loss: 0.6631 - val_accuracy: 0.5870
Epoch 15/500
896/896 - 118s - loss: 0.7589 - accuracy: 0.5593 - val_loss: 0.6604 - val_accuracy: 0.5915
Epoch 16/500
896/896 - 118s - loss: 0.7534 - accuracy: 0.5616 - val_loss: 0.6584 - val_accuracy: 0.5937
Epoch 17/500
896/896 - 118s - loss: 0.7476 - accuracy: 0.5675 - val_loss: 0.6560 - val_accuracy: 0.5977
Epoch 18/500
896/896 - 118s - loss: 0.7434 - accuracy: 0.5718 - val_loss: 0.6535 - val_accuracy: 0.6028
Epoch 19/500
896/896 - 118s - loss: 0.7355 - accuracy: 0.5781 - val_loss: 0.6512 - val_accuracy: 0.6093
Epoch 20/500
896/896 - 118s - loss: 0.7336 - accuracy: 0.5812 - val_loss: 0.6488 - val_accuracy: 0.6146
Epoch 21/500
896/896 - 118s - loss: 0.7206 - accuracy: 0.5884 - val_loss: 0.6467 - val_accuracy: 0.6200
Epoch 22/500
896/896 - 118s - loss: 0.7144 - accuracy: 0.5938 - val_loss: 0.6440 - val_accuracy: 0.6248
Epoch 23/500
896/896 - 118s - loss: 0.7123 - accuracy: 0.5975 - val_loss: 0.6418 - val_accuracy: 0.6287
Epoch 24/500
896/896 - 118s - loss: 0.7133 - accuracy: 0.5980 - val_loss: 0.6389 - val_accuracy: 0.6299
Epoch 25/500
896/896 - 118s - loss: 0.7058 - accuracy: 0.6004 - val_loss: 0.6369 - val_accuracy: 0.6333
Epoch 26/500
896/896 - 118s - loss: 0.6927 - accuracy: 0.6091 - val_loss: 0.6336 - val_accuracy: 0.6369
Epoch 27/500
896/896 - 118s - loss: 0.6903 - accuracy: 0.6149 - val_loss: 0.6327 - val_accuracy: 0.6400
Epoch 28/500
896/896 - 118s - loss: 0.6810 - accuracy: 0.6212 - val_loss: 0.6302 - val_accuracy: 0.6434
Epoch 29/500
896/896 - 118s - loss: 0.6816 - accuracy: 0.6233 - val_loss: 0.6284 - val_accuracy: 0.6431
Epoch 30/500
896/896 - 118s - loss: 0.6678 - accuracy: 0.6318 - val_loss: 0.6265 - val_accuracy: 0.6457
Epoch 31/500
896/896 - 118s - loss: 0.6647 - accuracy: 0.6376 - val_loss: 0.6242 - val_accuracy: 0.6494
Epoch 32/500
896/896 - 118s - loss: 0.6578 - accuracy: 0.6449 - val_loss: 0.6231 - val_accuracy: 0.6508
Epoch 33/500
896/896 - 118s - loss: 0.6518 - accuracy: 0.6513 - val_loss: 0.6221 - val_accuracy: 0.6508
Epoch 34/500
896/896 - 118s - loss: 0.6507 - accuracy: 0.6480 - val_loss: 0.6191 - val_accuracy: 0.6564
Epoch 35/500
896/896 - 118s - loss: 0.6361 - accuracy: 0.6597 - val_loss: 0.6184 - val_accuracy: 0.6573
Epoch 36/500
896/896 - 118s - loss: 0.6434 - accuracy: 0.6563 - val_loss: 0.6170 - val_accuracy: 0.6629
Epoch 37/500
896/896 - 118s - loss: 0.6239 - accuracy: 0.6675 - val_loss: 0.6154 - val_accuracy: 0.6657
Epoch 38/500
896/896 - 118s - loss: 0.6283 - accuracy: 0.6672 - val_loss: 0.6148 - val_accuracy: 0.6660
Epoch 39/500
896/896 - 118s - loss: 0.6187 - accuracy: 0.6766 - val_loss: 0.6146 - val_accuracy: 0.6674
Epoch 40/500
896/896 - 118s - loss: 0.6156 - accuracy: 0.6808 - val_loss: 0.6116 - val_accuracy: 0.6683
Epoch 41/500
896/896 - 118s - loss: 0.6063 - accuracy: 0.6813 - val_loss: 0.6104 - val_accuracy: 0.6697
Epoch 42/500
896/896 - 118s - loss: 0.6050 - accuracy: 0.6849 - val_loss: 0.6101 - val_accuracy: 0.6717
Epoch 43/500
896/896 - 118s - loss: 0.5993 - accuracy: 0.6905 - val_loss: 0.6093 - val_accuracy: 0.6702
Epoch 44/500
896/896 - 118s - loss: 0.5971 - accuracy: 0.6962 - val_loss: 0.6096 - val_accuracy: 0.6722
Epoch 45/500
896/896 - 118s - loss: 0.5846 - accuracy: 0.7037 - val_loss: 0.6093 - val_accuracy: 0.6731
Epoch 46/500
896/896 - 118s - loss: 0.5848 - accuracy: 0.7015 - val_loss: 0.6070 - val_accuracy: 0.6756
Epoch 47/500
896/896 - 118s - loss: 0.5801 - accuracy: 0.7070 - val_loss: 0.6074 - val_accuracy: 0.6756
Epoch 48/500
896/896 - 118s - loss: 0.5731 - accuracy: 0.7105 - val_loss: 0.6066 - val_accuracy: 0.6770
Epoch 49/500
896/896 - 118s - loss: 0.5671 - accuracy: 0.7111 - val_loss: 0.6068 - val_accuracy: 0.6759
Epoch 50/500
896/896 - 118s - loss: 0.5619 - accuracy: 0.7204 - val_loss: 0.6069 - val_accuracy: 0.6762
Epoch 51/500
896/896 - 118s - loss: 0.5529 - accuracy: 0.7247 - val_loss: 0.6062 - val_accuracy: 0.6790
Epoch 52/500
896/896 - 118s - loss: 0.5507 - accuracy: 0.7267 - val_loss: 0.6056 - val_accuracy: 0.6804
Epoch 53/500
896/896 - 118s - loss: 0.5485 - accuracy: 0.7293 - val_loss: 0.6040 - val_accuracy: 0.6813
Epoch 54/500
896/896 - 118s - loss: 0.5448 - accuracy: 0.7316 - val_loss: 0.6062 - val_accuracy: 0.6801
Epoch 55/500
896/896 - 118s - loss: 0.5332 - accuracy: 0.7349 - val_loss: 0.6062 - val_accuracy: 0.6838
Epoch 56/500
896/896 - 118s - loss: 0.5340 - accuracy: 0.7367 - val_loss: 0.6059 - val_accuracy: 0.6832
Epoch 57/500
896/896 - 118s - loss: 0.5282 - accuracy: 0.7435 - val_loss: 0.6051 - val_accuracy: 0.6838
Epoch 58/500
896/896 - 118s - loss: 0.5269 - accuracy: 0.7449 - val_loss: 0.6056 - val_accuracy: 0.6877
Epoch 59/500
896/896 - 118s - loss: 0.5198 - accuracy: 0.7488 - val_loss: 0.6077 - val_accuracy: 0.6858
Epoch 60/500
896/896 - 118s - loss: 0.5143 - accuracy: 0.7539 - val_loss: 0.6065 - val_accuracy: 0.6846
Epoch 61/500
896/896 - 118s - loss: 0.5085 - accuracy: 0.7540 - val_loss: 0.6064 - val_accuracy: 0.6861
Epoch 62/500
896/896 - 118s - loss: 0.5117 - accuracy: 0.7569 - val_loss: 0.6077 - val_accuracy: 0.6883
Epoch 63/500
896/896 - 118s - loss: 0.5125 - accuracy: 0.7517 - val_loss: 0.6078 - val_accuracy: 0.6897
Epoch 64/500
896/896 - 118s - loss: 0.5085 - accuracy: 0.7586 - val_loss: 0.6066 - val_accuracy: 0.6914
Epoch 65/500
896/896 - 118s - loss: 0.4900 - accuracy: 0.7657 - val_loss: 0.6075 - val_accuracy: 0.6903
Epoch 66/500
896/896 - 118s - loss: 0.4894 - accuracy: 0.7679 - val_loss: 0.6084 - val_accuracy: 0.6931
Epoch 67/500
896/896 - 118s - loss: 0.4827 - accuracy: 0.7715 - val_loss: 0.6095 - val_accuracy: 0.6914
Epoch 68/500
896/896 - 118s - loss: 0.4837 - accuracy: 0.7717 - val_loss: 0.6104 - val_accuracy: 0.6894
Epoch 69/500
896/896 - 118s - loss: 0.4802 - accuracy: 0.7734 - val_loss: 0.6116 - val_accuracy: 0.6911
Epoch 70/500
896/896 - 118s - loss: 0.4769 - accuracy: 0.7742 - val_loss: 0.6122 - val_accuracy: 0.6897
Epoch 71/500
896/896 - 118s - loss: 0.4700 - accuracy: 0.7799 - val_loss: 0.6113 - val_accuracy: 0.6937
Epoch 72/500
896/896 - 118s - loss: 0.4676 - accuracy: 0.7825 - val_loss: 0.6143 - val_accuracy: 0.6886
Epoch 73/500
896/896 - 118s - loss: 0.4647 - accuracy: 0.7834 - val_loss: 0.6150 - val_accuracy: 0.6894
Epoch 74/500
896/896 - 118s - loss: 0.4597 - accuracy: 0.7856 - val_loss: 0.6129 - val_accuracy: 0.6934
Epoch 75/500
896/896 - 118s - loss: 0.4622 - accuracy: 0.7858 - val_loss: 0.6143 - val_accuracy: 0.6917
Epoch 76/500
896/896 - 118s - loss: 0.4557 - accuracy: 0.7887 - val_loss: 0.6156 - val_accuracy: 0.6900
Epoch 77/500
896/896 - 118s - loss: 0.4539 - accuracy: 0.7910 - val_loss: 0.6147 - val_accuracy: 0.6897
Epoch 78/500
896/896 - 118s - loss: 0.4460 - accuracy: 0.7918 - val_loss: 0.6145 - val_accuracy: 0.6931
Epoch 79/500
896/896 - 118s - loss: 0.4469 - accuracy: 0.7937 - val_loss: 0.6177 - val_accuracy: 0.6894
Epoch 80/500
896/896 - 118s - loss: 0.4444 - accuracy: 0.7943 - val_loss: 0.6208 - val_accuracy: 0.6886
Epoch 81/500
896/896 - 118s - loss: 0.4435 - accuracy: 0.7962 - val_loss: 0.6203 - val_accuracy: 0.6894
Epoch 82/500
896/896 - 118s - loss: 0.4355 - accuracy: 0.8015 - val_loss: 0.6193 - val_accuracy: 0.6951
Epoch 83/500
896/896 - 118s - loss: 0.4352 - accuracy: 0.8003 - val_loss: 0.6214 - val_accuracy: 0.6909
Epoch 84/500
896/896 - 118s - loss: 0.4315 - accuracy: 0.8005 - val_loss: 0.6221 - val_accuracy: 0.6900
Epoch 85/500
896/896 - 118s - loss: 0.4232 - accuracy: 0.8076 - val_loss: 0.6210 - val_accuracy: 0.6948
Epoch 86/500
896/896 - 118s - loss: 0.4197 - accuracy: 0.8092 - val_loss: 0.6233 - val_accuracy: 0.6937
Epoch 87/500
896/896 - 118s - loss: 0.4186 - accuracy: 0.8074 - val_loss: 0.6262 - val_accuracy: 0.6903
Epoch 88/500
896/896 - 118s - loss: 0.4190 - accuracy: 0.8117 - val_loss: 0.6231 - val_accuracy: 0.6973
Epoch 89/500
896/896 - 118s - loss: 0.4158 - accuracy: 0.8117 - val_loss: 0.6275 - val_accuracy: 0.6923
Epoch 90/500
896/896 - 118s - loss: 0.4164 - accuracy: 0.8105 - val_loss: 0.6275 - val_accuracy: 0.6957
Epoch 91/500
896/896 - 118s - loss: 0.4067 - accuracy: 0.8161 - val_loss: 0.6283 - val_accuracy: 0.6945
Epoch 92/500
896/896 - 118s - loss: 0.4065 - accuracy: 0.8201 - val_loss: 0.6280 - val_accuracy: 0.6979
Epoch 93/500
896/896 - 118s - loss: 0.4052 - accuracy: 0.8162 - val_loss: 0.6270 - val_accuracy: 0.6999
Epoch 94/500
896/896 - 118s - loss: 0.3980 - accuracy: 0.8181 - val_loss: 0.6288 - val_accuracy: 0.6982
Epoch 95/500
896/896 - 118s - loss: 0.4004 - accuracy: 0.8204 - val_loss: 0.6301 - val_accuracy: 0.6968
Epoch 96/500
896/896 - 118s - loss: 0.3949 - accuracy: 0.8214 - val_loss: 0.6288 - val_accuracy: 0.7007
Epoch 97/500
896/896 - 118s - loss: 0.3895 - accuracy: 0.8247 - val_loss: 0.6346 - val_accuracy: 0.6985
Epoch 98/500
896/896 - 118s - loss: 0.3914 - accuracy: 0.8225 - val_loss: 0.6353 - val_accuracy: 0.6971
Epoch 99/500
896/896 - 118s - loss: 0.3842 - accuracy: 0.8270 - val_loss: 0.6356 - val_accuracy: 0.6971
Epoch 100/500
896/896 - 118s - loss: 0.3814 - accuracy: 0.8289 - val_loss: 0.6376 - val_accuracy: 0.6993
Epoch 101/500
896/896 - 118s - loss: 0.3867 - accuracy: 0.8278 - val_loss: 0.6364 - val_accuracy: 0.6990
Epoch 102/500
896/896 - 118s - loss: 0.3812 - accuracy: 0.8306 - val_loss: 0.6365 - val_accuracy: 0.7007
Epoch 103/500
896/896 - 118s - loss: 0.3749 - accuracy: 0.8326 - val_loss: 0.6404 - val_accuracy: 0.6957
Epoch 104/500
896/896 - 118s - loss: 0.3747 - accuracy: 0.8356 - val_loss: 0.6386 - val_accuracy: 0.6996
Epoch 105/500
896/896 - 118s - loss: 0.3692 - accuracy: 0.8356 - val_loss: 0.6418 - val_accuracy: 0.6971
Epoch 106/500
896/896 - 118s - loss: 0.3669 - accuracy: 0.8359 - val_loss: 0.6425 - val_accuracy: 0.6971
Epoch 107/500
896/896 - 118s - loss: 0.3670 - accuracy: 0.8379 - val_loss: 0.6428 - val_accuracy: 0.6968
Epoch 108/500
896/896 - 118s - loss: 0.3624 - accuracy: 0.8388 - val_loss: 0.6496 - val_accuracy: 0.6914
Epoch 109/500
896/896 - 118s - loss: 0.3578 - accuracy: 0.8414 - val_loss: 0.6446 - val_accuracy: 0.6985
Epoch 110/500
896/896 - 118s - loss: 0.3614 - accuracy: 0.8421 - val_loss: 0.6490 - val_accuracy: 0.6957
Epoch 111/500
896/896 - 118s - loss: 0.3592 - accuracy: 0.8411 - val_loss: 0.6455 - val_accuracy: 0.7010
Epoch 112/500
896/896 - 118s - loss: 0.3576 - accuracy: 0.8421 - val_loss: 0.6513 - val_accuracy: 0.6948
Epoch 113/500
896/896 - 118s - loss: 0.3555 - accuracy: 0.8444 - val_loss: 0.6474 - val_accuracy: 0.6993
Epoch 114/500
896/896 - 118s - loss: 0.3489 - accuracy: 0.8461 - val_loss: 0.6510 - val_accuracy: 0.6957
Epoch 115/500
896/896 - 118s - loss: 0.3470 - accuracy: 0.8481 - val_loss: 0.6510 - val_accuracy: 0.6988
Epoch 116/500
896/896 - 118s - loss: 0.3457 - accuracy: 0.8492 - val_loss: 0.6540 - val_accuracy: 0.6993
Epoch 117/500
896/896 - 118s - loss: 0.3408 - accuracy: 0.8496 - val_loss: 0.6543 - val_accuracy: 0.6996
Epoch 118/500
896/896 - 118s - loss: 0.3340 - accuracy: 0.8578 - val_loss: 0.6606 - val_accuracy: 0.6962
Epoch 119/500
896/896 - 118s - loss: 0.3368 - accuracy: 0.8515 - val_loss: 0.6570 - val_accuracy: 0.6993
Epoch 120/500
896/896 - 118s - loss: 0.3327 - accuracy: 0.8551 - val_loss: 0.6578 - val_accuracy: 0.6996
Epoch 121/500
896/896 - 118s - loss: 0.3326 - accuracy: 0.8544 - val_loss: 0.6594 - val_accuracy: 0.6988
Epoch 122/500
896/896 - 118s - loss: 0.3316 - accuracy: 0.8571 - val_loss: 0.6679 - val_accuracy: 0.6900
Epoch 123/500
896/896 - 118s - loss: 0.3286 - accuracy: 0.8572 - val_loss: 0.6625 - val_accuracy: 0.6968
Epoch 124/500
896/896 - 118s - loss: 0.3262 - accuracy: 0.8595 - val_loss: 0.6676 - val_accuracy: 0.6954
Epoch 125/500
896/896 - 118s - loss: 0.3279 - accuracy: 0.8580 - val_loss: 0.6669 - val_accuracy: 0.6968
Epoch 126/500
896/896 - 118s - loss: 0.3223 - accuracy: 0.8580 - val_loss: 0.6671 - val_accuracy: 0.6971
Epoch 127/500
896/896 - 118s - loss: 0.3272 - accuracy: 0.8580 - val_loss: 0.6676 - val_accuracy: 0.6976
Epoch 128/500
896/896 - 118s - loss: 0.3188 - accuracy: 0.8612 - val_loss: 0.6691 - val_accuracy: 0.6959
Epoch 129/500
896/896 - 118s - loss: 0.3199 - accuracy: 0.8627 - val_loss: 0.6749 - val_accuracy: 0.6954
Epoch 130/500
896/896 - 118s - loss: 0.3219 - accuracy: 0.8605 - val_loss: 0.6736 - val_accuracy: 0.6928
Epoch 131/500
896/896 - 118s - loss: 0.3181 - accuracy: 0.8627 - val_loss: 0.6752 - val_accuracy: 0.6923
========================================
save_weights
h5_weights/X5628FC.po/embedding_cnn_one_branch.h5
========================================

end time >>> Tue Oct  5 01:10:25 2021

end time >>> Tue Oct  5 01:10:25 2021

end time >>> Tue Oct  5 01:10:25 2021

end time >>> Tue Oct  5 01:10:25 2021

end time >>> Tue Oct  5 01:10:25 2021












args.model = embedding_cnn_one_branch
time used = 15512.051864385605


************************************
************************************

    Welcome to use DeepChromeHiC

************************************
************************************

begin time >>> Tue Oct  5 01:10:27 2021

begin time >>> Tue Oct  5 01:10:27 2021

begin time >>> Tue Oct  5 01:10:27 2021

begin time >>> Tue Oct  5 01:10:27 2021

begin time >>> Tue Oct  5 01:10:27 2021



If it is the first time to use, please preprocess the data first.
Use the command: python3 DeepChromeHiC.py -p true -n [gene name]
For example: python3 DeepChromeHiC.py -p true -n AD2.po


=== Below is your input ===

args.model = embedding_cnn_two_branch
args.type = train
args.name = X5628FC.po
args.length = 10001
===========================


-> h5_weights/X5628FC.po folder already exist. pass.
-> result/X5628FC.po/onehot_cnn_one_branch folder already exist. pass.
-> result/X5628FC.po/onehot_cnn_two_branch folder already exist. pass.
-> result/X5628FC.po/onehot_embedding_dense folder already exist. pass.
-> result/X5628FC.po/onehot_dense folder already exist. pass.
-> result/X5628FC.po/onehot_resnet18 folder already exist. pass.
-> result/X5628FC.po/onehot_resnet34 folder already exist. pass.
-> result/X5628FC.po/embedding_cnn_one_branch folder already exist. pass.
-> result/X5628FC.po/embedding_cnn_two_branch folder already exist. pass.
-> result/X5628FC.po/embedding_dense folder already exist. pass.
-> result/X5628FC.po/onehot_embedding_cnn_one_branch folder already exist. pass.
-> result/X5628FC.po/onehot_embedding_cnn_two_branch folder already exist. pass.
########################################
gen_name
X5628FC.po
########################################

########################################
model_name
embedding_cnn_two_branch
########################################

Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 10001, 100)   409700      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 10001, 100)   409700      input_2[0][0]                    
__________________________________________________________________________________________________
sequential (Sequential)         (None, 77, 64)       205888      embedding[0][0]                  
__________________________________________________________________________________________________
sequential_1 (Sequential)       (None, 77, 64)       205888      embedding_1[0][0]                
__________________________________________________________________________________________________
flatten (Flatten)               (None, 4928)         0           sequential[0][0]                 
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 4928)         0           sequential_1[0][0]               
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 9856)         0           flatten[0][0]                    
                                                                 flatten_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 9856)         39424       concatenate[0][0]                
__________________________________________________________________________________________________
dropout (Dropout)               (None, 9856)         0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dense (Dense)                   (None, 512)          5046784     dropout[0][0]                    
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 512)          2048        dense[0][0]                      
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 512)          2048        dense_1[0][0]                    
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           activation_9[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_2[0][0]                  
==================================================================================================
Total params: 6,584,649
Trainable params: 6,561,865
Non-trainable params: 22,784
__________________________________________________________________________________________________
Epoch 1/500
896/896 - 118s - loss: 0.9108 - accuracy: 0.5054 - val_loss: 0.7056 - val_accuracy: 0.5184
Epoch 2/500
896/896 - 118s - loss: 0.8582 - accuracy: 0.5063 - val_loss: 0.6944 - val_accuracy: 0.5387
Epoch 3/500
896/896 - 118s - loss: 0.8243 - accuracy: 0.5155 - val_loss: 0.6876 - val_accuracy: 0.5528
Epoch 4/500
896/896 - 118s - loss: 0.8196 - accuracy: 0.5202 - val_loss: 0.6833 - val_accuracy: 0.5576
Epoch 5/500
896/896 - 118s - loss: 0.8088 - accuracy: 0.5198 - val_loss: 0.6791 - val_accuracy: 0.5669
Epoch 6/500
896/896 - 118s - loss: 0.7990 - accuracy: 0.5300 - val_loss: 0.6758 - val_accuracy: 0.5836
Epoch 7/500
896/896 - 118s - loss: 0.7913 - accuracy: 0.5305 - val_loss: 0.6725 - val_accuracy: 0.5895
Epoch 8/500
896/896 - 118s - loss: 0.7823 - accuracy: 0.5393 - val_loss: 0.6697 - val_accuracy: 0.5954
Epoch 9/500
896/896 - 118s - loss: 0.7817 - accuracy: 0.5403 - val_loss: 0.6668 - val_accuracy: 0.5980
Epoch 10/500
896/896 - 118s - loss: 0.7703 - accuracy: 0.5445 - val_loss: 0.6638 - val_accuracy: 0.6039
Epoch 11/500
896/896 - 118s - loss: 0.7580 - accuracy: 0.5555 - val_loss: 0.6608 - val_accuracy: 0.6135
Epoch 12/500
896/896 - 118s - loss: 0.7525 - accuracy: 0.5596 - val_loss: 0.6575 - val_accuracy: 0.6155
Epoch 13/500
896/896 - 117s - loss: 0.7557 - accuracy: 0.5535 - val_loss: 0.6552 - val_accuracy: 0.6208
Epoch 14/500
896/896 - 118s - loss: 0.7470 - accuracy: 0.5628 - val_loss: 0.6520 - val_accuracy: 0.6279
Epoch 15/500
896/896 - 118s - loss: 0.7395 - accuracy: 0.5665 - val_loss: 0.6490 - val_accuracy: 0.6313
Epoch 16/500
896/896 - 117s - loss: 0.7316 - accuracy: 0.5739 - val_loss: 0.6462 - val_accuracy: 0.6378
Epoch 17/500
896/896 - 117s - loss: 0.7219 - accuracy: 0.5824 - val_loss: 0.6429 - val_accuracy: 0.6381
Epoch 18/500
896/896 - 118s - loss: 0.7161 - accuracy: 0.5875 - val_loss: 0.6402 - val_accuracy: 0.6414
Epoch 19/500
896/896 - 118s - loss: 0.7096 - accuracy: 0.5914 - val_loss: 0.6372 - val_accuracy: 0.6482
Epoch 20/500
896/896 - 118s - loss: 0.7038 - accuracy: 0.5959 - val_loss: 0.6343 - val_accuracy: 0.6494
Epoch 21/500
896/896 - 118s - loss: 0.7039 - accuracy: 0.5992 - val_loss: 0.6315 - val_accuracy: 0.6513
Epoch 22/500
896/896 - 118s - loss: 0.6951 - accuracy: 0.6046 - val_loss: 0.6288 - val_accuracy: 0.6564
Epoch 23/500
896/896 - 118s - loss: 0.6848 - accuracy: 0.6139 - val_loss: 0.6256 - val_accuracy: 0.6584
Epoch 24/500
896/896 - 118s - loss: 0.6797 - accuracy: 0.6212 - val_loss: 0.6226 - val_accuracy: 0.6606
Epoch 25/500
896/896 - 118s - loss: 0.6782 - accuracy: 0.6200 - val_loss: 0.6200 - val_accuracy: 0.6663
Epoch 26/500
896/896 - 117s - loss: 0.6684 - accuracy: 0.6317 - val_loss: 0.6176 - val_accuracy: 0.6640
Epoch 27/500
896/896 - 118s - loss: 0.6554 - accuracy: 0.6391 - val_loss: 0.6147 - val_accuracy: 0.6683
Epoch 28/500
896/896 - 118s - loss: 0.6584 - accuracy: 0.6401 - val_loss: 0.6126 - val_accuracy: 0.6705
Epoch 29/500
896/896 - 118s - loss: 0.6455 - accuracy: 0.6512 - val_loss: 0.6104 - val_accuracy: 0.6725
Epoch 30/500
896/896 - 118s - loss: 0.6398 - accuracy: 0.6531 - val_loss: 0.6081 - val_accuracy: 0.6736
Epoch 31/500
896/896 - 118s - loss: 0.6371 - accuracy: 0.6579 - val_loss: 0.6060 - val_accuracy: 0.6742
Epoch 32/500
896/896 - 117s - loss: 0.6227 - accuracy: 0.6702 - val_loss: 0.6035 - val_accuracy: 0.6790
Epoch 33/500
896/896 - 117s - loss: 0.6279 - accuracy: 0.6682 - val_loss: 0.6013 - val_accuracy: 0.6810
Epoch 34/500
896/896 - 117s - loss: 0.6109 - accuracy: 0.6774 - val_loss: 0.6000 - val_accuracy: 0.6838
Epoch 35/500
896/896 - 117s - loss: 0.6091 - accuracy: 0.6804 - val_loss: 0.5984 - val_accuracy: 0.6900
Epoch 36/500
896/896 - 117s - loss: 0.5954 - accuracy: 0.6917 - val_loss: 0.5967 - val_accuracy: 0.6863
Epoch 37/500
896/896 - 117s - loss: 0.5978 - accuracy: 0.6904 - val_loss: 0.5949 - val_accuracy: 0.6909
Epoch 38/500
896/896 - 117s - loss: 0.5901 - accuracy: 0.6989 - val_loss: 0.5937 - val_accuracy: 0.6877
Epoch 39/500
896/896 - 117s - loss: 0.5781 - accuracy: 0.7029 - val_loss: 0.5924 - val_accuracy: 0.6911
Epoch 40/500
896/896 - 117s - loss: 0.5693 - accuracy: 0.7130 - val_loss: 0.5914 - val_accuracy: 0.6945
Epoch 41/500
896/896 - 117s - loss: 0.5695 - accuracy: 0.7117 - val_loss: 0.5905 - val_accuracy: 0.6948
Epoch 42/500
896/896 - 117s - loss: 0.5581 - accuracy: 0.7187 - val_loss: 0.5900 - val_accuracy: 0.6962
Epoch 43/500
896/896 - 117s - loss: 0.5539 - accuracy: 0.7203 - val_loss: 0.5896 - val_accuracy: 0.6968
Epoch 44/500
896/896 - 117s - loss: 0.5452 - accuracy: 0.7300 - val_loss: 0.5893 - val_accuracy: 0.6979
Epoch 45/500
896/896 - 117s - loss: 0.5406 - accuracy: 0.7308 - val_loss: 0.5890 - val_accuracy: 0.7002
Epoch 46/500
896/896 - 117s - loss: 0.5344 - accuracy: 0.7360 - val_loss: 0.5885 - val_accuracy: 0.7013
Epoch 47/500
896/896 - 117s - loss: 0.5236 - accuracy: 0.7435 - val_loss: 0.5886 - val_accuracy: 0.7016
Epoch 48/500
896/896 - 117s - loss: 0.5242 - accuracy: 0.7447 - val_loss: 0.5886 - val_accuracy: 0.7002
Epoch 49/500
896/896 - 117s - loss: 0.5230 - accuracy: 0.7461 - val_loss: 0.5884 - val_accuracy: 0.7019
Epoch 50/500
896/896 - 117s - loss: 0.5109 - accuracy: 0.7523 - val_loss: 0.5878 - val_accuracy: 0.7050
Epoch 51/500
896/896 - 117s - loss: 0.5080 - accuracy: 0.7535 - val_loss: 0.5884 - val_accuracy: 0.7047
Epoch 52/500
896/896 - 117s - loss: 0.5012 - accuracy: 0.7622 - val_loss: 0.5890 - val_accuracy: 0.7069
Epoch 53/500
896/896 - 117s - loss: 0.4952 - accuracy: 0.7636 - val_loss: 0.5888 - val_accuracy: 0.7086
Epoch 54/500
896/896 - 117s - loss: 0.4922 - accuracy: 0.7649 - val_loss: 0.5890 - val_accuracy: 0.7098
Epoch 55/500
896/896 - 117s - loss: 0.4834 - accuracy: 0.7702 - val_loss: 0.5893 - val_accuracy: 0.7112
Epoch 56/500
896/896 - 117s - loss: 0.4837 - accuracy: 0.7709 - val_loss: 0.5900 - val_accuracy: 0.7101
Epoch 57/500
896/896 - 117s - loss: 0.4756 - accuracy: 0.7743 - val_loss: 0.5903 - val_accuracy: 0.7103
Epoch 58/500
896/896 - 117s - loss: 0.4712 - accuracy: 0.7802 - val_loss: 0.5914 - val_accuracy: 0.7132
Epoch 59/500
896/896 - 117s - loss: 0.4624 - accuracy: 0.7834 - val_loss: 0.5913 - val_accuracy: 0.7123
Epoch 60/500
896/896 - 117s - loss: 0.4602 - accuracy: 0.7829 - val_loss: 0.5925 - val_accuracy: 0.7115
Epoch 61/500
896/896 - 117s - loss: 0.4631 - accuracy: 0.7861 - val_loss: 0.5932 - val_accuracy: 0.7132
Epoch 62/500
896/896 - 117s - loss: 0.4476 - accuracy: 0.7924 - val_loss: 0.5929 - val_accuracy: 0.7151
Epoch 63/500
896/896 - 117s - loss: 0.4508 - accuracy: 0.7915 - val_loss: 0.5945 - val_accuracy: 0.7123
Epoch 64/500
896/896 - 117s - loss: 0.4402 - accuracy: 0.7947 - val_loss: 0.5956 - val_accuracy: 0.7117
Epoch 65/500
896/896 - 117s - loss: 0.4365 - accuracy: 0.7991 - val_loss: 0.5965 - val_accuracy: 0.7146
Epoch 66/500
896/896 - 117s - loss: 0.4287 - accuracy: 0.8054 - val_loss: 0.5977 - val_accuracy: 0.7157
Epoch 67/500
896/896 - 117s - loss: 0.4293 - accuracy: 0.8043 - val_loss: 0.5986 - val_accuracy: 0.7146
Epoch 68/500
896/896 - 117s - loss: 0.4254 - accuracy: 0.8046 - val_loss: 0.5999 - val_accuracy: 0.7151
Epoch 69/500
896/896 - 117s - loss: 0.4172 - accuracy: 0.8092 - val_loss: 0.6003 - val_accuracy: 0.7160
Epoch 70/500
896/896 - 117s - loss: 0.4119 - accuracy: 0.8134 - val_loss: 0.6023 - val_accuracy: 0.7154
Epoch 71/500
896/896 - 117s - loss: 0.4044 - accuracy: 0.8179 - val_loss: 0.6033 - val_accuracy: 0.7182
Epoch 72/500
896/896 - 117s - loss: 0.4062 - accuracy: 0.8148 - val_loss: 0.6045 - val_accuracy: 0.7191
Epoch 73/500
896/896 - 117s - loss: 0.4014 - accuracy: 0.8187 - val_loss: 0.6068 - val_accuracy: 0.7168
Epoch 74/500
896/896 - 117s - loss: 0.3964 - accuracy: 0.8229 - val_loss: 0.6082 - val_accuracy: 0.7171
Epoch 75/500
896/896 - 117s - loss: 0.3880 - accuracy: 0.8237 - val_loss: 0.6093 - val_accuracy: 0.7194
Epoch 76/500
896/896 - 117s - loss: 0.3895 - accuracy: 0.8262 - val_loss: 0.6105 - val_accuracy: 0.7165
Epoch 77/500
896/896 - 117s - loss: 0.3804 - accuracy: 0.8314 - val_loss: 0.6121 - val_accuracy: 0.7171
Epoch 78/500
896/896 - 117s - loss: 0.3800 - accuracy: 0.8318 - val_loss: 0.6139 - val_accuracy: 0.7140
Epoch 79/500
896/896 - 117s - loss: 0.3741 - accuracy: 0.8310 - val_loss: 0.6161 - val_accuracy: 0.7157
Epoch 80/500
896/896 - 117s - loss: 0.3708 - accuracy: 0.8337 - val_loss: 0.6173 - val_accuracy: 0.7151
Epoch 81/500
896/896 - 117s - loss: 0.3706 - accuracy: 0.8344 - val_loss: 0.6203 - val_accuracy: 0.7182
Epoch 82/500
896/896 - 117s - loss: 0.3666 - accuracy: 0.8365 - val_loss: 0.6210 - val_accuracy: 0.7168
Epoch 83/500
896/896 - 117s - loss: 0.3647 - accuracy: 0.8387 - val_loss: 0.6215 - val_accuracy: 0.7168
Epoch 84/500
896/896 - 117s - loss: 0.3578 - accuracy: 0.8422 - val_loss: 0.6241 - val_accuracy: 0.7174
Epoch 85/500
896/896 - 117s - loss: 0.3544 - accuracy: 0.8441 - val_loss: 0.6244 - val_accuracy: 0.7180
Epoch 86/500
896/896 - 117s - loss: 0.3487 - accuracy: 0.8467 - val_loss: 0.6269 - val_accuracy: 0.7180
Epoch 87/500
896/896 - 117s - loss: 0.3471 - accuracy: 0.8480 - val_loss: 0.6292 - val_accuracy: 0.7180
Epoch 88/500
896/896 - 117s - loss: 0.3395 - accuracy: 0.8528 - val_loss: 0.6319 - val_accuracy: 0.7188
Epoch 89/500
896/896 - 117s - loss: 0.3449 - accuracy: 0.8504 - val_loss: 0.6324 - val_accuracy: 0.7196
Epoch 90/500
896/896 - 117s - loss: 0.3407 - accuracy: 0.8491 - val_loss: 0.6350 - val_accuracy: 0.7171
Epoch 91/500
896/896 - 117s - loss: 0.3371 - accuracy: 0.8507 - val_loss: 0.6375 - val_accuracy: 0.7149
Epoch 92/500
896/896 - 117s - loss: 0.3338 - accuracy: 0.8551 - val_loss: 0.6382 - val_accuracy: 0.7177
Epoch 93/500
896/896 - 117s - loss: 0.3244 - accuracy: 0.8597 - val_loss: 0.6401 - val_accuracy: 0.7185
Epoch 94/500
896/896 - 117s - loss: 0.3201 - accuracy: 0.8627 - val_loss: 0.6436 - val_accuracy: 0.7199
Epoch 95/500
896/896 - 117s - loss: 0.3207 - accuracy: 0.8604 - val_loss: 0.6454 - val_accuracy: 0.7191
Epoch 96/500
896/896 - 117s - loss: 0.3193 - accuracy: 0.8608 - val_loss: 0.6465 - val_accuracy: 0.7185
Epoch 97/500
896/896 - 117s - loss: 0.3197 - accuracy: 0.8618 - val_loss: 0.6481 - val_accuracy: 0.7180
Epoch 98/500
896/896 - 117s - loss: 0.3085 - accuracy: 0.8671 - val_loss: 0.6503 - val_accuracy: 0.7182
Epoch 99/500
896/896 - 117s - loss: 0.3095 - accuracy: 0.8659 - val_loss: 0.6542 - val_accuracy: 0.7171
Epoch 100/500
896/896 - 117s - loss: 0.3041 - accuracy: 0.8706 - val_loss: 0.6544 - val_accuracy: 0.7163
Epoch 101/500
896/896 - 117s - loss: 0.2996 - accuracy: 0.8696 - val_loss: 0.6564 - val_accuracy: 0.7174
Epoch 102/500
896/896 - 117s - loss: 0.2973 - accuracy: 0.8737 - val_loss: 0.6590 - val_accuracy: 0.7194
Epoch 103/500
896/896 - 117s - loss: 0.3012 - accuracy: 0.8706 - val_loss: 0.6639 - val_accuracy: 0.7219
Epoch 104/500
896/896 - 117s - loss: 0.2937 - accuracy: 0.8754 - val_loss: 0.6638 - val_accuracy: 0.7199
Epoch 105/500
896/896 - 117s - loss: 0.2904 - accuracy: 0.8765 - val_loss: 0.6672 - val_accuracy: 0.7163
Epoch 106/500
896/896 - 117s - loss: 0.2916 - accuracy: 0.8768 - val_loss: 0.6679 - val_accuracy: 0.7177
Epoch 107/500
896/896 - 117s - loss: 0.2838 - accuracy: 0.8788 - val_loss: 0.6697 - val_accuracy: 0.7140
Epoch 108/500
896/896 - 117s - loss: 0.2852 - accuracy: 0.8788 - val_loss: 0.6715 - val_accuracy: 0.7154
Epoch 109/500
896/896 - 117s - loss: 0.2809 - accuracy: 0.8806 - val_loss: 0.6748 - val_accuracy: 0.7149
Epoch 110/500
896/896 - 117s - loss: 0.2794 - accuracy: 0.8793 - val_loss: 0.6774 - val_accuracy: 0.7168
Epoch 111/500
896/896 - 117s - loss: 0.2749 - accuracy: 0.8830 - val_loss: 0.6797 - val_accuracy: 0.7165
Epoch 112/500
896/896 - 117s - loss: 0.2695 - accuracy: 0.8856 - val_loss: 0.6822 - val_accuracy: 0.7160
Epoch 113/500
896/896 - 117s - loss: 0.2760 - accuracy: 0.8817 - val_loss: 0.6844 - val_accuracy: 0.7168
Epoch 114/500
896/896 - 117s - loss: 0.2671 - accuracy: 0.8876 - val_loss: 0.6847 - val_accuracy: 0.7157
Epoch 115/500
896/896 - 117s - loss: 0.2712 - accuracy: 0.8857 - val_loss: 0.6878 - val_accuracy: 0.7146
Epoch 116/500
896/896 - 117s - loss: 0.2674 - accuracy: 0.8864 - val_loss: 0.6894 - val_accuracy: 0.7171
Epoch 117/500
896/896 - 117s - loss: 0.2657 - accuracy: 0.8879 - val_loss: 0.6921 - val_accuracy: 0.7168
Epoch 118/500
896/896 - 117s - loss: 0.2572 - accuracy: 0.8920 - val_loss: 0.6948 - val_accuracy: 0.7163
Epoch 119/500
896/896 - 117s - loss: 0.2645 - accuracy: 0.8870 - val_loss: 0.6982 - val_accuracy: 0.7168
Epoch 120/500
896/896 - 117s - loss: 0.2584 - accuracy: 0.8904 - val_loss: 0.6990 - val_accuracy: 0.7165
Epoch 121/500
896/896 - 117s - loss: 0.2475 - accuracy: 0.8975 - val_loss: 0.6997 - val_accuracy: 0.7146
Epoch 122/500
896/896 - 117s - loss: 0.2509 - accuracy: 0.8964 - val_loss: 0.7017 - val_accuracy: 0.7163
Epoch 123/500
896/896 - 117s - loss: 0.2476 - accuracy: 0.8966 - val_loss: 0.7035 - val_accuracy: 0.7151
========================================
save_weights
h5_weights/X5628FC.po/embedding_cnn_two_branch.h5
========================================

end time >>> Tue Oct  5 05:11:52 2021

end time >>> Tue Oct  5 05:11:52 2021

end time >>> Tue Oct  5 05:11:52 2021

end time >>> Tue Oct  5 05:11:52 2021

end time >>> Tue Oct  5 05:11:52 2021












args.model = embedding_cnn_two_branch
time used = 14484.958649635315


