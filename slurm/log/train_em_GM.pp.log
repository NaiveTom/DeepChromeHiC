************************************
************************************

    Welcome to use DeepChromeHiC

************************************
************************************

begin time >>> Sun Oct  3 03:54:58 2021

begin time >>> Sun Oct  3 03:54:58 2021

begin time >>> Sun Oct  3 03:54:58 2021

begin time >>> Sun Oct  3 03:54:58 2021

begin time >>> Sun Oct  3 03:54:58 2021



If it is the first time to use, please preprocess the data first.
Use the command: python3 DeepChromeHiC.py -p true -n [gene name]
For example: python3 DeepChromeHiC.py -p true -n AD2.po


=== Below is your input ===

args.model = embedding_dense
args.type = train
args.name = GM.pp
args.length = 10001
===========================


-> h5_weights/GM.pp folder already exist. pass.
-> result/GM.pp/onehot_cnn_one_branch folder already exist. pass.
-> result/GM.pp/onehot_cnn_two_branch folder already exist. pass.
-> result/GM.pp/onehot_embedding_dense folder already exist. pass.
-> result/GM.pp/onehot_dense folder already exist. pass.
-> result/GM.pp/onehot_resnet18 folder already exist. pass.
-> result/GM.pp/onehot_resnet34 folder already exist. pass.
-> result/GM.pp/embedding_cnn_one_branch folder already exist. pass.
-> result/GM.pp/embedding_cnn_two_branch folder already exist. pass.
-> result/GM.pp/embedding_dense folder already exist. pass.
-> result/GM.pp/onehot_embedding_cnn_one_branch folder already exist. pass.
-> result/GM.pp/onehot_embedding_cnn_two_branch folder already exist. pass.
########################################
gen_name
GM.pp
########################################

########################################
model_name
embedding_dense
########################################

Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 10001, 100)   409700      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 10001, 100)   409700      input_2[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 20002, 100)   0           embedding[0][0]                  
                                                                 embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 626, 64)      409664      concatenate[0][0]                
__________________________________________________________________________________________________
max_pooling1d (MaxPooling1D)    (None, 38, 64)       0           conv1d[0][0]                     
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 38, 64)       256         max_pooling1d[0][0]              
__________________________________________________________________________________________________
flatten (Flatten)               (None, 2432)         0           batch_normalization[0][0]        
__________________________________________________________________________________________________
dropout (Dropout)               (None, 2432)         0           flatten[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 512)          1245696     dropout[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        dense[0][0]                      
__________________________________________________________________________________________________
activation (Activation)         (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           activation[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 512)          2048        dense_1[0][0]                    
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 512)          0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 512)          262656      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 512)          2048        dense_2[0][0]                    
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 512)          0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           activation_2[0][0]               
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 3,006,985
Trainable params: 3,003,785
Non-trainable params: 3,200
__________________________________________________________________________________________________
Epoch 1/500
140/140 - 18s - loss: 0.8984 - accuracy: 0.4899 - val_loss: 0.6925 - val_accuracy: 0.5217
Epoch 2/500
140/140 - 18s - loss: 0.8938 - accuracy: 0.5004 - val_loss: 0.6929 - val_accuracy: 0.5145
Epoch 3/500
140/140 - 18s - loss: 0.8784 - accuracy: 0.5009 - val_loss: 0.6946 - val_accuracy: 0.5072
Epoch 4/500
140/140 - 18s - loss: 0.8684 - accuracy: 0.5116 - val_loss: 0.6955 - val_accuracy: 0.5072
Epoch 5/500
140/140 - 18s - loss: 0.8716 - accuracy: 0.5049 - val_loss: 0.6947 - val_accuracy: 0.5000
Epoch 6/500
140/140 - 18s - loss: 0.8609 - accuracy: 0.5139 - val_loss: 0.6947 - val_accuracy: 0.5018
Epoch 7/500
140/140 - 18s - loss: 0.8629 - accuracy: 0.5107 - val_loss: 0.6954 - val_accuracy: 0.5036
Epoch 8/500
140/140 - 18s - loss: 0.8571 - accuracy: 0.5054 - val_loss: 0.6947 - val_accuracy: 0.5054
Epoch 9/500
140/140 - 18s - loss: 0.8600 - accuracy: 0.5045 - val_loss: 0.6941 - val_accuracy: 0.5000
Epoch 10/500
140/140 - 18s - loss: 0.8530 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5163
Epoch 11/500
140/140 - 18s - loss: 0.8466 - accuracy: 0.5107 - val_loss: 0.6938 - val_accuracy: 0.5145
Epoch 12/500
140/140 - 18s - loss: 0.8499 - accuracy: 0.5025 - val_loss: 0.6933 - val_accuracy: 0.5236
Epoch 13/500
140/140 - 18s - loss: 0.8482 - accuracy: 0.5052 - val_loss: 0.6929 - val_accuracy: 0.5199
Epoch 14/500
140/140 - 18s - loss: 0.8545 - accuracy: 0.4987 - val_loss: 0.6923 - val_accuracy: 0.5145
Epoch 15/500
140/140 - 18s - loss: 0.8473 - accuracy: 0.5081 - val_loss: 0.6915 - val_accuracy: 0.5127
Epoch 16/500
140/140 - 18s - loss: 0.8292 - accuracy: 0.5219 - val_loss: 0.6915 - val_accuracy: 0.5127
Epoch 17/500
140/140 - 18s - loss: 0.8295 - accuracy: 0.5296 - val_loss: 0.6911 - val_accuracy: 0.5127
Epoch 18/500
140/140 - 18s - loss: 0.8455 - accuracy: 0.5085 - val_loss: 0.6910 - val_accuracy: 0.5199
Epoch 19/500
140/140 - 18s - loss: 0.8343 - accuracy: 0.5199 - val_loss: 0.6912 - val_accuracy: 0.5181
Epoch 20/500
140/140 - 18s - loss: 0.8391 - accuracy: 0.4982 - val_loss: 0.6913 - val_accuracy: 0.5199
Epoch 21/500
140/140 - 18s - loss: 0.8380 - accuracy: 0.5067 - val_loss: 0.6907 - val_accuracy: 0.5181
Epoch 22/500
140/140 - 18s - loss: 0.8453 - accuracy: 0.5119 - val_loss: 0.6891 - val_accuracy: 0.5181
Epoch 23/500
140/140 - 18s - loss: 0.8299 - accuracy: 0.5170 - val_loss: 0.6894 - val_accuracy: 0.5163
Epoch 24/500
140/140 - 18s - loss: 0.8335 - accuracy: 0.5072 - val_loss: 0.6890 - val_accuracy: 0.5109
Epoch 25/500
140/140 - 18s - loss: 0.8267 - accuracy: 0.5107 - val_loss: 0.6889 - val_accuracy: 0.5199
Epoch 26/500
140/140 - 18s - loss: 0.8219 - accuracy: 0.5148 - val_loss: 0.6886 - val_accuracy: 0.5254
Epoch 27/500
140/140 - 18s - loss: 0.8298 - accuracy: 0.5130 - val_loss: 0.6880 - val_accuracy: 0.5145
Epoch 28/500
140/140 - 18s - loss: 0.8279 - accuracy: 0.5134 - val_loss: 0.6872 - val_accuracy: 0.5199
Epoch 29/500
140/140 - 18s - loss: 0.8127 - accuracy: 0.5237 - val_loss: 0.6867 - val_accuracy: 0.5163
Epoch 30/500
140/140 - 18s - loss: 0.8094 - accuracy: 0.5137 - val_loss: 0.6859 - val_accuracy: 0.5181
Epoch 31/500
140/140 - 18s - loss: 0.8182 - accuracy: 0.5202 - val_loss: 0.6865 - val_accuracy: 0.5308
Epoch 32/500
140/140 - 18s - loss: 0.8261 - accuracy: 0.5134 - val_loss: 0.6864 - val_accuracy: 0.5326
Epoch 33/500
140/140 - 18s - loss: 0.8121 - accuracy: 0.5287 - val_loss: 0.6859 - val_accuracy: 0.5290
Epoch 34/500
140/140 - 18s - loss: 0.8059 - accuracy: 0.5258 - val_loss: 0.6846 - val_accuracy: 0.5236
Epoch 35/500
140/140 - 18s - loss: 0.8121 - accuracy: 0.5204 - val_loss: 0.6847 - val_accuracy: 0.5290
Epoch 36/500
140/140 - 18s - loss: 0.8155 - accuracy: 0.5235 - val_loss: 0.6849 - val_accuracy: 0.5254
Epoch 37/500
140/140 - 18s - loss: 0.8107 - accuracy: 0.5172 - val_loss: 0.6843 - val_accuracy: 0.5290
Epoch 38/500
140/140 - 18s - loss: 0.8247 - accuracy: 0.5186 - val_loss: 0.6845 - val_accuracy: 0.5217
Epoch 39/500
140/140 - 18s - loss: 0.8185 - accuracy: 0.5190 - val_loss: 0.6844 - val_accuracy: 0.5290
Epoch 40/500
140/140 - 18s - loss: 0.8189 - accuracy: 0.5186 - val_loss: 0.6835 - val_accuracy: 0.5326
Epoch 41/500
140/140 - 18s - loss: 0.8076 - accuracy: 0.5302 - val_loss: 0.6832 - val_accuracy: 0.5453
Epoch 42/500
140/140 - 18s - loss: 0.7978 - accuracy: 0.5320 - val_loss: 0.6830 - val_accuracy: 0.5308
Epoch 43/500
140/140 - 18s - loss: 0.7975 - accuracy: 0.5289 - val_loss: 0.6827 - val_accuracy: 0.5380
Epoch 44/500
140/140 - 18s - loss: 0.8206 - accuracy: 0.5096 - val_loss: 0.6821 - val_accuracy: 0.5417
Epoch 45/500
140/140 - 18s - loss: 0.8031 - accuracy: 0.5287 - val_loss: 0.6818 - val_accuracy: 0.5362
Epoch 46/500
140/140 - 18s - loss: 0.7959 - accuracy: 0.5390 - val_loss: 0.6811 - val_accuracy: 0.5417
Epoch 47/500
140/140 - 18s - loss: 0.8155 - accuracy: 0.5204 - val_loss: 0.6812 - val_accuracy: 0.5417
Epoch 48/500
140/140 - 18s - loss: 0.7978 - accuracy: 0.5300 - val_loss: 0.6806 - val_accuracy: 0.5380
Epoch 49/500
140/140 - 18s - loss: 0.8114 - accuracy: 0.5137 - val_loss: 0.6799 - val_accuracy: 0.5453
Epoch 50/500
140/140 - 18s - loss: 0.7987 - accuracy: 0.5372 - val_loss: 0.6800 - val_accuracy: 0.5399
Epoch 51/500
140/140 - 18s - loss: 0.8105 - accuracy: 0.5251 - val_loss: 0.6804 - val_accuracy: 0.5489
Epoch 52/500
140/140 - 18s - loss: 0.8040 - accuracy: 0.5322 - val_loss: 0.6801 - val_accuracy: 0.5471
Epoch 53/500
140/140 - 18s - loss: 0.8029 - accuracy: 0.5334 - val_loss: 0.6795 - val_accuracy: 0.5417
Epoch 54/500
140/140 - 18s - loss: 0.7946 - accuracy: 0.5338 - val_loss: 0.6789 - val_accuracy: 0.5562
Epoch 55/500
140/140 - 18s - loss: 0.8029 - accuracy: 0.5273 - val_loss: 0.6784 - val_accuracy: 0.5616
Epoch 56/500
140/140 - 18s - loss: 0.7931 - accuracy: 0.5329 - val_loss: 0.6780 - val_accuracy: 0.5562
Epoch 57/500
140/140 - 18s - loss: 0.7884 - accuracy: 0.5401 - val_loss: 0.6778 - val_accuracy: 0.5616
Epoch 58/500
140/140 - 18s - loss: 0.7901 - accuracy: 0.5392 - val_loss: 0.6778 - val_accuracy: 0.5707
Epoch 59/500
140/140 - 18s - loss: 0.7783 - accuracy: 0.5468 - val_loss: 0.6775 - val_accuracy: 0.5670
Epoch 60/500
140/140 - 18s - loss: 0.7916 - accuracy: 0.5343 - val_loss: 0.6767 - val_accuracy: 0.5652
Epoch 61/500
140/140 - 18s - loss: 0.7687 - accuracy: 0.5546 - val_loss: 0.6759 - val_accuracy: 0.5761
Epoch 62/500
140/140 - 18s - loss: 0.7908 - accuracy: 0.5423 - val_loss: 0.6760 - val_accuracy: 0.5725
Epoch 63/500
140/140 - 18s - loss: 0.7964 - accuracy: 0.5334 - val_loss: 0.6752 - val_accuracy: 0.5707
Epoch 64/500
140/140 - 18s - loss: 0.7797 - accuracy: 0.5549 - val_loss: 0.6745 - val_accuracy: 0.5761
Epoch 65/500
140/140 - 18s - loss: 0.7880 - accuracy: 0.5340 - val_loss: 0.6741 - val_accuracy: 0.5815
Epoch 66/500
140/140 - 18s - loss: 0.7757 - accuracy: 0.5423 - val_loss: 0.6733 - val_accuracy: 0.5797
Epoch 67/500
140/140 - 18s - loss: 0.7870 - accuracy: 0.5381 - val_loss: 0.6733 - val_accuracy: 0.5851
Epoch 68/500
140/140 - 18s - loss: 0.7765 - accuracy: 0.5446 - val_loss: 0.6733 - val_accuracy: 0.5779
Epoch 69/500
140/140 - 18s - loss: 0.7643 - accuracy: 0.5562 - val_loss: 0.6727 - val_accuracy: 0.5779
Epoch 70/500
140/140 - 18s - loss: 0.7771 - accuracy: 0.5437 - val_loss: 0.6721 - val_accuracy: 0.5797
Epoch 71/500
140/140 - 18s - loss: 0.7718 - accuracy: 0.5455 - val_loss: 0.6720 - val_accuracy: 0.5797
Epoch 72/500
140/140 - 18s - loss: 0.7806 - accuracy: 0.5419 - val_loss: 0.6715 - val_accuracy: 0.5779
Epoch 73/500
140/140 - 18s - loss: 0.7722 - accuracy: 0.5443 - val_loss: 0.6708 - val_accuracy: 0.5851
Epoch 74/500
140/140 - 18s - loss: 0.7779 - accuracy: 0.5376 - val_loss: 0.6704 - val_accuracy: 0.5996
Epoch 75/500
140/140 - 18s - loss: 0.7756 - accuracy: 0.5403 - val_loss: 0.6698 - val_accuracy: 0.5906
Epoch 76/500
140/140 - 18s - loss: 0.7752 - accuracy: 0.5446 - val_loss: 0.6696 - val_accuracy: 0.5851
Epoch 77/500
140/140 - 18s - loss: 0.7707 - accuracy: 0.5428 - val_loss: 0.6691 - val_accuracy: 0.5833
Epoch 78/500
140/140 - 18s - loss: 0.7607 - accuracy: 0.5513 - val_loss: 0.6688 - val_accuracy: 0.5851
Epoch 79/500
140/140 - 18s - loss: 0.7705 - accuracy: 0.5452 - val_loss: 0.6683 - val_accuracy: 0.5870
Epoch 80/500
140/140 - 18s - loss: 0.7673 - accuracy: 0.5446 - val_loss: 0.6678 - val_accuracy: 0.5870
Epoch 81/500
140/140 - 18s - loss: 0.7707 - accuracy: 0.5517 - val_loss: 0.6672 - val_accuracy: 0.5888
Epoch 82/500
140/140 - 18s - loss: 0.7631 - accuracy: 0.5522 - val_loss: 0.6664 - val_accuracy: 0.5942
Epoch 83/500
140/140 - 18s - loss: 0.7535 - accuracy: 0.5661 - val_loss: 0.6661 - val_accuracy: 0.5924
Epoch 84/500
140/140 - 18s - loss: 0.7472 - accuracy: 0.5694 - val_loss: 0.6660 - val_accuracy: 0.5978
Epoch 85/500
140/140 - 18s - loss: 0.7408 - accuracy: 0.5627 - val_loss: 0.6653 - val_accuracy: 0.5978
Epoch 86/500
140/140 - 18s - loss: 0.7363 - accuracy: 0.5779 - val_loss: 0.6645 - val_accuracy: 0.5906
Epoch 87/500
140/140 - 18s - loss: 0.7387 - accuracy: 0.5678 - val_loss: 0.6647 - val_accuracy: 0.5978
Epoch 88/500
140/140 - 18s - loss: 0.7465 - accuracy: 0.5737 - val_loss: 0.6643 - val_accuracy: 0.6014
Epoch 89/500
140/140 - 18s - loss: 0.7405 - accuracy: 0.5710 - val_loss: 0.6633 - val_accuracy: 0.6014
Epoch 90/500
140/140 - 18s - loss: 0.7358 - accuracy: 0.5889 - val_loss: 0.6625 - val_accuracy: 0.6051
Epoch 91/500
140/140 - 18s - loss: 0.7381 - accuracy: 0.5824 - val_loss: 0.6617 - val_accuracy: 0.6069
Epoch 92/500
140/140 - 18s - loss: 0.7374 - accuracy: 0.5799 - val_loss: 0.6610 - val_accuracy: 0.6069
Epoch 93/500
140/140 - 18s - loss: 0.7499 - accuracy: 0.5683 - val_loss: 0.6605 - val_accuracy: 0.6051
Epoch 94/500
140/140 - 18s - loss: 0.7372 - accuracy: 0.5773 - val_loss: 0.6599 - val_accuracy: 0.6069
Epoch 95/500
140/140 - 18s - loss: 0.7394 - accuracy: 0.5797 - val_loss: 0.6594 - val_accuracy: 0.6105
Epoch 96/500
140/140 - 18s - loss: 0.7415 - accuracy: 0.5739 - val_loss: 0.6588 - val_accuracy: 0.6087
Epoch 97/500
140/140 - 18s - loss: 0.7484 - accuracy: 0.5694 - val_loss: 0.6578 - val_accuracy: 0.6069
Epoch 98/500
140/140 - 18s - loss: 0.7200 - accuracy: 0.5898 - val_loss: 0.6570 - val_accuracy: 0.6087
Epoch 99/500
140/140 - 18s - loss: 0.7272 - accuracy: 0.5871 - val_loss: 0.6564 - val_accuracy: 0.6159
Epoch 100/500
140/140 - 18s - loss: 0.7275 - accuracy: 0.5878 - val_loss: 0.6557 - val_accuracy: 0.6141
Epoch 101/500
140/140 - 18s - loss: 0.7118 - accuracy: 0.5974 - val_loss: 0.6552 - val_accuracy: 0.6178
Epoch 102/500
140/140 - 18s - loss: 0.7165 - accuracy: 0.5936 - val_loss: 0.6543 - val_accuracy: 0.6268
Epoch 103/500
140/140 - 18s - loss: 0.7053 - accuracy: 0.6055 - val_loss: 0.6537 - val_accuracy: 0.6214
Epoch 104/500
140/140 - 18s - loss: 0.7215 - accuracy: 0.5920 - val_loss: 0.6528 - val_accuracy: 0.6268
Epoch 105/500
140/140 - 18s - loss: 0.7311 - accuracy: 0.5914 - val_loss: 0.6521 - val_accuracy: 0.6250
Epoch 106/500
140/140 - 18s - loss: 0.7226 - accuracy: 0.5869 - val_loss: 0.6508 - val_accuracy: 0.6250
Epoch 107/500
140/140 - 18s - loss: 0.7194 - accuracy: 0.5884 - val_loss: 0.6506 - val_accuracy: 0.6232
Epoch 108/500
140/140 - 18s - loss: 0.7186 - accuracy: 0.5994 - val_loss: 0.6498 - val_accuracy: 0.6250
Epoch 109/500
140/140 - 18s - loss: 0.7039 - accuracy: 0.6005 - val_loss: 0.6493 - val_accuracy: 0.6286
Epoch 110/500
140/140 - 18s - loss: 0.7063 - accuracy: 0.6070 - val_loss: 0.6482 - val_accuracy: 0.6268
Epoch 111/500
140/140 - 18s - loss: 0.7001 - accuracy: 0.6039 - val_loss: 0.6471 - val_accuracy: 0.6377
Epoch 112/500
140/140 - 18s - loss: 0.6999 - accuracy: 0.6048 - val_loss: 0.6462 - val_accuracy: 0.6268
Epoch 113/500
140/140 - 18s - loss: 0.7038 - accuracy: 0.6032 - val_loss: 0.6457 - val_accuracy: 0.6322
Epoch 114/500
140/140 - 18s - loss: 0.6853 - accuracy: 0.6173 - val_loss: 0.6450 - val_accuracy: 0.6395
Epoch 115/500
140/140 - 18s - loss: 0.6937 - accuracy: 0.6095 - val_loss: 0.6442 - val_accuracy: 0.6395
Epoch 116/500
140/140 - 18s - loss: 0.6817 - accuracy: 0.6146 - val_loss: 0.6433 - val_accuracy: 0.6377
Epoch 117/500
140/140 - 18s - loss: 0.6800 - accuracy: 0.6198 - val_loss: 0.6423 - val_accuracy: 0.6449
Epoch 118/500
140/140 - 18s - loss: 0.6788 - accuracy: 0.6196 - val_loss: 0.6415 - val_accuracy: 0.6395
Epoch 119/500
140/140 - 18s - loss: 0.6870 - accuracy: 0.6171 - val_loss: 0.6408 - val_accuracy: 0.6467
Epoch 120/500
140/140 - 18s - loss: 0.6943 - accuracy: 0.6117 - val_loss: 0.6392 - val_accuracy: 0.6431
Epoch 121/500
140/140 - 18s - loss: 0.6683 - accuracy: 0.6361 - val_loss: 0.6388 - val_accuracy: 0.6413
Epoch 122/500
140/140 - 18s - loss: 0.6722 - accuracy: 0.6299 - val_loss: 0.6379 - val_accuracy: 0.6395
Epoch 123/500
140/140 - 18s - loss: 0.6561 - accuracy: 0.6451 - val_loss: 0.6369 - val_accuracy: 0.6395
Epoch 124/500
140/140 - 18s - loss: 0.6584 - accuracy: 0.6529 - val_loss: 0.6364 - val_accuracy: 0.6449
Epoch 125/500
140/140 - 18s - loss: 0.6574 - accuracy: 0.6375 - val_loss: 0.6352 - val_accuracy: 0.6377
Epoch 126/500
140/140 - 18s - loss: 0.6597 - accuracy: 0.6384 - val_loss: 0.6341 - val_accuracy: 0.6413
Epoch 127/500
140/140 - 18s - loss: 0.6608 - accuracy: 0.6375 - val_loss: 0.6333 - val_accuracy: 0.6467
Epoch 128/500
140/140 - 18s - loss: 0.6588 - accuracy: 0.6408 - val_loss: 0.6322 - val_accuracy: 0.6449
Epoch 129/500
140/140 - 18s - loss: 0.6608 - accuracy: 0.6451 - val_loss: 0.6310 - val_accuracy: 0.6377
Epoch 130/500
140/140 - 18s - loss: 0.6393 - accuracy: 0.6581 - val_loss: 0.6305 - val_accuracy: 0.6431
Epoch 131/500
140/140 - 18s - loss: 0.6378 - accuracy: 0.6592 - val_loss: 0.6293 - val_accuracy: 0.6467
Epoch 132/500
140/140 - 18s - loss: 0.6481 - accuracy: 0.6514 - val_loss: 0.6285 - val_accuracy: 0.6540
Epoch 133/500
140/140 - 18s - loss: 0.6213 - accuracy: 0.6661 - val_loss: 0.6277 - val_accuracy: 0.6449
Epoch 134/500
140/140 - 18s - loss: 0.6302 - accuracy: 0.6635 - val_loss: 0.6266 - val_accuracy: 0.6467
Epoch 135/500
140/140 - 18s - loss: 0.6185 - accuracy: 0.6742 - val_loss: 0.6258 - val_accuracy: 0.6413
Epoch 136/500
140/140 - 18s - loss: 0.6270 - accuracy: 0.6740 - val_loss: 0.6252 - val_accuracy: 0.6449
Epoch 137/500
140/140 - 18s - loss: 0.6125 - accuracy: 0.6724 - val_loss: 0.6250 - val_accuracy: 0.6486
Epoch 138/500
140/140 - 18s - loss: 0.6317 - accuracy: 0.6735 - val_loss: 0.6243 - val_accuracy: 0.6449
Epoch 139/500
140/140 - 18s - loss: 0.6236 - accuracy: 0.6762 - val_loss: 0.6226 - val_accuracy: 0.6522
Epoch 140/500
140/140 - 18s - loss: 0.6065 - accuracy: 0.6836 - val_loss: 0.6218 - val_accuracy: 0.6504
Epoch 141/500
140/140 - 18s - loss: 0.6071 - accuracy: 0.6843 - val_loss: 0.6212 - val_accuracy: 0.6522
Epoch 142/500
140/140 - 18s - loss: 0.5978 - accuracy: 0.6863 - val_loss: 0.6207 - val_accuracy: 0.6486
Epoch 143/500
140/140 - 18s - loss: 0.5973 - accuracy: 0.6890 - val_loss: 0.6195 - val_accuracy: 0.6540
Epoch 144/500
140/140 - 18s - loss: 0.6080 - accuracy: 0.6807 - val_loss: 0.6186 - val_accuracy: 0.6504
Epoch 145/500
140/140 - 18s - loss: 0.5878 - accuracy: 0.7026 - val_loss: 0.6183 - val_accuracy: 0.6558
Epoch 146/500
140/140 - 18s - loss: 0.5910 - accuracy: 0.6950 - val_loss: 0.6185 - val_accuracy: 0.6522
Epoch 147/500
140/140 - 18s - loss: 0.5914 - accuracy: 0.6937 - val_loss: 0.6173 - val_accuracy: 0.6558
Epoch 148/500
140/140 - 18s - loss: 0.5924 - accuracy: 0.6988 - val_loss: 0.6162 - val_accuracy: 0.6540
Epoch 149/500
140/140 - 18s - loss: 0.5756 - accuracy: 0.7026 - val_loss: 0.6156 - val_accuracy: 0.6594
Epoch 150/500
140/140 - 18s - loss: 0.5773 - accuracy: 0.7109 - val_loss: 0.6154 - val_accuracy: 0.6558
Epoch 151/500
140/140 - 18s - loss: 0.5656 - accuracy: 0.7118 - val_loss: 0.6151 - val_accuracy: 0.6594
Epoch 152/500
140/140 - 18s - loss: 0.5608 - accuracy: 0.7159 - val_loss: 0.6141 - val_accuracy: 0.6649
Epoch 153/500
140/140 - 18s - loss: 0.5526 - accuracy: 0.7232 - val_loss: 0.6132 - val_accuracy: 0.6612
Epoch 154/500
140/140 - 18s - loss: 0.5518 - accuracy: 0.7217 - val_loss: 0.6126 - val_accuracy: 0.6649
Epoch 155/500
140/140 - 18s - loss: 0.5540 - accuracy: 0.7201 - val_loss: 0.6119 - val_accuracy: 0.6667
Epoch 156/500
140/140 - 18s - loss: 0.5531 - accuracy: 0.7232 - val_loss: 0.6122 - val_accuracy: 0.6649
Epoch 157/500
140/140 - 18s - loss: 0.5479 - accuracy: 0.7259 - val_loss: 0.6119 - val_accuracy: 0.6630
Epoch 158/500
140/140 - 18s - loss: 0.5416 - accuracy: 0.7356 - val_loss: 0.6117 - val_accuracy: 0.6630
Epoch 159/500
140/140 - 18s - loss: 0.5236 - accuracy: 0.7447 - val_loss: 0.6120 - val_accuracy: 0.6667
Epoch 160/500
140/140 - 18s - loss: 0.5356 - accuracy: 0.7333 - val_loss: 0.6111 - val_accuracy: 0.6667
Epoch 161/500
140/140 - 18s - loss: 0.5291 - accuracy: 0.7405 - val_loss: 0.6115 - val_accuracy: 0.6685
Epoch 162/500
140/140 - 18s - loss: 0.5274 - accuracy: 0.7441 - val_loss: 0.6106 - val_accuracy: 0.6721
Epoch 163/500
140/140 - 18s - loss: 0.5017 - accuracy: 0.7550 - val_loss: 0.6102 - val_accuracy: 0.6703
Epoch 164/500
140/140 - 18s - loss: 0.5206 - accuracy: 0.7425 - val_loss: 0.6104 - val_accuracy: 0.6703
Epoch 165/500
140/140 - 18s - loss: 0.5141 - accuracy: 0.7553 - val_loss: 0.6101 - val_accuracy: 0.6703
Epoch 166/500
140/140 - 18s - loss: 0.5082 - accuracy: 0.7485 - val_loss: 0.6106 - val_accuracy: 0.6703
Epoch 167/500
140/140 - 18s - loss: 0.5086 - accuracy: 0.7510 - val_loss: 0.6104 - val_accuracy: 0.6703
Epoch 168/500
140/140 - 18s - loss: 0.5190 - accuracy: 0.7521 - val_loss: 0.6101 - val_accuracy: 0.6721
Epoch 169/500
140/140 - 18s - loss: 0.4926 - accuracy: 0.7633 - val_loss: 0.6110 - val_accuracy: 0.6667
Epoch 170/500
140/140 - 18s - loss: 0.4792 - accuracy: 0.7794 - val_loss: 0.6111 - val_accuracy: 0.6739
Epoch 171/500
140/140 - 18s - loss: 0.4923 - accuracy: 0.7550 - val_loss: 0.6110 - val_accuracy: 0.6685
Epoch 172/500
140/140 - 18s - loss: 0.4772 - accuracy: 0.7723 - val_loss: 0.6117 - val_accuracy: 0.6721
Epoch 173/500
140/140 - 18s - loss: 0.4713 - accuracy: 0.7756 - val_loss: 0.6121 - val_accuracy: 0.6667
Epoch 174/500
140/140 - 18s - loss: 0.4716 - accuracy: 0.7716 - val_loss: 0.6127 - val_accuracy: 0.6703
Epoch 175/500
140/140 - 18s - loss: 0.4686 - accuracy: 0.7761 - val_loss: 0.6127 - val_accuracy: 0.6757
Epoch 176/500
140/140 - 18s - loss: 0.4605 - accuracy: 0.7806 - val_loss: 0.6124 - val_accuracy: 0.6757
Epoch 177/500
140/140 - 18s - loss: 0.4547 - accuracy: 0.7783 - val_loss: 0.6138 - val_accuracy: 0.6739
Epoch 178/500
140/140 - 18s - loss: 0.4617 - accuracy: 0.7781 - val_loss: 0.6145 - val_accuracy: 0.6703
Epoch 179/500
140/140 - 18s - loss: 0.4465 - accuracy: 0.7978 - val_loss: 0.6148 - val_accuracy: 0.6721
Epoch 180/500
140/140 - 18s - loss: 0.4351 - accuracy: 0.7991 - val_loss: 0.6155 - val_accuracy: 0.6721
Epoch 181/500
140/140 - 18s - loss: 0.4445 - accuracy: 0.7940 - val_loss: 0.6158 - val_accuracy: 0.6739
Epoch 182/500
140/140 - 18s - loss: 0.4284 - accuracy: 0.7989 - val_loss: 0.6164 - val_accuracy: 0.6775
Epoch 183/500
140/140 - 18s - loss: 0.4358 - accuracy: 0.7931 - val_loss: 0.6177 - val_accuracy: 0.6812
Epoch 184/500
140/140 - 18s - loss: 0.4430 - accuracy: 0.7868 - val_loss: 0.6181 - val_accuracy: 0.6812
Epoch 185/500
140/140 - 18s - loss: 0.4242 - accuracy: 0.8079 - val_loss: 0.6179 - val_accuracy: 0.6793
Epoch 186/500
140/140 - 18s - loss: 0.4293 - accuracy: 0.7985 - val_loss: 0.6186 - val_accuracy: 0.6775
Epoch 187/500
140/140 - 18s - loss: 0.4234 - accuracy: 0.8139 - val_loss: 0.6191 - val_accuracy: 0.6757
Epoch 188/500
140/140 - 18s - loss: 0.4299 - accuracy: 0.7983 - val_loss: 0.6200 - val_accuracy: 0.6757
Epoch 189/500
140/140 - 18s - loss: 0.4082 - accuracy: 0.8086 - val_loss: 0.6208 - val_accuracy: 0.6757
Epoch 190/500
140/140 - 18s - loss: 0.4094 - accuracy: 0.8128 - val_loss: 0.6206 - val_accuracy: 0.6739
Epoch 191/500
140/140 - 18s - loss: 0.4000 - accuracy: 0.8215 - val_loss: 0.6229 - val_accuracy: 0.6812
Epoch 192/500
140/140 - 18s - loss: 0.3890 - accuracy: 0.8189 - val_loss: 0.6234 - val_accuracy: 0.6775
Epoch 193/500
140/140 - 18s - loss: 0.3958 - accuracy: 0.8222 - val_loss: 0.6241 - val_accuracy: 0.6812
Epoch 194/500
140/140 - 18s - loss: 0.3808 - accuracy: 0.8296 - val_loss: 0.6243 - val_accuracy: 0.6793
Epoch 195/500
140/140 - 18s - loss: 0.3936 - accuracy: 0.8242 - val_loss: 0.6261 - val_accuracy: 0.6775
Epoch 196/500
140/140 - 18s - loss: 0.3820 - accuracy: 0.8258 - val_loss: 0.6274 - val_accuracy: 0.6775
Epoch 197/500
140/140 - 18s - loss: 0.3793 - accuracy: 0.8292 - val_loss: 0.6277 - val_accuracy: 0.6793
Epoch 198/500
140/140 - 18s - loss: 0.3729 - accuracy: 0.8287 - val_loss: 0.6299 - val_accuracy: 0.6812
Epoch 199/500
140/140 - 18s - loss: 0.3749 - accuracy: 0.8298 - val_loss: 0.6323 - val_accuracy: 0.6848
Epoch 200/500
140/140 - 18s - loss: 0.3671 - accuracy: 0.8363 - val_loss: 0.6332 - val_accuracy: 0.6812
Epoch 201/500
140/140 - 18s - loss: 0.3674 - accuracy: 0.8356 - val_loss: 0.6351 - val_accuracy: 0.6775
Epoch 202/500
140/140 - 18s - loss: 0.3559 - accuracy: 0.8446 - val_loss: 0.6372 - val_accuracy: 0.6812
Epoch 203/500
140/140 - 18s - loss: 0.3494 - accuracy: 0.8430 - val_loss: 0.6380 - val_accuracy: 0.6757
Epoch 204/500
140/140 - 18s - loss: 0.3457 - accuracy: 0.8442 - val_loss: 0.6394 - val_accuracy: 0.6739
Epoch 205/500
140/140 - 18s - loss: 0.3512 - accuracy: 0.8471 - val_loss: 0.6393 - val_accuracy: 0.6757
Epoch 206/500
140/140 - 18s - loss: 0.3374 - accuracy: 0.8495 - val_loss: 0.6404 - val_accuracy: 0.6703
Epoch 207/500
140/140 - 18s - loss: 0.3400 - accuracy: 0.8513 - val_loss: 0.6431 - val_accuracy: 0.6703
Epoch 208/500
140/140 - 18s - loss: 0.3422 - accuracy: 0.8529 - val_loss: 0.6452 - val_accuracy: 0.6739
Epoch 209/500
140/140 - 18s - loss: 0.3254 - accuracy: 0.8609 - val_loss: 0.6476 - val_accuracy: 0.6685
Epoch 210/500
140/140 - 18s - loss: 0.3422 - accuracy: 0.8522 - val_loss: 0.6493 - val_accuracy: 0.6703
Epoch 211/500
140/140 - 18s - loss: 0.3279 - accuracy: 0.8562 - val_loss: 0.6496 - val_accuracy: 0.6739
Epoch 212/500
140/140 - 18s - loss: 0.3138 - accuracy: 0.8645 - val_loss: 0.6530 - val_accuracy: 0.6757
Epoch 213/500
140/140 - 18s - loss: 0.3170 - accuracy: 0.8650 - val_loss: 0.6539 - val_accuracy: 0.6739
Epoch 214/500
140/140 - 18s - loss: 0.3090 - accuracy: 0.8677 - val_loss: 0.6560 - val_accuracy: 0.6757
Epoch 215/500
140/140 - 18s - loss: 0.3077 - accuracy: 0.8657 - val_loss: 0.6583 - val_accuracy: 0.6739
Epoch 216/500
140/140 - 18s - loss: 0.3068 - accuracy: 0.8677 - val_loss: 0.6604 - val_accuracy: 0.6739
Epoch 217/500
140/140 - 18s - loss: 0.3167 - accuracy: 0.8641 - val_loss: 0.6595 - val_accuracy: 0.6757
Epoch 218/500
140/140 - 18s - loss: 0.3217 - accuracy: 0.8609 - val_loss: 0.6601 - val_accuracy: 0.6775
Epoch 219/500
140/140 - 18s - loss: 0.2896 - accuracy: 0.8742 - val_loss: 0.6633 - val_accuracy: 0.6757
========================================
save_weights
h5_weights/GM.pp/embedding_dense.h5
========================================

end time >>> Sun Oct  3 05:00:16 2021

end time >>> Sun Oct  3 05:00:16 2021

end time >>> Sun Oct  3 05:00:16 2021

end time >>> Sun Oct  3 05:00:16 2021

end time >>> Sun Oct  3 05:00:16 2021












args.model = embedding_dense
time used = 3918.5293185710907


************************************
************************************

    Welcome to use DeepChromeHiC

************************************
************************************

begin time >>> Sun Oct  3 05:00:18 2021

begin time >>> Sun Oct  3 05:00:18 2021

begin time >>> Sun Oct  3 05:00:18 2021

begin time >>> Sun Oct  3 05:00:18 2021

begin time >>> Sun Oct  3 05:00:18 2021



If it is the first time to use, please preprocess the data first.
Use the command: python3 DeepChromeHiC.py -p true -n [gene name]
For example: python3 DeepChromeHiC.py -p true -n AD2.po


=== Below is your input ===

args.model = embedding_cnn_one_branch
args.type = train
args.name = GM.pp
args.length = 10001
===========================


-> h5_weights/GM.pp folder already exist. pass.
-> result/GM.pp/onehot_cnn_one_branch folder already exist. pass.
-> result/GM.pp/onehot_cnn_two_branch folder already exist. pass.
-> result/GM.pp/onehot_embedding_dense folder already exist. pass.
-> result/GM.pp/onehot_dense folder already exist. pass.
-> result/GM.pp/onehot_resnet18 folder already exist. pass.
-> result/GM.pp/onehot_resnet34 folder already exist. pass.
-> result/GM.pp/embedding_cnn_one_branch folder already exist. pass.
-> result/GM.pp/embedding_cnn_two_branch folder already exist. pass.
-> result/GM.pp/embedding_dense folder already exist. pass.
-> result/GM.pp/onehot_embedding_cnn_one_branch folder already exist. pass.
-> result/GM.pp/onehot_embedding_cnn_two_branch folder already exist. pass.
########################################
gen_name
GM.pp
########################################

########################################
model_name
embedding_cnn_one_branch
########################################

Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 10001, 100)   409700      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 10001, 100)   409700      input_2[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 20002, 100)   0           embedding[0][0]                  
                                                                 embedding_1[0][0]                
__________________________________________________________________________________________________
sequential (Sequential)         (None, 155, 64)      205888      concatenate[0][0]                
__________________________________________________________________________________________________
flatten (Flatten)               (None, 9920)         0           sequential[0][0]                 
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 9920)         39680       flatten[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 9920)         0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dense (Dense)                   (None, 512)          5079552     dropout[0][0]                    
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 512)          2048        dense[0][0]                      
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 512)          0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           activation_4[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 512)          2048        dense_1[0][0]                    
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 512)          0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           activation_5[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_2[0][0]                  
==================================================================================================
Total params: 6,411,785
Trainable params: 6,389,385
Non-trainable params: 22,400
__________________________________________________________________________________________________
Epoch 1/500
140/140 - 19s - loss: 0.9392 - accuracy: 0.4893 - val_loss: 0.6938 - val_accuracy: 0.5217
Epoch 2/500
140/140 - 19s - loss: 0.9072 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5489
Epoch 3/500
140/140 - 19s - loss: 0.8944 - accuracy: 0.5069 - val_loss: 0.6916 - val_accuracy: 0.5525
Epoch 4/500
140/140 - 19s - loss: 0.8883 - accuracy: 0.5029 - val_loss: 0.6906 - val_accuracy: 0.5652
Epoch 5/500
140/140 - 19s - loss: 0.8570 - accuracy: 0.5110 - val_loss: 0.6884 - val_accuracy: 0.5634
Epoch 6/500
140/140 - 19s - loss: 0.8634 - accuracy: 0.5078 - val_loss: 0.6869 - val_accuracy: 0.5707
Epoch 7/500
140/140 - 19s - loss: 0.8507 - accuracy: 0.5125 - val_loss: 0.6860 - val_accuracy: 0.5634
Epoch 8/500
140/140 - 19s - loss: 0.8384 - accuracy: 0.5287 - val_loss: 0.6852 - val_accuracy: 0.5525
Epoch 9/500
140/140 - 19s - loss: 0.8387 - accuracy: 0.5197 - val_loss: 0.6830 - val_accuracy: 0.5634
Epoch 10/500
140/140 - 19s - loss: 0.8085 - accuracy: 0.5383 - val_loss: 0.6816 - val_accuracy: 0.5670
Epoch 11/500
140/140 - 19s - loss: 0.8202 - accuracy: 0.5258 - val_loss: 0.6807 - val_accuracy: 0.5670
Epoch 12/500
140/140 - 19s - loss: 0.7934 - accuracy: 0.5490 - val_loss: 0.6794 - val_accuracy: 0.5707
Epoch 13/500
140/140 - 19s - loss: 0.7974 - accuracy: 0.5504 - val_loss: 0.6783 - val_accuracy: 0.5725
Epoch 14/500
140/140 - 19s - loss: 0.8135 - accuracy: 0.5269 - val_loss: 0.6770 - val_accuracy: 0.5707
Epoch 15/500
140/140 - 19s - loss: 0.7986 - accuracy: 0.5401 - val_loss: 0.6772 - val_accuracy: 0.5598
Epoch 16/500
140/140 - 19s - loss: 0.7894 - accuracy: 0.5490 - val_loss: 0.6752 - val_accuracy: 0.5725
Epoch 17/500
140/140 - 19s - loss: 0.7983 - accuracy: 0.5468 - val_loss: 0.6746 - val_accuracy: 0.5670
Epoch 18/500
140/140 - 19s - loss: 0.7667 - accuracy: 0.5638 - val_loss: 0.6734 - val_accuracy: 0.5707
Epoch 19/500
140/140 - 19s - loss: 0.7835 - accuracy: 0.5513 - val_loss: 0.6721 - val_accuracy: 0.5707
Epoch 20/500
140/140 - 19s - loss: 0.7451 - accuracy: 0.5797 - val_loss: 0.6702 - val_accuracy: 0.5761
Epoch 21/500
140/140 - 19s - loss: 0.7488 - accuracy: 0.5717 - val_loss: 0.6685 - val_accuracy: 0.5761
Epoch 22/500
140/140 - 19s - loss: 0.7491 - accuracy: 0.5824 - val_loss: 0.6675 - val_accuracy: 0.5761
Epoch 23/500
140/140 - 19s - loss: 0.7461 - accuracy: 0.5858 - val_loss: 0.6669 - val_accuracy: 0.5833
Epoch 24/500
140/140 - 19s - loss: 0.7450 - accuracy: 0.5725 - val_loss: 0.6651 - val_accuracy: 0.5851
Epoch 25/500
140/140 - 19s - loss: 0.7311 - accuracy: 0.5945 - val_loss: 0.6647 - val_accuracy: 0.5870
Epoch 26/500
140/140 - 19s - loss: 0.7331 - accuracy: 0.5851 - val_loss: 0.6631 - val_accuracy: 0.5888
Epoch 27/500
140/140 - 19s - loss: 0.7264 - accuracy: 0.5963 - val_loss: 0.6624 - val_accuracy: 0.5906
Epoch 28/500
140/140 - 19s - loss: 0.7373 - accuracy: 0.5815 - val_loss: 0.6612 - val_accuracy: 0.5960
Epoch 29/500
140/140 - 19s - loss: 0.7294 - accuracy: 0.5907 - val_loss: 0.6601 - val_accuracy: 0.5851
Epoch 30/500
140/140 - 19s - loss: 0.7242 - accuracy: 0.5949 - val_loss: 0.6587 - val_accuracy: 0.5942
Epoch 31/500
140/140 - 19s - loss: 0.7083 - accuracy: 0.6061 - val_loss: 0.6575 - val_accuracy: 0.5942
Epoch 32/500
140/140 - 19s - loss: 0.7057 - accuracy: 0.6120 - val_loss: 0.6565 - val_accuracy: 0.5942
Epoch 33/500
140/140 - 19s - loss: 0.7005 - accuracy: 0.6048 - val_loss: 0.6555 - val_accuracy: 0.6014
Epoch 34/500
140/140 - 19s - loss: 0.7049 - accuracy: 0.6111 - val_loss: 0.6538 - val_accuracy: 0.5942
Epoch 35/500
140/140 - 19s - loss: 0.7007 - accuracy: 0.6149 - val_loss: 0.6531 - val_accuracy: 0.5978
Epoch 36/500
140/140 - 19s - loss: 0.6820 - accuracy: 0.6232 - val_loss: 0.6518 - val_accuracy: 0.6069
Epoch 37/500
140/140 - 19s - loss: 0.6840 - accuracy: 0.6227 - val_loss: 0.6507 - val_accuracy: 0.6123
Epoch 38/500
140/140 - 19s - loss: 0.6681 - accuracy: 0.6337 - val_loss: 0.6516 - val_accuracy: 0.6033
Epoch 39/500
140/140 - 19s - loss: 0.6703 - accuracy: 0.6332 - val_loss: 0.6499 - val_accuracy: 0.6123
Epoch 40/500
140/140 - 19s - loss: 0.6608 - accuracy: 0.6384 - val_loss: 0.6487 - val_accuracy: 0.6087
Epoch 41/500
140/140 - 19s - loss: 0.6678 - accuracy: 0.6382 - val_loss: 0.6477 - val_accuracy: 0.6123
Epoch 42/500
140/140 - 19s - loss: 0.6562 - accuracy: 0.6377 - val_loss: 0.6472 - val_accuracy: 0.6159
Epoch 43/500
140/140 - 19s - loss: 0.6319 - accuracy: 0.6646 - val_loss: 0.6452 - val_accuracy: 0.6178
Epoch 44/500
140/140 - 19s - loss: 0.6494 - accuracy: 0.6511 - val_loss: 0.6442 - val_accuracy: 0.6123
Epoch 45/500
140/140 - 19s - loss: 0.6542 - accuracy: 0.6527 - val_loss: 0.6443 - val_accuracy: 0.6178
Epoch 46/500
140/140 - 19s - loss: 0.6430 - accuracy: 0.6599 - val_loss: 0.6424 - val_accuracy: 0.6196
Epoch 47/500
140/140 - 19s - loss: 0.6326 - accuracy: 0.6597 - val_loss: 0.6425 - val_accuracy: 0.6196
Epoch 48/500
140/140 - 19s - loss: 0.6392 - accuracy: 0.6608 - val_loss: 0.6411 - val_accuracy: 0.6196
Epoch 49/500
140/140 - 19s - loss: 0.6096 - accuracy: 0.6769 - val_loss: 0.6393 - val_accuracy: 0.6196
Epoch 50/500
140/140 - 19s - loss: 0.6196 - accuracy: 0.6688 - val_loss: 0.6393 - val_accuracy: 0.6196
Epoch 51/500
140/140 - 19s - loss: 0.6230 - accuracy: 0.6673 - val_loss: 0.6385 - val_accuracy: 0.6214
Epoch 52/500
140/140 - 19s - loss: 0.6046 - accuracy: 0.6935 - val_loss: 0.6368 - val_accuracy: 0.6232
Epoch 53/500
140/140 - 19s - loss: 0.6025 - accuracy: 0.6854 - val_loss: 0.6376 - val_accuracy: 0.6214
Epoch 54/500
140/140 - 19s - loss: 0.5914 - accuracy: 0.6803 - val_loss: 0.6360 - val_accuracy: 0.6196
Epoch 55/500
140/140 - 19s - loss: 0.5960 - accuracy: 0.6858 - val_loss: 0.6345 - val_accuracy: 0.6286
Epoch 56/500
140/140 - 19s - loss: 0.5896 - accuracy: 0.6903 - val_loss: 0.6345 - val_accuracy: 0.6232
Epoch 57/500
140/140 - 19s - loss: 0.5724 - accuracy: 0.7051 - val_loss: 0.6329 - val_accuracy: 0.6268
Epoch 58/500
140/140 - 19s - loss: 0.5699 - accuracy: 0.7069 - val_loss: 0.6340 - val_accuracy: 0.6268
Epoch 59/500
140/140 - 19s - loss: 0.5592 - accuracy: 0.7145 - val_loss: 0.6323 - val_accuracy: 0.6304
Epoch 60/500
140/140 - 19s - loss: 0.5631 - accuracy: 0.7132 - val_loss: 0.6317 - val_accuracy: 0.6322
Epoch 61/500
140/140 - 19s - loss: 0.5577 - accuracy: 0.7163 - val_loss: 0.6308 - val_accuracy: 0.6322
Epoch 62/500
140/140 - 19s - loss: 0.5562 - accuracy: 0.7226 - val_loss: 0.6288 - val_accuracy: 0.6341
Epoch 63/500
140/140 - 19s - loss: 0.5538 - accuracy: 0.7170 - val_loss: 0.6290 - val_accuracy: 0.6377
Epoch 64/500
140/140 - 19s - loss: 0.5420 - accuracy: 0.7219 - val_loss: 0.6285 - val_accuracy: 0.6395
Epoch 65/500
140/140 - 19s - loss: 0.5427 - accuracy: 0.7282 - val_loss: 0.6273 - val_accuracy: 0.6413
Epoch 66/500
140/140 - 19s - loss: 0.5227 - accuracy: 0.7436 - val_loss: 0.6258 - val_accuracy: 0.6449
Epoch 67/500
140/140 - 19s - loss: 0.5323 - accuracy: 0.7288 - val_loss: 0.6274 - val_accuracy: 0.6467
Epoch 68/500
140/140 - 19s - loss: 0.5236 - accuracy: 0.7398 - val_loss: 0.6268 - val_accuracy: 0.6431
Epoch 69/500
140/140 - 19s - loss: 0.5120 - accuracy: 0.7497 - val_loss: 0.6275 - val_accuracy: 0.6431
Epoch 70/500
140/140 - 19s - loss: 0.5090 - accuracy: 0.7521 - val_loss: 0.6277 - val_accuracy: 0.6413
Epoch 71/500
140/140 - 19s - loss: 0.4985 - accuracy: 0.7526 - val_loss: 0.6264 - val_accuracy: 0.6431
Epoch 72/500
140/140 - 19s - loss: 0.4977 - accuracy: 0.7622 - val_loss: 0.6259 - val_accuracy: 0.6522
Epoch 73/500
140/140 - 19s - loss: 0.4998 - accuracy: 0.7515 - val_loss: 0.6267 - val_accuracy: 0.6522
Epoch 74/500
140/140 - 19s - loss: 0.4899 - accuracy: 0.7656 - val_loss: 0.6274 - val_accuracy: 0.6467
Epoch 75/500
140/140 - 19s - loss: 0.5004 - accuracy: 0.7535 - val_loss: 0.6255 - val_accuracy: 0.6558
Epoch 76/500
140/140 - 19s - loss: 0.4775 - accuracy: 0.7725 - val_loss: 0.6274 - val_accuracy: 0.6504
Epoch 77/500
140/140 - 19s - loss: 0.4765 - accuracy: 0.7721 - val_loss: 0.6273 - val_accuracy: 0.6540
Epoch 78/500
140/140 - 19s - loss: 0.4674 - accuracy: 0.7714 - val_loss: 0.6267 - val_accuracy: 0.6522
Epoch 79/500
140/140 - 19s - loss: 0.4642 - accuracy: 0.7779 - val_loss: 0.6267 - val_accuracy: 0.6504
Epoch 80/500
140/140 - 19s - loss: 0.4646 - accuracy: 0.7797 - val_loss: 0.6273 - val_accuracy: 0.6540
Epoch 81/500
140/140 - 19s - loss: 0.4496 - accuracy: 0.7893 - val_loss: 0.6267 - val_accuracy: 0.6504
Epoch 82/500
140/140 - 19s - loss: 0.4549 - accuracy: 0.7855 - val_loss: 0.6269 - val_accuracy: 0.6486
Epoch 83/500
140/140 - 19s - loss: 0.4435 - accuracy: 0.7962 - val_loss: 0.6291 - val_accuracy: 0.6504
Epoch 84/500
140/140 - 19s - loss: 0.4452 - accuracy: 0.7868 - val_loss: 0.6303 - val_accuracy: 0.6504
Epoch 85/500
140/140 - 19s - loss: 0.4395 - accuracy: 0.7971 - val_loss: 0.6293 - val_accuracy: 0.6522
Epoch 86/500
140/140 - 19s - loss: 0.4363 - accuracy: 0.7886 - val_loss: 0.6315 - val_accuracy: 0.6540
Epoch 87/500
140/140 - 19s - loss: 0.4271 - accuracy: 0.8043 - val_loss: 0.6295 - val_accuracy: 0.6522
Epoch 88/500
140/140 - 19s - loss: 0.4209 - accuracy: 0.8043 - val_loss: 0.6312 - val_accuracy: 0.6540
Epoch 89/500
140/140 - 19s - loss: 0.4217 - accuracy: 0.8030 - val_loss: 0.6303 - val_accuracy: 0.6540
Epoch 90/500
140/140 - 19s - loss: 0.4095 - accuracy: 0.8142 - val_loss: 0.6311 - val_accuracy: 0.6522
Epoch 91/500
140/140 - 19s - loss: 0.4149 - accuracy: 0.8081 - val_loss: 0.6332 - val_accuracy: 0.6576
Epoch 92/500
140/140 - 19s - loss: 0.3950 - accuracy: 0.8215 - val_loss: 0.6329 - val_accuracy: 0.6576
Epoch 93/500
140/140 - 19s - loss: 0.4071 - accuracy: 0.8162 - val_loss: 0.6329 - val_accuracy: 0.6540
Epoch 94/500
140/140 - 19s - loss: 0.3951 - accuracy: 0.8200 - val_loss: 0.6356 - val_accuracy: 0.6522
Epoch 95/500
140/140 - 19s - loss: 0.4061 - accuracy: 0.8101 - val_loss: 0.6365 - val_accuracy: 0.6576
Epoch 96/500
140/140 - 19s - loss: 0.3831 - accuracy: 0.8220 - val_loss: 0.6392 - val_accuracy: 0.6558
Epoch 97/500
140/140 - 19s - loss: 0.3957 - accuracy: 0.8184 - val_loss: 0.6377 - val_accuracy: 0.6576
Epoch 98/500
140/140 - 19s - loss: 0.3932 - accuracy: 0.8206 - val_loss: 0.6388 - val_accuracy: 0.6594
Epoch 99/500
140/140 - 19s - loss: 0.3705 - accuracy: 0.8352 - val_loss: 0.6410 - val_accuracy: 0.6522
Epoch 100/500
140/140 - 19s - loss: 0.3557 - accuracy: 0.8439 - val_loss: 0.6405 - val_accuracy: 0.6540
Epoch 101/500
140/140 - 19s - loss: 0.3550 - accuracy: 0.8383 - val_loss: 0.6426 - val_accuracy: 0.6540
Epoch 102/500
140/140 - 19s - loss: 0.3659 - accuracy: 0.8361 - val_loss: 0.6422 - val_accuracy: 0.6576
Epoch 103/500
140/140 - 19s - loss: 0.3702 - accuracy: 0.8321 - val_loss: 0.6459 - val_accuracy: 0.6522
Epoch 104/500
140/140 - 19s - loss: 0.3572 - accuracy: 0.8475 - val_loss: 0.6454 - val_accuracy: 0.6576
Epoch 105/500
140/140 - 19s - loss: 0.3645 - accuracy: 0.8359 - val_loss: 0.6452 - val_accuracy: 0.6612
Epoch 106/500
140/140 - 19s - loss: 0.3457 - accuracy: 0.8480 - val_loss: 0.6471 - val_accuracy: 0.6612
Epoch 107/500
140/140 - 19s - loss: 0.3468 - accuracy: 0.8498 - val_loss: 0.6476 - val_accuracy: 0.6612
Epoch 108/500
140/140 - 19s - loss: 0.3548 - accuracy: 0.8421 - val_loss: 0.6476 - val_accuracy: 0.6630
Epoch 109/500
140/140 - 19s - loss: 0.3317 - accuracy: 0.8533 - val_loss: 0.6504 - val_accuracy: 0.6667
Epoch 110/500
140/140 - 19s - loss: 0.3371 - accuracy: 0.8545 - val_loss: 0.6514 - val_accuracy: 0.6649
Epoch 111/500
140/140 - 19s - loss: 0.3404 - accuracy: 0.8448 - val_loss: 0.6521 - val_accuracy: 0.6667
Epoch 112/500
140/140 - 19s - loss: 0.3235 - accuracy: 0.8623 - val_loss: 0.6533 - val_accuracy: 0.6685
Epoch 113/500
140/140 - 19s - loss: 0.3243 - accuracy: 0.8652 - val_loss: 0.6549 - val_accuracy: 0.6612
Epoch 114/500
140/140 - 19s - loss: 0.3231 - accuracy: 0.8605 - val_loss: 0.6553 - val_accuracy: 0.6630
Epoch 115/500
140/140 - 19s - loss: 0.3150 - accuracy: 0.8690 - val_loss: 0.6587 - val_accuracy: 0.6667
Epoch 116/500
140/140 - 19s - loss: 0.3176 - accuracy: 0.8623 - val_loss: 0.6617 - val_accuracy: 0.6558
Epoch 117/500
140/140 - 19s - loss: 0.3096 - accuracy: 0.8679 - val_loss: 0.6625 - val_accuracy: 0.6612
Epoch 118/500
140/140 - 19s - loss: 0.3056 - accuracy: 0.8708 - val_loss: 0.6618 - val_accuracy: 0.6649
Epoch 119/500
140/140 - 19s - loss: 0.3052 - accuracy: 0.8719 - val_loss: 0.6650 - val_accuracy: 0.6612
Epoch 120/500
140/140 - 19s - loss: 0.2980 - accuracy: 0.8742 - val_loss: 0.6662 - val_accuracy: 0.6649
Epoch 121/500
140/140 - 19s - loss: 0.2984 - accuracy: 0.8683 - val_loss: 0.6708 - val_accuracy: 0.6594
Epoch 122/500
140/140 - 19s - loss: 0.2852 - accuracy: 0.8811 - val_loss: 0.6714 - val_accuracy: 0.6649
Epoch 123/500
140/140 - 19s - loss: 0.2988 - accuracy: 0.8724 - val_loss: 0.6712 - val_accuracy: 0.6703
Epoch 124/500
140/140 - 19s - loss: 0.2939 - accuracy: 0.8719 - val_loss: 0.6738 - val_accuracy: 0.6721
Epoch 125/500
140/140 - 19s - loss: 0.2923 - accuracy: 0.8766 - val_loss: 0.6732 - val_accuracy: 0.6703
Epoch 126/500
140/140 - 19s - loss: 0.2778 - accuracy: 0.8847 - val_loss: 0.6747 - val_accuracy: 0.6721
Epoch 127/500
140/140 - 19s - loss: 0.2826 - accuracy: 0.8833 - val_loss: 0.6775 - val_accuracy: 0.6721
Epoch 128/500
140/140 - 19s - loss: 0.2766 - accuracy: 0.8885 - val_loss: 0.6802 - val_accuracy: 0.6757
Epoch 129/500
140/140 - 19s - loss: 0.2700 - accuracy: 0.8871 - val_loss: 0.6804 - val_accuracy: 0.6739
Epoch 130/500
140/140 - 19s - loss: 0.2671 - accuracy: 0.8883 - val_loss: 0.6809 - val_accuracy: 0.6739
Epoch 131/500
140/140 - 19s - loss: 0.2780 - accuracy: 0.8833 - val_loss: 0.6840 - val_accuracy: 0.6739
Epoch 132/500
140/140 - 19s - loss: 0.2534 - accuracy: 0.8948 - val_loss: 0.6855 - val_accuracy: 0.6757
Epoch 133/500
140/140 - 19s - loss: 0.2659 - accuracy: 0.8927 - val_loss: 0.6914 - val_accuracy: 0.6775
Epoch 134/500
140/140 - 19s - loss: 0.2540 - accuracy: 0.8943 - val_loss: 0.6907 - val_accuracy: 0.6757
Epoch 135/500
140/140 - 19s - loss: 0.2408 - accuracy: 0.9030 - val_loss: 0.6920 - val_accuracy: 0.6739
Epoch 136/500
140/140 - 19s - loss: 0.2479 - accuracy: 0.9017 - val_loss: 0.6963 - val_accuracy: 0.6757
Epoch 137/500
140/140 - 19s - loss: 0.2517 - accuracy: 0.8943 - val_loss: 0.6972 - val_accuracy: 0.6793
Epoch 138/500
140/140 - 19s - loss: 0.2413 - accuracy: 0.9055 - val_loss: 0.6961 - val_accuracy: 0.6757
Epoch 139/500
140/140 - 19s - loss: 0.2564 - accuracy: 0.8954 - val_loss: 0.6974 - val_accuracy: 0.6793
Epoch 140/500
140/140 - 19s - loss: 0.2508 - accuracy: 0.8988 - val_loss: 0.7022 - val_accuracy: 0.6739
Epoch 141/500
140/140 - 19s - loss: 0.2412 - accuracy: 0.8977 - val_loss: 0.7029 - val_accuracy: 0.6812
Epoch 142/500
140/140 - 19s - loss: 0.2402 - accuracy: 0.9060 - val_loss: 0.7049 - val_accuracy: 0.6775
Epoch 143/500
140/140 - 19s - loss: 0.2396 - accuracy: 0.9001 - val_loss: 0.7071 - val_accuracy: 0.6757
Epoch 144/500
140/140 - 18s - loss: 0.2319 - accuracy: 0.9010 - val_loss: 0.7109 - val_accuracy: 0.6739
Epoch 145/500
140/140 - 19s - loss: 0.2281 - accuracy: 0.9080 - val_loss: 0.7148 - val_accuracy: 0.6739
Epoch 146/500
140/140 - 19s - loss: 0.2369 - accuracy: 0.9057 - val_loss: 0.7155 - val_accuracy: 0.6739
Epoch 147/500
140/140 - 19s - loss: 0.2259 - accuracy: 0.9109 - val_loss: 0.7172 - val_accuracy: 0.6812
Epoch 148/500
140/140 - 19s - loss: 0.2235 - accuracy: 0.9089 - val_loss: 0.7189 - val_accuracy: 0.6830
Epoch 149/500
140/140 - 19s - loss: 0.2167 - accuracy: 0.9142 - val_loss: 0.7215 - val_accuracy: 0.6848
Epoch 150/500
140/140 - 19s - loss: 0.2238 - accuracy: 0.9091 - val_loss: 0.7239 - val_accuracy: 0.6812
Epoch 151/500
140/140 - 19s - loss: 0.2217 - accuracy: 0.9073 - val_loss: 0.7243 - val_accuracy: 0.6830
Epoch 152/500
140/140 - 19s - loss: 0.2075 - accuracy: 0.9163 - val_loss: 0.7275 - val_accuracy: 0.6812
Epoch 153/500
140/140 - 19s - loss: 0.2123 - accuracy: 0.9156 - val_loss: 0.7311 - val_accuracy: 0.6812
Epoch 154/500
140/140 - 19s - loss: 0.2121 - accuracy: 0.9111 - val_loss: 0.7296 - val_accuracy: 0.6812
Epoch 155/500
140/140 - 19s - loss: 0.2058 - accuracy: 0.9154 - val_loss: 0.7325 - val_accuracy: 0.6812
Epoch 156/500
140/140 - 19s - loss: 0.2083 - accuracy: 0.9172 - val_loss: 0.7372 - val_accuracy: 0.6830
Epoch 157/500
140/140 - 19s - loss: 0.2005 - accuracy: 0.9169 - val_loss: 0.7363 - val_accuracy: 0.6793
Epoch 158/500
140/140 - 19s - loss: 0.2146 - accuracy: 0.9113 - val_loss: 0.7388 - val_accuracy: 0.6812
Epoch 159/500
140/140 - 19s - loss: 0.2000 - accuracy: 0.9183 - val_loss: 0.7453 - val_accuracy: 0.6793
Epoch 160/500
140/140 - 19s - loss: 0.2098 - accuracy: 0.9183 - val_loss: 0.7438 - val_accuracy: 0.6812
Epoch 161/500
140/140 - 19s - loss: 0.1965 - accuracy: 0.9221 - val_loss: 0.7501 - val_accuracy: 0.6775
Epoch 162/500
140/140 - 19s - loss: 0.2074 - accuracy: 0.9160 - val_loss: 0.7536 - val_accuracy: 0.6848
Epoch 163/500
140/140 - 19s - loss: 0.1924 - accuracy: 0.9212 - val_loss: 0.7503 - val_accuracy: 0.6793
Epoch 164/500
140/140 - 19s - loss: 0.1917 - accuracy: 0.9248 - val_loss: 0.7543 - val_accuracy: 0.6757
Epoch 165/500
140/140 - 19s - loss: 0.1901 - accuracy: 0.9261 - val_loss: 0.7562 - val_accuracy: 0.6812
Epoch 166/500
140/140 - 19s - loss: 0.1854 - accuracy: 0.9270 - val_loss: 0.7564 - val_accuracy: 0.6830
Epoch 167/500
140/140 - 19s - loss: 0.1870 - accuracy: 0.9286 - val_loss: 0.7585 - val_accuracy: 0.6848
Epoch 168/500
140/140 - 19s - loss: 0.1830 - accuracy: 0.9268 - val_loss: 0.7628 - val_accuracy: 0.6848
Epoch 169/500
140/140 - 19s - loss: 0.1783 - accuracy: 0.9268 - val_loss: 0.7634 - val_accuracy: 0.6848
========================================
save_weights
h5_weights/GM.pp/embedding_cnn_one_branch.h5
========================================

end time >>> Sun Oct  3 05:53:12 2021

end time >>> Sun Oct  3 05:53:12 2021

end time >>> Sun Oct  3 05:53:12 2021

end time >>> Sun Oct  3 05:53:12 2021

end time >>> Sun Oct  3 05:53:12 2021












args.model = embedding_cnn_one_branch
time used = 3174.638265132904


************************************
************************************

    Welcome to use DeepChromeHiC

************************************
************************************

begin time >>> Sun Oct  3 05:53:13 2021

begin time >>> Sun Oct  3 05:53:13 2021

begin time >>> Sun Oct  3 05:53:13 2021

begin time >>> Sun Oct  3 05:53:13 2021

begin time >>> Sun Oct  3 05:53:13 2021



If it is the first time to use, please preprocess the data first.
Use the command: python3 DeepChromeHiC.py -p true -n [gene name]
For example: python3 DeepChromeHiC.py -p true -n AD2.po


=== Below is your input ===

args.model = embedding_cnn_two_branch
args.type = train
args.name = GM.pp
args.length = 10001
===========================


-> h5_weights/GM.pp folder already exist. pass.
-> result/GM.pp/onehot_cnn_one_branch folder already exist. pass.
-> result/GM.pp/onehot_cnn_two_branch folder already exist. pass.
-> result/GM.pp/onehot_embedding_dense folder already exist. pass.
-> result/GM.pp/onehot_dense folder already exist. pass.
-> result/GM.pp/onehot_resnet18 folder already exist. pass.
-> result/GM.pp/onehot_resnet34 folder already exist. pass.
-> result/GM.pp/embedding_cnn_one_branch folder already exist. pass.
-> result/GM.pp/embedding_cnn_two_branch folder already exist. pass.
-> result/GM.pp/embedding_dense folder already exist. pass.
-> result/GM.pp/onehot_embedding_cnn_one_branch folder already exist. pass.
-> result/GM.pp/onehot_embedding_cnn_two_branch folder already exist. pass.
########################################
gen_name
GM.pp
########################################

########################################
model_name
embedding_cnn_two_branch
########################################

Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 10001)]      0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 10001, 100)   409700      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 10001, 100)   409700      input_2[0][0]                    
__________________________________________________________________________________________________
sequential (Sequential)         (None, 77, 64)       205888      embedding[0][0]                  
__________________________________________________________________________________________________
sequential_1 (Sequential)       (None, 77, 64)       205888      embedding_1[0][0]                
__________________________________________________________________________________________________
flatten (Flatten)               (None, 4928)         0           sequential[0][0]                 
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 4928)         0           sequential_1[0][0]               
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 9856)         0           flatten[0][0]                    
                                                                 flatten_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 9856)         39424       concatenate[0][0]                
__________________________________________________________________________________________________
dropout (Dropout)               (None, 9856)         0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dense (Dense)                   (None, 512)          5046784     dropout[0][0]                    
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 512)          2048        dense[0][0]                      
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 512)          2048        dense_1[0][0]                    
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           activation_9[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_2[0][0]                  
==================================================================================================
Total params: 6,584,649
Trainable params: 6,561,865
Non-trainable params: 22,784
__________________________________________________________________________________________________
Epoch 1/500
140/140 - 19s - loss: 0.8861 - accuracy: 0.4969 - val_loss: 0.6937 - val_accuracy: 0.5217
Epoch 2/500
140/140 - 19s - loss: 0.8675 - accuracy: 0.5119 - val_loss: 0.6970 - val_accuracy: 0.5217
Epoch 3/500
140/140 - 19s - loss: 0.8572 - accuracy: 0.5157 - val_loss: 0.6992 - val_accuracy: 0.5435
Epoch 4/500
140/140 - 19s - loss: 0.8346 - accuracy: 0.5190 - val_loss: 0.6996 - val_accuracy: 0.5435
Epoch 5/500
140/140 - 19s - loss: 0.8462 - accuracy: 0.5146 - val_loss: 0.6981 - val_accuracy: 0.5471
Epoch 6/500
140/140 - 19s - loss: 0.8142 - accuracy: 0.5213 - val_loss: 0.6966 - val_accuracy: 0.5507
Epoch 7/500
140/140 - 19s - loss: 0.8223 - accuracy: 0.5226 - val_loss: 0.6946 - val_accuracy: 0.5543
Epoch 8/500
140/140 - 19s - loss: 0.8103 - accuracy: 0.5291 - val_loss: 0.6928 - val_accuracy: 0.5580
Epoch 9/500
140/140 - 19s - loss: 0.8110 - accuracy: 0.5343 - val_loss: 0.6913 - val_accuracy: 0.5616
Epoch 10/500
140/140 - 19s - loss: 0.8064 - accuracy: 0.5338 - val_loss: 0.6897 - val_accuracy: 0.5598
Epoch 11/500
140/140 - 19s - loss: 0.7868 - accuracy: 0.5502 - val_loss: 0.6880 - val_accuracy: 0.5670
Epoch 12/500
140/140 - 19s - loss: 0.7791 - accuracy: 0.5560 - val_loss: 0.6857 - val_accuracy: 0.5815
Epoch 13/500
140/140 - 19s - loss: 0.7851 - accuracy: 0.5553 - val_loss: 0.6842 - val_accuracy: 0.5870
Epoch 14/500
140/140 - 19s - loss: 0.7940 - accuracy: 0.5484 - val_loss: 0.6827 - val_accuracy: 0.5851
Epoch 15/500
140/140 - 19s - loss: 0.7731 - accuracy: 0.5658 - val_loss: 0.6816 - val_accuracy: 0.5833
Epoch 16/500
140/140 - 19s - loss: 0.7730 - accuracy: 0.5562 - val_loss: 0.6798 - val_accuracy: 0.5960
Epoch 17/500
140/140 - 19s - loss: 0.7572 - accuracy: 0.5708 - val_loss: 0.6779 - val_accuracy: 0.5924
Epoch 18/500
140/140 - 19s - loss: 0.7552 - accuracy: 0.5714 - val_loss: 0.6767 - val_accuracy: 0.5906
Epoch 19/500
140/140 - 19s - loss: 0.7545 - accuracy: 0.5703 - val_loss: 0.6758 - val_accuracy: 0.5924
Epoch 20/500
140/140 - 19s - loss: 0.7558 - accuracy: 0.5717 - val_loss: 0.6744 - val_accuracy: 0.5978
Epoch 21/500
140/140 - 19s - loss: 0.7362 - accuracy: 0.5759 - val_loss: 0.6734 - val_accuracy: 0.5942
Epoch 22/500
140/140 - 19s - loss: 0.7325 - accuracy: 0.5900 - val_loss: 0.6716 - val_accuracy: 0.5942
Epoch 23/500
140/140 - 19s - loss: 0.7260 - accuracy: 0.5970 - val_loss: 0.6698 - val_accuracy: 0.6033
Epoch 24/500
140/140 - 19s - loss: 0.7210 - accuracy: 0.5943 - val_loss: 0.6687 - val_accuracy: 0.6087
Epoch 25/500
140/140 - 19s - loss: 0.7174 - accuracy: 0.5979 - val_loss: 0.6672 - val_accuracy: 0.6051
Epoch 26/500
140/140 - 19s - loss: 0.7149 - accuracy: 0.6086 - val_loss: 0.6662 - val_accuracy: 0.6033
Epoch 27/500
140/140 - 19s - loss: 0.7148 - accuracy: 0.5945 - val_loss: 0.6642 - val_accuracy: 0.6196
Epoch 28/500
140/140 - 19s - loss: 0.6951 - accuracy: 0.6032 - val_loss: 0.6631 - val_accuracy: 0.6159
Epoch 29/500
140/140 - 19s - loss: 0.6969 - accuracy: 0.6151 - val_loss: 0.6624 - val_accuracy: 0.6141
Epoch 30/500
140/140 - 19s - loss: 0.6896 - accuracy: 0.6167 - val_loss: 0.6609 - val_accuracy: 0.6214
Epoch 31/500
140/140 - 19s - loss: 0.6959 - accuracy: 0.6041 - val_loss: 0.6597 - val_accuracy: 0.6196
Epoch 32/500
140/140 - 19s - loss: 0.6820 - accuracy: 0.6202 - val_loss: 0.6583 - val_accuracy: 0.6214
Epoch 33/500
140/140 - 19s - loss: 0.6827 - accuracy: 0.6283 - val_loss: 0.6569 - val_accuracy: 0.6232
Epoch 34/500
140/140 - 19s - loss: 0.6725 - accuracy: 0.6267 - val_loss: 0.6559 - val_accuracy: 0.6250
Epoch 35/500
140/140 - 19s - loss: 0.6736 - accuracy: 0.6312 - val_loss: 0.6553 - val_accuracy: 0.6268
Epoch 36/500
140/140 - 19s - loss: 0.6691 - accuracy: 0.6404 - val_loss: 0.6536 - val_accuracy: 0.6286
Epoch 37/500
140/140 - 19s - loss: 0.6548 - accuracy: 0.6471 - val_loss: 0.6528 - val_accuracy: 0.6304
Epoch 38/500
140/140 - 19s - loss: 0.6553 - accuracy: 0.6364 - val_loss: 0.6517 - val_accuracy: 0.6304
Epoch 39/500
140/140 - 19s - loss: 0.6408 - accuracy: 0.6538 - val_loss: 0.6508 - val_accuracy: 0.6322
Epoch 40/500
140/140 - 19s - loss: 0.6355 - accuracy: 0.6496 - val_loss: 0.6490 - val_accuracy: 0.6395
Epoch 41/500
140/140 - 19s - loss: 0.6376 - accuracy: 0.6572 - val_loss: 0.6479 - val_accuracy: 0.6449
Epoch 42/500
140/140 - 19s - loss: 0.6368 - accuracy: 0.6599 - val_loss: 0.6478 - val_accuracy: 0.6467
Epoch 43/500
140/140 - 19s - loss: 0.6234 - accuracy: 0.6684 - val_loss: 0.6468 - val_accuracy: 0.6431
Epoch 44/500
140/140 - 19s - loss: 0.6170 - accuracy: 0.6755 - val_loss: 0.6461 - val_accuracy: 0.6449
Epoch 45/500
140/140 - 19s - loss: 0.6072 - accuracy: 0.6782 - val_loss: 0.6446 - val_accuracy: 0.6413
Epoch 46/500
140/140 - 19s - loss: 0.6187 - accuracy: 0.6749 - val_loss: 0.6441 - val_accuracy: 0.6467
Epoch 47/500
140/140 - 19s - loss: 0.5943 - accuracy: 0.6921 - val_loss: 0.6436 - val_accuracy: 0.6449
Epoch 48/500
140/140 - 19s - loss: 0.5963 - accuracy: 0.6876 - val_loss: 0.6427 - val_accuracy: 0.6395
Epoch 49/500
140/140 - 19s - loss: 0.5996 - accuracy: 0.6816 - val_loss: 0.6417 - val_accuracy: 0.6413
Epoch 50/500
140/140 - 19s - loss: 0.5753 - accuracy: 0.7085 - val_loss: 0.6403 - val_accuracy: 0.6449
Epoch 51/500
140/140 - 19s - loss: 0.5704 - accuracy: 0.7022 - val_loss: 0.6397 - val_accuracy: 0.6449
Epoch 52/500
140/140 - 19s - loss: 0.5692 - accuracy: 0.7161 - val_loss: 0.6386 - val_accuracy: 0.6449
Epoch 53/500
140/140 - 19s - loss: 0.5670 - accuracy: 0.7114 - val_loss: 0.6390 - val_accuracy: 0.6467
Epoch 54/500
140/140 - 19s - loss: 0.5564 - accuracy: 0.7176 - val_loss: 0.6383 - val_accuracy: 0.6431
Epoch 55/500
140/140 - 19s - loss: 0.5461 - accuracy: 0.7273 - val_loss: 0.6377 - val_accuracy: 0.6522
Epoch 56/500
140/140 - 19s - loss: 0.5517 - accuracy: 0.7188 - val_loss: 0.6367 - val_accuracy: 0.6522
Epoch 57/500
140/140 - 19s - loss: 0.5575 - accuracy: 0.7176 - val_loss: 0.6364 - val_accuracy: 0.6504
Epoch 58/500
140/140 - 19s - loss: 0.5452 - accuracy: 0.7215 - val_loss: 0.6354 - val_accuracy: 0.6522
Epoch 59/500
140/140 - 19s - loss: 0.5256 - accuracy: 0.7362 - val_loss: 0.6344 - val_accuracy: 0.6522
Epoch 60/500
140/140 - 19s - loss: 0.5322 - accuracy: 0.7360 - val_loss: 0.6338 - val_accuracy: 0.6522
Epoch 61/500
140/140 - 19s - loss: 0.5291 - accuracy: 0.7445 - val_loss: 0.6337 - val_accuracy: 0.6522
Epoch 62/500
140/140 - 19s - loss: 0.5137 - accuracy: 0.7416 - val_loss: 0.6341 - val_accuracy: 0.6522
Epoch 63/500
140/140 - 19s - loss: 0.5151 - accuracy: 0.7506 - val_loss: 0.6336 - val_accuracy: 0.6522
Epoch 64/500
140/140 - 19s - loss: 0.5057 - accuracy: 0.7465 - val_loss: 0.6344 - val_accuracy: 0.6486
Epoch 65/500
140/140 - 19s - loss: 0.5042 - accuracy: 0.7582 - val_loss: 0.6336 - val_accuracy: 0.6540
Epoch 66/500
140/140 - 19s - loss: 0.5159 - accuracy: 0.7436 - val_loss: 0.6336 - val_accuracy: 0.6522
Epoch 67/500
140/140 - 19s - loss: 0.4831 - accuracy: 0.7642 - val_loss: 0.6337 - val_accuracy: 0.6576
Epoch 68/500
140/140 - 19s - loss: 0.4726 - accuracy: 0.7689 - val_loss: 0.6331 - val_accuracy: 0.6558
Epoch 69/500
140/140 - 19s - loss: 0.4729 - accuracy: 0.7765 - val_loss: 0.6334 - val_accuracy: 0.6540
Epoch 70/500
140/140 - 19s - loss: 0.4687 - accuracy: 0.7777 - val_loss: 0.6345 - val_accuracy: 0.6558
Epoch 71/500
140/140 - 19s - loss: 0.4611 - accuracy: 0.7819 - val_loss: 0.6342 - val_accuracy: 0.6522
Epoch 72/500
140/140 - 19s - loss: 0.4681 - accuracy: 0.7756 - val_loss: 0.6348 - val_accuracy: 0.6612
Epoch 73/500
140/140 - 19s - loss: 0.4551 - accuracy: 0.7850 - val_loss: 0.6357 - val_accuracy: 0.6486
Epoch 74/500
140/140 - 19s - loss: 0.4488 - accuracy: 0.7915 - val_loss: 0.6353 - val_accuracy: 0.6486
Epoch 75/500
140/140 - 19s - loss: 0.4473 - accuracy: 0.7868 - val_loss: 0.6364 - val_accuracy: 0.6504
Epoch 76/500
140/140 - 19s - loss: 0.4441 - accuracy: 0.7944 - val_loss: 0.6362 - val_accuracy: 0.6486
Epoch 77/500
140/140 - 19s - loss: 0.4465 - accuracy: 0.7868 - val_loss: 0.6378 - val_accuracy: 0.6431
Epoch 78/500
140/140 - 19s - loss: 0.4154 - accuracy: 0.8014 - val_loss: 0.6388 - val_accuracy: 0.6413
Epoch 79/500
140/140 - 19s - loss: 0.4264 - accuracy: 0.7953 - val_loss: 0.6396 - val_accuracy: 0.6431
Epoch 80/500
140/140 - 19s - loss: 0.4049 - accuracy: 0.8139 - val_loss: 0.6402 - val_accuracy: 0.6431
Epoch 81/500
140/140 - 19s - loss: 0.4140 - accuracy: 0.8099 - val_loss: 0.6412 - val_accuracy: 0.6431
Epoch 82/500
140/140 - 19s - loss: 0.4017 - accuracy: 0.8211 - val_loss: 0.6424 - val_accuracy: 0.6431
Epoch 83/500
140/140 - 19s - loss: 0.3862 - accuracy: 0.8245 - val_loss: 0.6436 - val_accuracy: 0.6395
Epoch 84/500
140/140 - 19s - loss: 0.3956 - accuracy: 0.8206 - val_loss: 0.6439 - val_accuracy: 0.6431
Epoch 85/500
140/140 - 19s - loss: 0.3848 - accuracy: 0.8278 - val_loss: 0.6451 - val_accuracy: 0.6467
Epoch 86/500
140/140 - 19s - loss: 0.3926 - accuracy: 0.8189 - val_loss: 0.6456 - val_accuracy: 0.6431
Epoch 87/500
140/140 - 19s - loss: 0.3811 - accuracy: 0.8283 - val_loss: 0.6465 - val_accuracy: 0.6449
Epoch 88/500
140/140 - 19s - loss: 0.3773 - accuracy: 0.8251 - val_loss: 0.6480 - val_accuracy: 0.6504
Epoch 89/500
140/140 - 19s - loss: 0.3649 - accuracy: 0.8323 - val_loss: 0.6491 - val_accuracy: 0.6467
Epoch 90/500
140/140 - 19s - loss: 0.3835 - accuracy: 0.8202 - val_loss: 0.6508 - val_accuracy: 0.6486
Epoch 91/500
140/140 - 19s - loss: 0.3570 - accuracy: 0.8444 - val_loss: 0.6524 - val_accuracy: 0.6504
Epoch 92/500
140/140 - 19s - loss: 0.3538 - accuracy: 0.8419 - val_loss: 0.6537 - val_accuracy: 0.6522
========================================
save_weights
h5_weights/GM.pp/embedding_cnn_two_branch.h5
========================================

end time >>> Sun Oct  3 06:22:13 2021

end time >>> Sun Oct  3 06:22:13 2021

end time >>> Sun Oct  3 06:22:13 2021

end time >>> Sun Oct  3 06:22:13 2021

end time >>> Sun Oct  3 06:22:13 2021












args.model = embedding_cnn_two_branch
time used = 1739.9312179088593


